{"cells":[{"cell_type":"markdown","source":["# Predicting Airline Delays - Final Notebook\n###### W261 Spring 2020 \n###### Presentation Date: April 16th, 2020\n###### Team 20: Diana Iftimie, Shaji K Kunjumohamed, Navya Sandadi, & Shobha Sankar"],"metadata":{}},{"cell_type":"markdown","source":["## I. Question Formulation & Introduction\n\nAs we've all probably experienced at some point in our lives, air travel is never easy. Whether you're the person getting on a flight traveling around the world, the folks in the air traffic control towers orchestrating incoming and outgoing flights, or the airports and airlines trying their best to effectively coordinate flights at every hour of every day of every year, so much can go wrong. The delays alone are enough to completely derail anyone's plans and trigger a cascading effect of consequences down the line as delays continue to stack up on top of each other over the course of time. And the biggest problem is that these delays often occur when we least expect them and at the worst possible times.\n\nDelays are costly for airlines and their passengers. A 2010 study commissioned by the Federal Aviation Administration estimated thatÂ flight delays cost the airline industry $8 billion a year, much of it due to increased spending on crews, fuel and maintenance. They cost passengers even more, nearly $17 billion.\n\nTo attempt to solve this problem, we introduce the *Airline Delays* dataset, a dataset of US domestic flights from 2015 to 2019 collected by the Bureau of Transportation Statistics for the purpose of studying airline delays. For this analysis, we will primarily use this dataset to study the nature of airline delays in the United States over the last few years, with the ultimate goal of developing models for predicting significant flight departure delays (30 minutes or more) in the United States. \n\nIn developing such models, we seek to answer the core question, **\"Given known information prior to a flight's departure, can we predict departure delays and identify the likely causes of such delays?\"**. In the last few years, about 11% of all US domestic flights resulted in significant delays, and answering these questions can truly help us to understand why such delays happen. In doing so, not only can airlines and airports start to identify likely causes and find ways to mitigate them and save both time and money, but air travelers also have the potential to better prepare for likely delays and possibly even plan for different flights in order to reduce their chance of significant delay. \n\nTo effectively investigate this question and produce a practically useful model, we will aim to develop a model that performs better than a baseline model that predicts the majority class of 'no delay' every time (this would have an accuracy of 89%). Having said that, we have been informed by our instructors that the state of the art is 85% accuracy, but will proceed to also prioritize model interpretability along side model performance metrics to help address our core question. Given the classification nature of this problem, we will concentrate on improving metrics such as precision, recall, F1, area under ROC, and area under PR curve, over our baseline model. We will also concentrate on producing models that can explain what features of flights known prior to departure time can best predict departure delays and from these, attempt to best infer possible causes of departure delays."],"metadata":{}},{"cell_type":"code","source":["# Pyspark SQL libraries\nfrom pyspark.sql import functions as F\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import when\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType\nfrom pyspark.sql.functions import udf\nfrom pyspark.sql import Window\n\n# Pyspark ML libraries\nimport pyspark.ml.pipeline as pl\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.classification import LinearSVC\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.feature import Bucketizer, StringIndexer, VectorIndexer, VectorAssembler, OneHotEncoderEstimator\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import RandomForestClassifier\n\nfrom pyspark.mllib.evaluation import MulticlassMetrics\n\n# Other python librarires\nfrom dateutil.relativedelta import relativedelta, SU, MO, TU, WE, TH, FR, SA\nimport pandas as pd\nimport datetime as dt\nimport ast\nimport random"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["%sh \npip install plotly --upgrade"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Collecting plotly\n  Downloading https://files.pythonhosted.org/packages/15/90/918bccb0ca60dc6d126d921e2c67126d75949f5da777e6b18c51fb12603d/plotly-4.6.0-py2.py3-none-any.whl (7.1MB)\nCollecting retrying&gt;=1.3.3 (from plotly)\n  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\nRequirement already satisfied, skipping upgrade: six in /databricks/conda/envs/databricks-ml/lib/python3.7/site-packages (from plotly) (1.12.0)\nBuilding wheels for collected packages: retrying\n  Building wheel for retrying (setup.py): started\n  Building wheel for retrying (setup.py): finished with status &#39;done&#39;\n  Stored in directory: /root/.cache/pip/wheels/d7/a9/33/acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\nSuccessfully built retrying\nInstalling collected packages: retrying, plotly\nSuccessfully installed plotly-4.6.0 retrying-1.3.3\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["from plotly.offline import plot\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.subplots import make_subplots"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"markdown","source":["## II. EDA & Discussion of Challenges\n\n### Dataset Introduction\nThe Bureau of Transporation Statistics provides us with a wide variety of features relating to each flight in the *Airline Delays* dataset. These features range from features about the scheduled flight such as the planned departure, arrival, and elapsed times, the planned distance, the carrier and airport information, information regarding the causes of certain delays for the entire flight, as well as the amounts of delay (for both flight departure and arrival), among many other features. \n\nGiven that for this analysis, we will be concentrating on predicting and identifying the likely causes of departure delays before any such delay happens, we will primarily concentrate on our EDA, feature engineering, and model development using features of flights that would be known at inference time. We will choose the inference time to be 6 hours prior to the scheduled departure time of a flight. Realistically speaking, providing someone with a notice that a flight will likely be delayed 6 hours in advance is likely a sufficient amount of time to let people prepare for such a delay to reduce the cost of the departure delay, if it occurs. Such features that fit this criterion include those that are related to:\n\n* **Time of year / Flight Date** \n    - `Year`: The year in which the flight occurs (range: [2015, 2019])\n    - `Month`: A numerical indicator for the month in which the flight occurs (range: [1, 12], 1 corresponds to January)\n    - `Day_Of_Month`: The day of the month in which the flight occurs (range: [1, 31])\n    - `Day_Of_Week`: A numerical indiciator for the day of the week in which the flight occurs (range: [1, 7], 1 corresponds to Monday)\n* **Scheduled Departure & Arrival Times**\n    - `CRS_Dep_Time`: The scheduled departure time of the flight (range: (0, 2400], 100 corresponds to 1AM departure time)\n    - `CRS_Arr_Time`: The scheduled arrival time of the flight (range: (0, 2400], 100 corresonds to 1AM arrival time)\n* **Planned Elapsed Times & Distances**\n    - `CRS_Elapsed_Time`: The scheduled elapsed time (in minutes) of the flight (continuous variable, 60 corresponds to 1 hour elapsed time)\n    - `Distance`: The planned distance (in miles) for the flight distance from origin to destination airports (continuous variable, e.g. 2475 miles)\n    - `Distance_Group`: A binned version of the `Distance` variable into integer bins (range: [1, 11], e.g. 2475 miles maps to a distance group of 10)\n* **Airline Carrier**\n    - `Op_Unique_Carrier`: A shortcode denoting the airline carrier that operated the flight (categorical, 19 distinct carriers, e.g. 'AS' corresponds to Alaska Airlines, more mappings of airlines codes can be found here: https://www.bts.gov/topics/airlines-and-airports/airline-codes) \n* **Origin & Destination Airports** \n    - `Origin`: A shortcode denoting the origin airport from which the plane took off (categorical, 364 distinct airports, e.g. 'SFO' corresponds to San Francisco International Airport, more mappings of airport codes can be found here: https://www.bts.gov/topics/airlines-and-airports/world-airport-codes)\n    - `Dest`: A shortcode denoting the destination airport at which the plane landed (categorical, 364 distinct airports, same in construct as `Origin`)\n\nWe will prioritize working with these features in the next few sections. Additionally, we will use the variable `Dep_Delay` (which describes the amount of departure delay in minutes) to define our outcome variable for \"significiant\" departure delays (i.e. delays of 30 minutes or more). These significant delays will be encoded in the variable `Dep_Del30`, a 0/1 indicator for whether the flight was delayed, which we will append to the dataset below. Finally, we will focus our analysis to the subset of flights that are not diverted, are not cancelled, and have non-null values for departure delays to ensure that we can accurately predict departure delays for flights. This subset will still leave us with a significant number of records to work with for the purpose of training and model development. \n\nBelow are a few example flights taken from the *Airline Delays* dataset that we will use for our analysis."],"metadata":{}},{"cell_type":"code","source":["def LoadAirlineDelaysData():\n  # Read in original dataset\n  airlines = spark.read.option(\"header\", \"true\").parquet(f\"dbfs:/mnt/mids-w261/data/datasets_final_project/parquet_airlines_data/201*.parquet\")\n\n  # Filter to datset with entries where diverted != 1, cancelled != 1, and dep_delay != Null\n  airlines = airlines.where('DIVERTED != 1') \\\n                     .where('CANCELLED != 1') \\\n                     .filter(airlines['DEP_DELAY'].isNotNull()) \n  return airlines\n\n# Generate other Departure Delay outcome indicators for n minutes\ndef CreateNewDepDelayOutcome(data, thresholds):\n  for threshold in thresholds:\n    if ('Dep_Del' + str(threshold) in data.columns):\n      print('Dep_Del' + str(threshold) + \" already exists\")\n      continue\n    data = data.withColumn('Dep_Del' + str(threshold), (data['Dep_Delay'] >= threshold).cast('integer'))\n  return data  \n\n# Load data & define outcome variable\nairlines = LoadAirlineDelaysData()\nairlines = CreateNewDepDelayOutcome(airlines, [30])\n\nprint(airlines.columns)\n\n# Filter dataset to variables of interest\noutcomeName = 'Dep_Del30'\nnumFeatureNames = ['Year', 'Month', 'Day_Of_Month', 'Day_Of_Week', 'Distance_Group']\ncontNumFeatureNames = ['CRS_Dep_Time', 'CRS_Arr_Time', 'CRS_Elapsed_Time', 'Distance']\ncatFeatureNames = ['Op_Unique_Carrier', 'Origin', 'Dest']\njoiningFeatures = ['FL_Date'] # Features needed to join with the holidays dataset--not needed for training\nairlines = airlines.select([outcomeName] + numFeatureNames + contNumFeatureNames + catFeatureNames + joiningFeatures)\n\n# Display a small sample of flight records\ndisplay(airlines.select([outcomeName] + numFeatureNames + contNumFeatureNames + catFeatureNames).sample(fraction=0.0001, seed=6).take(10))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Dep_Del30</th><th>Year</th><th>Month</th><th>Day_Of_Month</th><th>Day_Of_Week</th><th>Distance_Group</th><th>CRS_Dep_Time</th><th>CRS_Arr_Time</th><th>CRS_Elapsed_Time</th><th>Distance</th><th>Op_Unique_Carrier</th><th>Origin</th><th>Dest</th></tr></thead><tbody><tr><td>1</td><td>2019</td><td>6</td><td>20</td><td>4</td><td>1</td><td>2245</td><td>2349</td><td>64.0</td><td>224.0</td><td>DL</td><td>SEA</td><td>GEG</td></tr><tr><td>0</td><td>2019</td><td>6</td><td>21</td><td>5</td><td>1</td><td>1625</td><td>1618</td><td>53.0</td><td>134.0</td><td>DL</td><td>ATL</td><td>BHM</td></tr><tr><td>0</td><td>2019</td><td>6</td><td>21</td><td>5</td><td>2</td><td>1659</td><td>1837</td><td>98.0</td><td>432.0</td><td>DL</td><td>IND</td><td>ATL</td></tr><tr><td>0</td><td>2019</td><td>6</td><td>1</td><td>6</td><td>5</td><td>1800</td><td>2105</td><td>185.0</td><td>1065.0</td><td>UA</td><td>EWR</td><td>FLL</td></tr><tr><td>0</td><td>2019</td><td>6</td><td>2</td><td>7</td><td>3</td><td>1117</td><td>1222</td><td>125.0</td><td>522.0</td><td>OO</td><td>BOI</td><td>SFO</td></tr><tr><td>0</td><td>2019</td><td>6</td><td>3</td><td>1</td><td>3</td><td>810</td><td>955</td><td>105.0</td><td>587.0</td><td>WN</td><td>TPA</td><td>RDU</td></tr><tr><td>1</td><td>2019</td><td>6</td><td>19</td><td>3</td><td>1</td><td>1440</td><td>1530</td><td>50.0</td><td>148.0</td><td>WN</td><td>HOU</td><td>AUS</td></tr><tr><td>0</td><td>2019</td><td>6</td><td>28</td><td>5</td><td>8</td><td>1019</td><td>1302</td><td>283.0</td><td>1846.0</td><td>AA</td><td>ORD</td><td>SFO</td></tr><tr><td>0</td><td>2019</td><td>6</td><td>14</td><td>5</td><td>4</td><td>630</td><td>915</td><td>165.0</td><td>925.0</td><td>MQ</td><td>IAH</td><td>ORD</td></tr><tr><td>0</td><td>2019</td><td>6</td><td>24</td><td>1</td><td>3</td><td>1527</td><td>1652</td><td>145.0</td><td>606.0</td><td>MQ</td><td>ATL</td><td>ORD</td></tr></tbody></table></div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["Note that because we are interested in predicting departure delays for future flights, we will define our test set to be the entirety of flights from the year 2019 and use the years 2015-2018 for feature engineering and model development (training & validation sets). This way, we will simulate the conditions for training a model that will predict departure delays for future flights. This will leave about 23% of the data for testing and the remaining 77% for training & validation. \n\nAdditionally, in this section and the next section on feature engineering, we'll mainly be operating on distinct columns of the dataset at any given time. In order to help with scalability of our explorations and preprocessing, we will save these dataset splits to parquet files in the cluster, as parquet is optimized for column-wise storage and thus will help improve the performance of our column-wise analysis of the *Airlines Delays* dataset. We will also focus our EDA on the union of training & validation sets, to ensure our decisions are not influenced by the test set."],"metadata":{}},{"cell_type":"code","source":["def SplitDataset(airlines):\n  # Split airlines data into train, dev, test\n  test = airlines.where('Year = 2019') # held out\n  train, val = airlines.where('Year != 2019').randomSplit([7.0, 1.0], 6)\n\n  # Select a mini subset for the training dataset (~2000 records)\n  mini_train = train.sample(fraction=0.0001, seed=6)\n\n  print(\"mini_train size = \" + str(mini_train.count()))\n  print(\"train size = \" + str(train.count()))\n  print(\"val size = \" + str(val.count()))\n  print(\"test size = \" + str(test.count()))\n  \n  return (mini_train, train, val, test) \n\n# Write train & val data to parquet for easier EDA\ndef WriteAndRefDataToParquet(data, dataName):\n  # Write data to parquet format (for easier EDA)\n  data.write.mode('overwrite').format(\"parquet\").save(\"dbfs:/user/team20/finalnotebook/airlines_\" + dataName + \".parquet\")\n  \n  # Read data back directly from disk \n  return spark.read.option(\"header\", \"true\").parquet(\"dbfs:/user/team20/finalnotebook/airlines_\" + dataName + \".parquet\")\n\n# Split dataset into training/validation/test; use mini_train to help with quick testing\nmini_train, train, val, test = SplitDataset(airlines)\n\n# Save and reload datasets for more efficient EDA & feature engineering\nmini_train = WriteAndRefDataToParquet(mini_train, 'mini_train')\ntrain = WriteAndRefDataToParquet(train, 'train')\nval = WriteAndRefDataToParquet(val, 'val')\ntest = WriteAndRefDataToParquet(test, 'test')\ntrain_and_val = WriteAndRefDataToParquet(train.union(val), 'train_and_val')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">mini_train size = 2055\ntrain size = 20916140\nval size = 2989704\ntest size = 7268232\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["### Prospective Models for the Departure Delay Classification Task\nBefore we go into detail on our core EDA tasks, we'd like to introduce the models we will be considering in section IV to motivate our discussion. At a high level, we will be considering the set of models that include the following:\n* Decision Trees\n* Logistic Regression\n* Naive Bayes\n* Support Vector Machines\n\nGiven that our task for this analysis is to classify flights as delayed (1) or not delayed (0), we want to ensure that the models we consider are well suited for classification tasks, which all four of these models are good at. Additionally, since we'll be interested in looking at explainable models to help inform why certain flights are delayed over others, we consider Decision Trees, Logistic Regression, and Naive Bayes explicitly for this task, whereas Support Vector Machines are not as well-suited for explainability. We will discuss these models in more detail in section IV when we discuss our algorithm exploration. With that said, we'll keep these models in mind as we explore our core EDA tasks."],"metadata":{}},{"cell_type":"markdown","source":["### EDA Task #1: Binning Continuous Features\nAmong the features that we have to consider for predicting departure delays, we have 4 that are relatively continuous and can take on thousands of different values: `CRS_Dep_Time`, `CRS_Arr_Time`, `CRS_Elapsed_Time`, and `Distance`. Let's primarily focus on the variable `CRS_Elapsed_Time` to motivate this discussion and we'll generalize it to the remaining 3 variables. Below is a plot showing the bulk of the distribution for the feature `CRS_Elapsed_Time`."],"metadata":{}},{"cell_type":"code","source":["# Helper Function for plotting distinct values of feature on X and number of flights on Y, categorized by outocme variable\ndef MakeRegBarChart(full_data_dep, outcomeName, var, orderBy, barmode, xtype, xrange=None, yrange=None):\n  if (orderBy):\n      d = full_data_dep.select(var, outcomeName).groupBy(var, outcomeName).count().orderBy(orderBy).toPandas()\n  else:\n    d = full_data_dep.select(var, outcomeName).groupBy(var, outcomeName).count().toPandas()\n\n  t1 = go.Bar(\n    x = d[d[outcomeName] == 0.0][var],\n    y = d[d[outcomeName] == 0.0][\"count\"],\n    name=outcomeName + \" = \" + str(0.0)\n  )\n  t2 = go.Bar(\n    x = d[d[outcomeName] == 1.0][var],\n    y = d[d[outcomeName] == 1.0][\"count\"],\n    name=outcomeName + \" = \" + str(1.0)\n  )\n\n  l = go.Layout(\n    barmode=barmode, \n    title=\"Flight Counts by \" + var + \" & \" + outcomeName,\n    xaxis=dict(title=var, type=xtype, range=xrange),\n    yaxis=dict(title=\"Number of Flights\", range=yrange)\n  )\n  fig = go.Figure(data=[t1, t2], layout=l)\n  fig.show()\n  return fig\n\nvar = 'CRS_Elapsed_Time'\nfig = MakeRegBarChart(train_and_val, outcomeName, var, orderBy=var, barmode='stack', xtype='linear', xrange=[0, 450])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"33690af7-133d-475e-ab1e-d2ecfd558d14\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"33690af7-133d-475e-ab1e-d2ecfd558d14\")) {\n                    Plotly.newPlot(\n                        '33690af7-133d-475e-ab1e-d2ecfd558d14',\n                        [{\"name\": \"Dep_Del30 = 0.0\", \"type\": \"bar\", \"x\": [1.0, 5.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0, 513.0, 514.0, 515.0, 516.0, 517.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 537.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 576.0, 577.0, 578.0, 579.0, 580.0, 581.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0, 592.0, 593.0, 594.0, 595.0, 596.0, 597.0, 598.0, 599.0, 600.0, 602.0, 603.0, 604.0, 606.0, 607.0, 608.0, 610.0, 611.0, 612.0, 613.0, 614.0, 615.0, 616.0, 617.0, 618.0, 619.0, 620.0, 622.0, 623.0, 625.0, 627.0, 631.0, 632.0, 633.0, 636.0, 640.0, 641.0, 644.0, 645.0, 646.0, 647.0, 648.0, 650.0, 652.0, 654.0, 655.0, 656.0, 658.0, 660.0, 665.0, 667.0, 668.0, 669.0, 670.0, 672.0, 675.0, 676.0, 679.0, 680.0, 681.0, 683.0, 685.0, 686.0, 688.0, 690.0, 695.0, 698.0, 700.0, 702.0, 703.0, 704.0, 705.0, 712.0, 718.0], \"y\": [3, 1, 109, 1, 173, 442, 580, 623, 462, 133, 183, 145, 56, 100, 751, 784, 5237, 6711, 9829, 20023, 11592, 20063, 12216, 24676, 18597, 18058, 12999, 19682, 21073, 28481, 24351, 39573, 28615, 30109, 66116, 39498, 45844, 50034, 55127, 128584, 49460, 56196, 62751, 68154, 235046, 60741, 74730, 78564, 83207, 329285, 85192, 87726, 94708, 94069, 353815, 93332, 99784, 100208, 104154, 349646, 109476, 110373, 112726, 115361, 402953, 110246, 117389, 117979, 122942, 412708, 114533, 117239, 121822, 127016, 384170, 112349, 121992, 123376, 127074, 291560, 110856, 113545, 116680, 120997, 265627, 111232, 110720, 114070, 110395, 261405, 98164, 105014, 110509, 112597, 284512, 105786, 105904, 107354, 109784, 265714, 110681, 105629, 105533, 110876, 252791, 96383, 92954, 99616, 101230, 229238, 85546, 89860, 87262, 86777, 226153, 81844, 79809, 81847, 82543, 232023, 72743, 74949, 76738, 78711, 220087, 74083, 73824, 70620, 76475, 211287, 68493, 70121, 72451, 78556, 221551, 71524, 72564, 76983, 79482, 223452, 77031, 78469, 80189, 82341, 226518, 78912, 75920, 78759, 78615, 190987, 73527, 71285, 73724, 72786, 176659, 64673, 67758, 68455, 67263, 154682, 62248, 60346, 61019, 61176, 130378, 53180, 52657, 50694, 49454, 107607, 44568, 45916, 42620, 43688, 90507, 37705, 38308, 37864, 37382, 85054, 32969, 32242, 33311, 33259, 86884, 30879, 32461, 31702, 29188, 82178, 28600, 30094, 30221, 33007, 77440, 28641, 29504, 26466, 29275, 63487, 25474, 25620, 25565, 26430, 58788, 23220, 23905, 23864, 25005, 61885, 23025, 25412, 23031, 24458, 67887, 23838, 24364, 25327, 24173, 71315, 22358, 23302, 23962, 24383, 66184, 23180, 22145, 21011, 21666, 54893, 18789, 19694, 19972, 20100, 51315, 19084, 17634, 17967, 19846, 49016, 16819, 17357, 17744, 16926, 44732, 16101, 15406, 15194, 17470, 41635, 15113, 16150, 16416, 15599, 41250, 13937, 14366, 14765, 16274, 37944, 14603, 15887, 15466, 14342, 34063, 12742, 13918, 12976, 12317, 29349, 10916, 10293, 10799, 13030, 28570, 12015, 11891, 10962, 12080, 25049, 11798, 10827, 12522, 12357, 27642, 9891, 11321, 12545, 12500, 24561, 11099, 12451, 11264, 12566, 28183, 10924, 11867, 13288, 14382, 27156, 12655, 12306, 13586, 14345, 27858, 12641, 13937, 15710, 14469, 30334, 12649, 14390, 16087, 17154, 31595, 13292, 13033, 13050, 15133, 24624, 11000, 12786, 11619, 12695, 26756, 10149, 10147, 10506, 10200, 21083, 8455, 8095, 9596, 8226, 18675, 7305, 7851, 8550, 8634, 17911, 6863, 7518, 8103, 7716, 15831, 6435, 6161, 6759, 6881, 14854, 6298, 6148, 6196, 6230, 15434, 5639, 6004, 7195, 6058, 13131, 5908, 7034, 5947, 6132, 13389, 5928, 5891, 6268, 5882, 12294, 5432, 5675, 4925, 5244, 11036, 4698, 3712, 5116, 4438, 8388, 3962, 3458, 3503, 3799, 6876, 2954, 2786, 3261, 3165, 5613, 1692, 2308, 1762, 1737, 2023, 1548, 1541, 1210, 1055, 923, 672, 504, 767, 575, 767, 520, 297, 433, 523, 856, 93, 233, 126, 203, 396, 209, 99, 281, 148, 296, 233, 304, 299, 124, 685, 461, 217, 533, 424, 376, 84, 33, 345, 176, 252, 59, 78, 264, 214, 264, 289, 524, 124, 300, 400, 259, 219, 90, 238, 339, 188, 67, 84, 275, 724, 258, 176, 226, 88, 427, 55, 215, 121, 103, 205, 81, 98, 111, 289, 68, 62, 223, 297, 137, 57, 84, 302, 188, 84, 269, 350, 293, 44, 184, 16, 232, 66, 56, 162, 40, 83, 289, 216, 134, 95, 122, 270, 327, 100, 166, 87, 127, 160, 562, 153, 186, 166, 217, 150, 58, 166, 63, 44, 158, 86, 69, 34, 27, 132, 51, 81, 3, 61, 18, 89, 127, 112, 69, 83, 233, 11, 115, 7, 121, 123, 37, 86, 121, 65, 123, 136, 104, 52, 110, 10, 91, 182, 49, 129, 16, 434, 148, 69, 178, 9, 288, 49, 6, 160, 334, 242, 133, 113, 9, 330, 50, 119, 79, 16, 187, 29, 34, 35, 32, 165, 13, 4, 11, 21, 1, 14, 4, 34, 34, 19, 14, 14, 12, 24, 60, 137, 89, 197, 64, 123, 2, 93, 32, 6, 12, 2, 51, 7, 29, 4, 151, 9, 70, 27, 46, 81, 65, 195, 59, 55, 412, 68, 55, 75, 111, 47, 5, 81, 72, 83, 148, 113, 101, 62, 59, 77, 43, 16, 53, 102, 112, 3, 28, 1, 12, 20, 19, 37, 21]}, {\"name\": \"Dep_Del30 = 1.0\", \"type\": \"bar\", \"x\": [-99.0, 1.0, 4.0, 18.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0, 513.0, 514.0, 515.0, 516.0, 517.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 530.0, 531.0, 532.0, 533.0, 535.0, 537.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 578.0, 579.0, 580.0, 581.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0, 592.0, 593.0, 595.0, 596.0, 599.0, 600.0, 602.0, 604.0, 608.0, 610.0, 611.0, 612.0, 613.0, 614.0, 615.0, 616.0, 617.0, 618.0, 619.0, 620.0, 622.0, 623.0, 625.0, 627.0, 631.0, 632.0, 633.0, 636.0, 640.0, 641.0, 644.0, 646.0, 647.0, 648.0, 650.0, 652.0, 654.0, 655.0, 656.0, 658.0, 660.0, 665.0, 667.0, 669.0, 670.0, 672.0, 675.0, 676.0, 679.0, 680.0, 681.0, 683.0, 685.0, 686.0, 688.0, 690.0, 695.0, 698.0, 700.0, 702.0, 704.0, 705.0, 712.0, 718.0], \"y\": [1, 1, 1, 10, 15, 37, 42, 63, 55, 10, 16, 17, 5, 17, 75, 61, 120, 314, 340, 601, 481, 792, 536, 1052, 895, 950, 906, 1261, 1446, 2398, 1965, 2731, 2693, 3068, 7485, 3641, 4363, 5265, 5585, 15073, 5797, 6680, 7141, 7455, 27953, 6892, 8562, 8996, 9177, 41670, 10310, 10032, 10971, 10735, 43906, 11040, 11954, 12023, 12436, 45812, 12949, 13290, 13760, 14141, 52842, 13553, 14401, 14322, 15705, 54788, 14993, 14750, 15714, 16565, 50943, 14448, 15485, 15788, 16743, 38116, 14376, 14516, 14660, 15263, 34714, 13875, 13320, 13990, 13132, 32698, 11833, 12510, 13349, 13288, 36111, 12501, 12529, 13111, 13024, 33059, 12967, 12859, 12991, 13900, 33843, 12071, 11510, 12529, 12435, 30585, 10782, 11716, 11419, 11856, 30359, 11038, 10538, 10961, 11221, 32775, 9604, 10592, 10666, 10777, 29946, 9881, 9973, 9549, 10249, 27711, 9190, 9613, 9723, 10622, 29521, 9338, 9772, 10077, 10344, 30426, 10969, 10782, 10814, 11061, 30774, 11249, 10956, 11091, 11426, 26060, 10980, 10558, 10697, 10613, 23715, 9761, 10285, 10393, 9899, 21801, 9534, 9056, 9401, 9752, 18675, 8481, 7868, 7897, 7196, 15378, 6833, 6779, 6132, 6868, 12331, 5538, 5282, 5176, 5562, 11155, 4314, 4635, 4549, 4750, 11106, 4245, 4378, 4124, 4212, 10971, 3914, 3935, 4128, 4322, 10426, 3982, 3736, 3267, 3854, 9045, 3276, 3201, 3185, 3288, 7796, 3039, 2963, 3096, 3267, 8159, 2973, 3256, 3146, 3260, 9282, 3061, 3133, 3053, 3126, 9435, 2915, 3004, 3059, 3174, 8080, 2885, 2613, 2611, 2807, 6649, 2527, 2429, 2423, 2409, 6325, 2397, 2484, 2202, 2494, 5794, 2257, 2236, 2531, 2115, 5876, 2281, 2032, 1982, 2446, 5274, 2071, 2159, 2192, 2089, 5691, 1884, 1988, 1936, 2057, 5467, 2001, 2180, 2106, 1902, 4711, 1854, 1980, 1699, 1655, 4243, 1300, 1326, 1435, 1378, 3810, 1385, 1409, 1222, 1422, 3096, 1383, 1292, 1599, 1481, 3068, 1202, 1459, 1482, 1521, 3098, 1308, 1688, 1423, 1695, 3368, 1376, 1682, 1727, 1761, 3347, 1688, 1506, 1956, 1876, 3466, 1650, 1956, 1839, 2054, 3812, 1761, 2052, 2312, 2400, 4206, 1971, 1634, 1687, 2183, 3141, 1518, 1742, 1526, 1599, 3335, 1594, 1487, 1541, 1384, 2333, 1179, 1158, 1208, 1195, 2190, 1027, 1085, 1201, 1048, 1986, 941, 986, 1083, 1048, 1998, 885, 733, 984, 860, 1601, 835, 876, 850, 768, 1585, 747, 792, 921, 834, 1585, 948, 934, 854, 829, 1655, 939, 884, 1028, 1008, 1569, 828, 983, 817, 936, 1494, 793, 548, 765, 746, 1139, 614, 428, 457, 697, 1028, 483, 457, 523, 516, 750, 323, 391, 232, 265, 342, 295, 245, 204, 179, 80, 98, 65, 107, 67, 139, 70, 35, 50, 57, 106, 7, 25, 23, 13, 53, 14, 14, 27, 19, 18, 6, 31, 30, 18, 89, 37, 14, 53, 58, 38, 5, 6, 40, 10, 22, 7, 3, 14, 26, 32, 30, 62, 8, 30, 70, 22, 37, 11, 13, 48, 23, 15, 11, 34, 97, 33, 6, 20, 12, 54, 15, 20, 18, 11, 33, 8, 11, 24, 61, 3, 5, 48, 37, 7, 7, 18, 24, 22, 18, 48, 90, 41, 22, 37, 1, 52, 14, 16, 45, 9, 19, 70, 53, 20, 20, 15, 33, 85, 25, 60, 27, 17, 37, 90, 25, 39, 46, 33, 30, 1, 23, 1, 9, 6, 28, 1, 11, 5, 9, 5, 12, 1, 6, 27, 15, 14, 10, 25, 1, 11, 1, 11, 10, 2, 10, 16, 12, 20, 22, 14, 2, 20, 1, 17, 19, 3, 15, 6, 63, 20, 5, 28, 1, 28, 19, 28, 22, 15, 7, 2, 33, 6, 8, 10, 1, 12, 4, 1, 2, 13, 1, 2, 3, 1, 1, 4, 2, 3, 1, 3, 30, 4, 14, 4, 19, 1, 4, 1, 1, 3, 1, 7, 1, 2, 1, 12, 4, 6, 15, 18, 9, 19, 15, 13, 18, 7, 4, 4, 7, 5, 8, 2, 13, 9, 14, 23, 7, 8, 20, 4, 3, 9, 18, 7, 1, 1, 3, 8, 2, 5, 2]}],\n                        {\"barmode\": \"stack\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Flight Counts by CRS_Elapsed_Time & Dep_Del30\"}, \"xaxis\": {\"range\": [0, 450], \"title\": {\"text\": \"CRS_Elapsed_Time\"}, \"type\": \"linear\"}, \"yaxis\": {\"title\": {\"text\": \"Number of Flights\"}}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":12},{"cell_type":"markdown","source":["From the plot above, we can see the continuous nature of `CRS_Elapsed_Time`, with the majortiy of flights ranging between 50 to 200 minutes. Note that each of the taller bars correspond to flight durations at the 5-minute markers (60, 65, 70, etc), as these are more \"convenient\" flight durations that airlines tend to define when scheduling their flights. \n\nNow, if we consider the possible values that `CRS_Elapsed_Time` can intrinsically take on, it can be any number of minutes that the flight is scheduled to take; these could be values such as 60 minutes, 65 minutes, 120 minutes, even going onto 400 minutes in some cases, as evident above. Conceptually speaking, some of these times are drasticaly different (60 minutes vs. 400 minutes), while others are similar enough that they would be considered the same flight duration (60 minutes vs. 65 minutes). Because of this, these flight times could be aggregated into bins in order to group similar flight durations. For example, we could aggregate the `CRS_Elapsed_Time` into 1-hour blocks, which will produce a distribution such as the one shown below:"],"metadata":{}},{"cell_type":"code","source":["# Augments the provided dataset for the given variable with binned/bucketized\n# versions of that variable, as defined by splits parameter\n# Column name suffixed with '_bin' will be the bucketized column\n# Column name suffixed with '_binlabel' will be the nicely-named version of the bucketized column\ndef BinValuesForEDA(df, var, splits, labels):\n  # Bin values\n  bucketizer = Bucketizer(splits=splits, inputCol=var, outputCol=var + \"_bin\")\n  df_buck = bucketizer.setHandleInvalid(\"keep\").transform(df)\n  \n  # Add label column for binned values\n  bucketMaps = {}\n  bucketNum = 0\n  for l in labels:\n    bucketMaps[bucketNum] = l\n    bucketNum = bucketNum + 1\n  \n  callnewColsUdf = udf(lambda x: bucketMaps[x], StringType())  \n  return df_buck.withColumn(var + \"_binlabel\", callnewColsUdf(F.col(var + \"_bin\")))\n\n# Make plot with binned version of CRS_Elapsed_Time\nd = BinValuesForEDA(train_and_val, var, \n                    splits = [float(\"-inf\"), 60, 120, 180, 240, 300, 360, float(\"inf\")], \n                    labels = ['0-1 hours', '1-2 hours', '2-3 hours', '3-4 hours', '4-5 hours', '5-6 hours', '6+ hours'])\nfig = MakeRegBarChart(d, outcomeName, var + \"_binlabel\", orderBy=var + \"_binlabel\", barmode='stack', xtype='category')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"929a33fb-dfed-430f-a320-e7d2c533c32e\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"929a33fb-dfed-430f-a320-e7d2c533c32e\")) {\n                    Plotly.newPlot(\n                        '929a33fb-dfed-430f-a320-e7d2c533c32e',\n                        [{\"name\": \"Dep_Del30 = 0.0\", \"type\": \"bar\", \"x\": [\"0-1 hours\", \"1-2 hours\", \"2-3 hours\", \"3-4 hours\", \"4-5 hours\", \"5-6 hours\", \"6+ hours\"], \"y\": [978195, 8971075, 6253912, 2495981, 1252466, 860927, 361208]}, {\"name\": \"Dep_Del30 = 1.0\", \"type\": \"bar\", \"x\": [\"0-1 hours\", \"1-2 hours\", \"2-3 hours\", \"3-4 hours\", \"4-5 hours\", \"5-6 hours\", \"6+ hours\"], \"y\": [91460, 1120341, 854839, 342191, 161562, 111749, 49938]}],\n                        {\"barmode\": \"stack\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Flight Counts by CRS_Elapsed_Time_binlabel & Dep_Del30\"}, \"xaxis\": {\"title\": {\"text\": \"CRS_Elapsed_Time_binlabel\"}, \"type\": \"category\"}, \"yaxis\": {\"title\": {\"text\": \"Number of Flights\"}}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":14},{"cell_type":"markdown","source":["By doing this kind of binning, we can see that the same general shape of the distribution is preserved, albeit at a coarser level, which removes some of the extra information that was present in the original variable. But doing this kind of aggregation has its benefits in terms of reducing the noise from the signal when it comes to modeling. \n\nIn the case of Logistic Regression, if we had referred to the original `CRS_Elapsed_Time`, we would estimate a single coefficient for the variable, which would tell us the effect that adding 1 minute to the elapsed time would have on the probability that a flight is delayed. However, if we were to bin this variable and treat the result as a categorical variable in our regression, the model would estimate a coefficient for all but one of the bins, which would tell us more detailed information about the effect of a flight having a certain kind of duration (e.g. 1-2 hours). By comparison to the coefficient we'd estimate on the raw `CRS_Elapsed_Time`, this would be a much more meaningful estimate to use to understand the underlying factors for departure delays. This will require the algorithm to have to learn more coefficients than if the original `CRS_Elapsed_Time` were to be used, but to answer our core question, it seems to be a worthwhile cost if we proceed with Logistic Regression as our model of choice.\n\nFor the case of Decision Trees, binning the `CRS_Elapsed_Time` will actually help to improve the scalability of the algorithm. If we are to use the raw `CRS_Elapsed_Time`, the decision tree algorithm will have to consider every possible split for the feature (as we'll see later, there are in fact 646 distinct values for the `CRS_Elapsed_Time` feature, meaning that the algorithm would have to consider 645 different splits when finding the best split). However, if we bin the feature as shown above, the number of splits the algorithm needs to consider drops to just 6, which is a large reduction in the amount of work the algorithm needs to do to find the best split, which will help with the scalability of the algorithm.\n\nThe benefits that come with binning `CRS_Elapsed_Time` can really extend to all our continuous variables. The `Distance_Group` already takes care of this for the feature `Distance` and in section III, we will take care bin the remaining continuous variable depending on the situation."],"metadata":{}},{"cell_type":"markdown","source":["### EDA Task #2: Ordering Categorical Features\nAmong the features we have to consider, there are three that are categorical in nature, namely `Op_Unique_Carrier`, `Origin`, and `Dest`. While some features such as `Op_Unique_Carrier` have only a few distinct values (19 in total), others such as `Origin` and `Dest` have many more distinct values (364 each). While these categorical features are meaningful to us, they can introduce some added difficulties to our models for training.\n\nIn the case of Support Vector Machines, each of these categorical features will have to be encoded with 1-hot encoding, where we generate a sparse vector of a length equal to the number of unique values in the categorical feature. For `Op_Unique_Carrier`, this would lead to the algorithm to have to consider a 19-dimensional space. Take it to `Origin` or `Dest` and these features alone will require considering a 364-dimensional space, which makes it difficult for the algorithm to scale.\n\nSimilarly for Logistic Regression, for a categorical feature with \\\\(n\\\\) distinct values, this will require estimating \\\\(n-1\\\\) unique coefficients--while these coefficients can be meaningful to us, the sheer number can be overwhelming to estimate from a scalability perspective. \n\nAnd with Decision Trees, the issue comes when considering the number of splits. If we take the `Op_Unique_Carrier` feature, because there are 19 values with no implicit order to them, when the Decision Tree algorithm considers all possible splits, it will have to consider not 18 splits, but \\\\(2^{k-1}-1 = 2^{19-1}-1 = 262,143\\\\) possible splits. Go even further to a categorical variable like `Origin` and the number becomes massive (\\\\(1.87 * 10^{109}\\\\) different splits to consider), which is computationally prohibitive to the algorithm as it will need to consider every single possible split to find the best split for the feature.\n\nIn order to address these issues, we'd really want to provide some sort of ordering and thus a ranking for each distinct value of our categorical features. Let's consider this in the context of our 'smaller' categorical variable, `Op_Unique_Carrier`. In its raw form, the distinct categories are in no way comparable (how does one compare 'DL' (Delta Airlines) to 'AS' (Alaska Airlines) in a meaningful way?). However, these categories could be compared using some intrinsic property of the category. Given that we're interested in using the information in `Op_Unique_Carrier` to predict our outcome `Dep_Del30`, we can evaluate what our average outcome is (or really the probability of a significant departure delay) for each variable and use this measure as a means of ordering the distinct categories. This ordering is shown in the plot below:"],"metadata":{}},{"cell_type":"code","source":["# Helper function that plot the probability of outcome on the x axis, the number of flights on the y axis\n# With entries for each distinct value of the feature as separate bars.\ndef MakeProbBarChart(full_data_dep, var, xtype, numDecimals):\n  # Filter out just to rows with delays or no delays\n  d_delay = full_data_dep.select(var, outcomeName).filter(F.col(outcomeName) == 1.0).groupBy(var, outcomeName).count().orderBy(\"count\")\n  d_nodelay = full_data_dep.select(var, outcomeName).filter(F.col(outcomeName) == 0.0).groupBy(var, outcomeName).count().orderBy(\"count\")\n\n  # Join tables to get probabilities of departure delay for each table\n  probs = d_delay.join(d_nodelay, d_delay[var] == d_nodelay[var]) \\\n             .select(d_delay[var], (d_delay[\"count\"]).alias(\"DelayCount\"), (d_nodelay[\"count\"]).alias(\"NoDelayCount\"), \\\n                     (d_delay[\"count\"] / (d_delay[\"count\"] + d_nodelay[\"count\"])).alias(\"Prob_\" + outcomeName))\n\n  # Join back with original data to get 0/1 labeling with probablities of departure delay as attribute of airlines\n  d = full_data_dep.select(var, outcomeName).groupBy(var, outcomeName).count()\n  d = d.join(probs, full_data_dep[var] == probs[var]) \\\n       .select(d[var], d[outcomeName], d[\"count\"], probs[\"Prob_\" + outcomeName]) \\\n       .orderBy(\"Prob_\" + outcomeName, outcomeName).toPandas()\n  d = d.round({'Prob_' + outcomeName: numDecimals})\n\n  t1 = go.Bar(\n    x = d[d[outcomeName] == 0.0][\"Prob_\" + outcomeName],\n    y = d[d[outcomeName] == 0.0][\"count\"],\n    name=outcomeName + \" = \" + str(0.0),\n    text=d[d[outcomeName] == 0.0][var]\n  )\n  t2 = go.Bar(\n    x = d[d[outcomeName] == 1.0][\"Prob_\" + outcomeName],\n    y = d[d[outcomeName] == 1.0][\"count\"],\n    name=outcomeName + \" = \" + str(1.0),\n    text=d[d[outcomeName] == 1.0][var]\n  )\n\n  l = go.Layout(\n    barmode='stack', \n    title=\"Flight Counts by \" + \"Prob_\" + outcomeName + \" & \" + outcomeName + \" for each \" + var,\n    xaxis=dict(title=\"Prob_\" + outcomeName + \" (Note: axis type = \" + xtype + \")\", type=xtype),\n    yaxis=dict(title=\"Number of Flights\")\n  )\n  fig = go.Figure(data=[t1, t2], layout=l)\n  fig.show()\n  return fig\n  \n# Plot Carrier and outcome with bar plots of probability on x axis\nfig = MakeProbBarChart(airlines, \"Op_Unique_Carrier\", xtype='category', numDecimals=5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"a189d418-a1da-48e2-bb8f-6f1fcb7bf0f3\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"a189d418-a1da-48e2-bb8f-6f1fcb7bf0f3\")) {\n                    Plotly.newPlot(\n                        'a189d418-a1da-48e2-bb8f-6f1fcb7bf0f3',\n                        [{\"name\": \"Dep_Del30 = 0.0\", \"text\": [\"HA\", \"AS\", \"DL\", \"US\", \"YX\", \"AA\", \"OO\", \"WN\", \"MQ\", \"9E\", \"UA\", \"EV\", \"G4\", \"OH\", \"YV\", \"VX\", \"NK\", \"F9\", \"B6\"], \"type\": \"bar\", \"x\": [0.03439, 0.07596, 0.08575, 0.08999, 0.11415, 0.11543, 0.11674, 0.11692, 0.12188, 0.12481, 0.12933, 0.1295, 0.12987, 0.13306, 0.13459, 0.13911, 0.13915, 0.168, 0.17293], \"y\": [385811, 955919, 4234666, 176745, 554425, 3821646, 3041108, 5732116, 770941, 425889, 2487306, 1467331, 173709, 474591, 371851, 186246, 668926, 446271, 1174579]}, {\"name\": \"Dep_Del30 = 1.0\", \"text\": [\"HA\", \"AS\", \"DL\", \"US\", \"YX\", \"AA\", \"OO\", \"WN\", \"MQ\", \"9E\", \"UA\", \"EV\", \"G4\", \"OH\", \"YV\", \"VX\", \"NK\", \"F9\", \"B6\"], \"type\": \"bar\", \"x\": [0.03439, 0.07596, 0.08575, 0.08999, 0.11415, 0.11543, 0.11674, 0.11692, 0.12188, 0.12481, 0.12933, 0.1295, 0.12987, 0.13306, 0.13459, 0.13911, 0.13915, 0.168, 0.17293], \"y\": [13742, 78583, 397159, 17478, 71442, 498688, 401933, 758961, 107005, 60736, 369480, 218282, 25926, 72840, 57829, 30094, 108126, 90113, 245583]}],\n                        {\"barmode\": \"stack\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Flight Counts by Prob_Dep_Del30 & Dep_Del30 for each Op_Unique_Carrier\"}, \"xaxis\": {\"title\": {\"text\": \"Prob_Dep_Del30 (Note: axis type = category)\"}, \"type\": \"category\"}, \"yaxis\": {\"title\": {\"text\": \"Number of Flights\"}}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":17},{"cell_type":"markdown","source":["By ordering the airline carriers by this average outcome (`Prob_Dep_Del30`), we can not only begin to compare the airlines (Alaska Airlines seems to be better than Delta Airlines by a small margin), but we can significantly reduce the number of splits to consider, from 262,143 possible splits to just 18 for `Op_Unique_Carrier` when it comes to the Decision Tree algorithm. Even further, if we assign numerical ranks, we have the potential to convert this categorical feature into a numerical feature (by assigning 1 to the highest ranked airline, 'HA' (Hawaiian Airlines), and 19 to the lowest ranked airline 'B6' (Jet Blue)), which helps to reduce the workload for both Logistic Regression and Support Vector Machines. \n\nThis data transformation essentially describes the application of Breiman's Theorem, which we can apply to all our categorical features, even the ones we feature engineer. Note that any ranking we generate for our categorical features will need to be generated based on our training set and separately applied to the test set, to ensure the ranking isn't in any way influenced by the data in our test set. We will proceed to apply this to all our categorical features in section III."],"metadata":{}},{"cell_type":"markdown","source":["### EDA Task #3: Balancing the Dataset\nFor our final EDA task, let's consider our outcome variable `Dep_Del30`. To ensure that our model is able to adequately predict whether a flight will be delayed, we need to make sure there is a good representation of both classes in the training set. However, as is evident in the pie chart below, we clearly have an over-representation of the no-delay category (`Dep_Del30 == 0`)."],"metadata":{}},{"cell_type":"code","source":["# Look at balance for outcome in training\ndisplay(train_and_val.groupBy(outcomeName).count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Dep_Del30</th><th>count</th></tr></thead><tbody><tr><td>1</td><td>2732080</td></tr><tr><td>0</td><td>21173764</td></tr></tbody></table></div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["What this chart tells us is that a simple model that always predicts no departure delay will have a high accuracy of around 89% (assuming our test set has a similar distribution). But of course, simply predicting the majority class is meaningless when it comes to answering our core question--all it really tells us is that most flights are not delayed.\n\nBut the problem extends further. Even if we develop a model that doesn't always predict no departure delay as a simple baseline model would, there is still a major problem of bias if we leave the dataset unbalanced. Namely, if the dataset is unbalanced, the model will still favor the majority class and learn features of majority class well at the expense of the minority class, which will come at a cost to model performance. Regardless of which of our four algorithms we'll concentrate on, this data imbalance is a concern that we'll need to address. There are a variety of methods that we can use to deal with this data imbalance (including majority class undersampling, minority class oversampling, SMOTE, majority class splitting), which we will discuss the theory, implementation, and scalability concerns at the end of section III. Any method that will balance the dataset will help to reduce bias, coming at a cost to inducing more variance in the model. However, for the purpose of developing a model that can help inform the likely causes of departure delays, this is a worthwhile tradeoff."],"metadata":{}},{"cell_type":"markdown","source":["### Further EDA\nDuring the investigation of our dataset, we did a deep dive to examine all of our in-scope variables from the original dataset to understand the nature of the dataset and help inform our decision making. To see more plots and discussion, please refer to our more extensive EDA linked below. We will also explore some more of these plots in the next section.\n\nhttps://dbc-b1c912e7-d804.cloud.databricks.com/?o=7564214546094626#notebook/3895804345790408/command/3895804345790409"],"metadata":{}},{"cell_type":"markdown","source":["## III. Feature Engineering\nWith the EDA discussion from the previous section in mind, we now proceed with applying the feature engineering described in the previous section. We will first look at summary statistics and check for missing values for each of our features for predicting departure delays. We'll then look to binning our numerical features, adding additional features via interactions, bringing in additional datasets, and looking at aggregated statistics. For the categorical features in the dataset (both original and those developed from an feature transformations), we will apply Breiman's Theorem to order these features and transform them into numerical features. Finally, we'll take a closer look at the data preprocessing techniques we will explore for balancing our dataset."],"metadata":{}},{"cell_type":"markdown","source":["### Summary Statistics & Missing Values Assessment\nIn the table shown below, we can see a set of summary statistics for each base feature, including general summary statistics (count, mean, standard deviation, min, max), as well as the number of distinct values and the number of null/missing values in the training & validation set. Based on the results shown below, all values appear to fall into the expected ranges based on the definitions of these features."],"metadata":{}},{"cell_type":"code","source":["def GetStats(df):\n  allCols = [outcomeName] + numFeatureNames + contNumFeatureNames + catFeatureNames\n\n  # Get summary stats for the full training dataset\n  summaryStats = df.select(allCols).describe().select(['summary'] + allCols)\n\n  # Get number of distinct values for each column in full training dataset\n  distinctCount = df.select(allCols) \\\n                               .agg(*(F.countDistinct(F.col(c)).alias(c) for c in allCols)) \\\n                               .withColumn('summary', F.lit('distinct count')) \\\n                               .select(['summary'] + allCols)\n\n  # Get number of nulls for each column in full training dataset\n  nullCount = df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in allCols]) \\\n                .withColumn('summary', F.lit('null count')) \\\n                .select(['summary'] + allCols)\n\n  # Union all statistics to single display\n  res = summaryStats.union(distinctCount.union(nullCount))\n  display(res)\n  \nGetStats(train_and_val)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>summary</th><th>Dep_Del30</th><th>Year</th><th>Month</th><th>Day_Of_Month</th><th>Day_Of_Week</th><th>Distance_Group</th><th>CRS_Dep_Time</th><th>CRS_Arr_Time</th><th>CRS_Elapsed_Time</th><th>Distance</th><th>Op_Unique_Carrier</th><th>Origin</th><th>Dest</th></tr></thead><tbody><tr><td>count</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td><td>23905844</td></tr><tr><td>mean</td><td>0.11428502587066158</td><td>2016.5862149439274</td><td>6.558258725356026</td><td>15.767601972137022</td><td>3.9362873780988448</td><td>3.799711401111795</td><td>1329.1912870760807</td><td>1489.10282774371</td><td>143.79028157299112</td><td>831.9439977103507</td><td>null</td><td>null</td><td>null</td></tr><tr><td>stddev</td><td>0.31815713565262305</td><td>1.1456243075500832</td><td>3.3955166330828477</td><td>8.780397027264396</td><td>1.990154916949751</td><td>2.4127113295500706</td><td>488.73713112947934</td><td>515.1422717263274</td><td>75.54544710770968</td><td>612.9232441359027</td><td>null</td><td>null</td><td>null</td></tr><tr><td>min</td><td>0</td><td>2015</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td><td>-99.0</td><td>28.0</td><td>9E</td><td>ABE</td><td>ABE</td></tr><tr><td>max</td><td>1</td><td>2018</td><td>12</td><td>31</td><td>7</td><td>11</td><td>2359</td><td>2400</td><td>718.0</td><td>4983.0</td><td>YX</td><td>YUM</td><td>YUM</td></tr><tr><td>distinct count</td><td>2</td><td>4</td><td>12</td><td>31</td><td>7</td><td>11</td><td>1423</td><td>1440</td><td>646</td><td>1609</td><td>19</td><td>364</td><td>364</td></tr><tr><td>null count</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["The only odd value seems to be the minimum value for `CRS_Elapsed_Time` that takes on a value of -99.0. Upon closer inspection, there's no true indication for why this datapoint is negative, except that it is likely a mistake in the dataset, since the difference in the departure and arrival times is 76 minutes, which should be the actual value of `CRS_Elapsed_Time`. However, given that we have about 24 million data points to train from, having this single data point be slightly incorrect should not affect the results of our training. For this reason, we'll leave the data point unchanged.\n\nFinally, note that we do not appear to have any null values in our training and validation data and thus we will not need to handle missing values for the purpose of training. However, there is a potential that our test data has missing values and or the features of the test data take on values that were not seen in the training data. Because this is always a possibility at inference time, we will need to make sure our data transformations are robust to such cases--we will evaluate this on a case-by-case basis."],"metadata":{}},{"cell_type":"markdown","source":["### Binning Continuous Numerical Features\nAs discussed in task #1 of the EDA in section II, one of the transformations we'd like to apply to our continuous numerical features is a binning transformation. In doing so, we can reduce the continuous variables to meaningful increments that will help with interpretability in Logistic Regression and help to reduce the number of splits that needs to be considered by the Decision Tree algorithm. In order to determine reasonable split points, let's evaluate the distributions of each of the continuous variables `CRS_Dep_Time`, `CRS_Arr_Time`, and `CRS_Elapsed_Time` (note that the continuous feature `Distance` has already been binned via the variable `Distance_Group`, so we will not examine this feature). These distribution are shown below (please zoom in for more detail):"],"metadata":{}},{"cell_type":"code","source":["fig1 = MakeRegBarChart(train_and_val, outcomeName, 'CRS_Dep_Time', orderBy='CRS_Dep_Time', barmode='stack', xtype='linear')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"147d4b4c-f609-408b-b909-8adc066ca1b8\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"147d4b4c-f609-408b-b909-8adc066ca1b8\")) {\n                    Plotly.newPlot(\n                        '147d4b4c-f609-408b-b909-8adc066ca1b8',\n                        [{\"name\": \"Dep_Del30 = 0.0\", \"type\": \"bar\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 215, 216, 217, 219, 220, 222, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 253, 255, 256, 257, 258, 259, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 400, 401, 403, 406, 407, 408, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 434, 435, 436, 438, 439, 440, 441, 443, 444, 445, 446, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359], \"y\": [256, 82, 132, 207, 2070, 130, 254, 98, 209, 1675, 155, 192, 207, 211, 4337, 113, 122, 160, 197, 2060, 103, 254, 249, 98, 2777, 60, 441, 136, 208, 6619, 142, 150, 133, 332, 3539, 129, 272, 330, 289, 3776, 347, 222, 230, 208, 6334, 348, 295, 302, 161, 3641, 229, 533, 182, 266, 5941, 349, 420, 590, 3925, 1004, 292, 153, 171, 145, 1101, 124, 155, 106, 148, 1916, 160, 92, 131, 180, 3245, 37, 52, 149, 104, 1506, 62, 47, 79, 58, 1215, 105, 93, 29, 93, 1793, 86, 90, 29, 7, 389, 58, 47, 12, 306, 22, 6, 34, 173, 1346, 62, 22, 62, 28, 698, 73, 20, 23, 25, 2064, 114, 101, 195, 286, 482, 122, 7, 49, 143, 354, 101, 55, 48, 6, 275, 7, 47, 137, 3, 41, 19, 154, 12, 38, 8, 194, 35, 30, 28, 272, 46, 60, 1, 163, 18, 38, 179, 94, 291, 15, 54, 37, 3, 412, 155, 11, 1, 292, 48, 34, 1, 347, 145, 45, 36, 292, 177, 39, 12, 12, 76, 97, 101, 95, 25, 29, 81, 42, 76, 1, 75, 77, 112, 47, 5, 16, 137, 25, 37, 92, 32, 25, 4, 27, 40, 100, 241, 69, 29, 43, 104, 206, 5, 4, 50, 58, 113, 43, 11, 2, 2, 112, 25, 46, 2, 58, 27, 59, 19, 3, 57, 33, 17, 5, 85, 207, 41, 33, 24, 33, 18, 2, 143, 13, 23, 38, 124, 13, 42, 5, 39, 144, 52, 9, 73, 28, 90, 12, 81, 70, 21, 44, 1, 28, 4, 42, 10, 45, 49, 19, 7, 40, 3, 66, 2, 1, 28, 53, 22, 80, 3, 5, 75, 3, 67, 10, 3, 41729, 2553, 1167, 1524, 1861, 11830, 780, 1052, 906, 1112, 13797, 909, 954, 651, 1248, 29424, 850, 803, 907, 1404, 20237, 1078, 733, 1004, 1392, 18665, 1138, 1218, 1554, 1741, 71868, 951, 1241, 1379, 1542, 33061, 1466, 1384, 1586, 1942, 40760, 1169, 1509, 1986, 2467, 70778, 1803, 2120, 1441, 2393, 48774, 2122, 2032, 2482, 2826, 35881, 2500, 2765, 2103, 5685, 437710, 8281, 6426, 6161, 6183, 93949, 5114, 5195, 5323, 4801, 86245, 4782, 5183, 3436, 6056, 113473, 4272, 4293, 4108, 4593, 88151, 4456, 4652, 4027, 3915, 69604, 3877, 4516, 4628, 6785, 149682, 3250, 3718, 3375, 3690, 62266, 3824, 4049, 3969, 3608, 66605, 3078, 2774, 3527, 3702, 95187, 2868, 3635, 3143, 3813, 69382, 3489, 3622, 3137, 4949, 60885, 3330, 3922, 5556, 16561, 321826, 8107, 7254, 5823, 7265, 96061, 5403, 5351, 5581, 5428, 100512, 4561, 6183, 3893, 5868, 102459, 4554, 4876, 4432, 5016, 83153, 4392, 4755, 4021, 5673, 79902, 6278, 5809, 4861, 10199, 135146, 5717, 6034, 4359, 4870, 68458, 5699, 5482, 5342, 4824, 64365, 4285, 4339, 4159, 5132, 89136, 4414, 4143, 3223, 5698, 69291, 3918, 4794, 4395, 4111, 67455, 4268, 5244, 4701, 16433, 197993, 6448, 5614, 4874, 5719, 75192, 5416, 5365, 4733, 5707, 87816, 5913, 6552, 4397, 6275, 97202, 7395, 4901, 5830, 6443, 90509, 6989, 5544, 5086, 4996, 86919, 6216, 5903, 5303, 7615, 137089, 7258, 6816, 6726, 6821, 85299, 7356, 7016, 6260, 7418, 74310, 7095, 5734, 5053, 7163, 102201, 7468, 6348, 5850, 5865, 73447, 6243, 5359, 4616, 5422, 80464, 6140, 4951, 6777, 14848, 146622, 8323, 7225, 5211, 5461, 80868, 7883, 8183, 6264, 7200, 74889, 4671, 7698, 5437, 7062, 71359, 6606, 6078, 6934, 7898, 65500, 5792, 5865, 5725, 6648, 56139, 4982, 4938, 5128, 8837, 87764, 6212, 6234, 5043, 6313, 68030, 5920, 5509, 5689, 9335, 77724, 8173, 7963, 7673, 7835, 86776, 9565, 8310, 7696, 8714, 78966, 9446, 7588, 6701, 6691, 84715, 10149, 7987, 8713, 17733, 125736, 9616, 10695, 9064, 8066, 78100, 10755, 8348, 8047, 7976, 72682, 7826, 7859, 5641, 7633, 93947, 8743, 7591, 8159, 8358, 80128, 7723, 6754, 6005, 7094, 79693, 9829, 9319, 7944, 9811, 93092, 7695, 7070, 6384, 6373, 65088, 6578, 6069, 6311, 5507, 76206, 6865, 7324, 6135, 6834, 72488, 6020, 7334, 6297, 8122, 71303, 9298, 8346, 8002, 7656, 67726, 8030, 7377, 6824, 14478, 120808, 9404, 9609, 7700, 7372, 80371, 9779, 8414, 7025, 8345, 70435, 7760, 9413, 6629, 8715, 86019, 10554, 9523, 7931, 9031, 77862, 9827, 9022, 7613, 7129, 76239, 9261, 7510, 7282, 9760, 94909, 8505, 7190, 7540, 6485, 70077, 8228, 7024, 7238, 6654, 68676, 7511, 6351, 6234, 7331, 74879, 7855, 6109, 7563, 7858, 67195, 6583, 6673, 5986, 8643, 75829, 6603, 6038, 6419, 13328, 117733, 7304, 7966, 6343, 7401, 77984, 10278, 7547, 7682, 8440, 71981, 8820, 8509, 6347, 6993, 84970, 9373, 8025, 6801, 7667, 72642, 6963, 7912, 7587, 7270, 66085, 7822, 8049, 7479, 9043, 90661, 9031, 7818, 7102, 6860, 66832, 7974, 7764, 6938, 6795, 65958, 7201, 7490, 6258, 7428, 80829, 7809, 7376, 7986, 7518, 75143, 7682, 8063, 7216, 7367, 65111, 7432, 8274, 6591, 16383, 107207, 7541, 7375, 7438, 8210, 62504, 6837, 6517, 7444, 7175, 64587, 7867, 7732, 5247, 7228, 67447, 6960, 6472, 6428, 7850, 59734, 6302, 6190, 6430, 7597, 60832, 7237, 7049, 7034, 11354, 84551, 6886, 7313, 6766, 6605, 65584, 6751, 6534, 5838, 7887, 73261, 9263, 8540, 6681, 9797, 95375, 10388, 9668, 8540, 8648, 71440, 9890, 9325, 8198, 7836, 77571, 8232, 8203, 8088, 19026, 98440, 6665, 7911, 6486, 5671, 59357, 6970, 6150, 6408, 6774, 55785, 7348, 7268, 6329, 6811, 61632, 6567, 6579, 6950, 7695, 65474, 8148, 7647, 6907, 7246, 67065, 7975, 7438, 6491, 12605, 83469, 8255, 7461, 6821, 7382, 67146, 7760, 7339, 7208, 8467, 65507, 6658, 5941, 5590, 6953, 70410, 6014, 5276, 5399, 7667, 62073, 6018, 5601, 5702, 10636, 70295, 7546, 7702, 7067, 21629, 103386, 6667, 7880, 5840, 6990, 67505, 8975, 6709, 6581, 7657, 77321, 9593, 10017, 6056, 8225, 74289, 9947, 7520, 7605, 8584, 66425, 8284, 7363, 6851, 7884, 69561, 7921, 8113, 8048, 11924, 95750, 7421, 7932, 6454, 7695, 72947, 8467, 7755, 7691, 7222, 63220, 6577, 8463, 7551, 7651, 71083, 7570, 7245, 6861, 7226, 66413, 7251, 7616, 7220, 6317, 64821, 6803, 6726, 6377, 17438, 92489, 6954, 7891, 6739, 5954, 58552, 6488, 5815, 6743, 6983, 60408, 6517, 6638, 4875, 7057, 59468, 5980, 5475, 4535, 7028, 63983, 8602, 6654, 7600, 7548, 62987, 7707, 6708, 7759, 11591, 84190, 8623, 7290, 6142, 7672, 64226, 7931, 6523, 6375, 7359, 64015, 7401, 7169, 6504, 8746, 70208, 6953, 6380, 6025, 8691, 62609, 6433, 6885, 5793, 7607, 71481, 7362, 8093, 6561, 22636, 108584, 6576, 6681, 6163, 6588, 72418, 7798, 5989, 6655, 7750, 65477, 6027, 7292, 5190, 6604, 73438, 7047, 6861, 6689, 6607, 65374, 6328, 7200, 6036, 6072, 66247, 6771, 6921, 7518, 11445, 95247, 7669, 8946, 7215, 8215, 79035, 8551, 9222, 8461, 9336, 73099, 8244, 9497, 8184, 9658, 85624, 9693, 8550, 7957, 9460, 73688, 8152, 9693, 9075, 10151, 77754, 7448, 8656, 7705, 27289, 88665, 5651, 6125, 5717, 7034, 61968, 5706, 5404, 5882, 7542, 57326, 5540, 6036, 6403, 6487, 66869, 6527, 6389, 6834, 7762, 63073, 5487, 6208, 6592, 7350, 67349, 6607, 4986, 5328, 11612, 80149, 5330, 6582, 5472, 6052, 56342, 4947, 4123, 4866, 6108, 57826, 4678, 5154, 4943, 5231, 68577, 5262, 5476, 5480, 6630, 67576, 5768, 6196, 4262, 5901, 74177, 6786, 6094, 5950, 22999, 73711, 6306, 7294, 5004, 6680, 49681, 5334, 6232, 5783, 6578, 57422, 5993, 8076, 4726, 7633, 62626, 7637, 6659, 6108, 6305, 54453, 6185, 6293, 5674, 5287, 57513, 7250, 6296, 6078, 11072, 71758, 6501, 6195, 5427, 5728, 57632, 6388, 5546, 5067, 5836, 62618, 5985, 6024, 5237, 6375, 68076, 5566, 4889, 5151, 7234, 62912, 7039, 7181, 6196, 8422, 75022, 7158, 6900, 6791, 27580, 79268, 5577, 6480, 5556, 6654, 62211, 6978, 5112, 5470, 7327, 61829, 5676, 5862, 4064, 6368, 68984, 6088, 5594, 4734, 7050, 65142, 5439, 4240, 4029, 5576, 58710, 5631, 4236, 4389, 9845, 66267, 4004, 3471, 2881, 4176, 49646, 3606, 3153, 2888, 3367, 47220, 3666, 3221, 2959, 2866, 44421, 3852, 1813, 2451, 2764, 42296, 3378, 3266, 2440, 2963, 47228, 3310, 3583, 2924, 12936, 46069, 3213, 2248, 1904, 2576, 36353, 4233, 4546, 3728, 4012, 32902, 3509, 4644, 2756, 3311, 38826, 4466, 3641, 3551, 4166, 31730, 3784, 3704, 2803, 2974, 28699, 3688, 3317, 2881, 5179, 39181, 3025, 2846, 1864, 2557, 29898, 2745, 2644, 2220, 3195, 31129, 2583, 2169, 2283, 3797, 39039, 3803, 2765, 2233, 4479, 37674, 3447, 2700, 2428, 2992, 52102, 3311, 3038, 3079, 12644, 49241, 2895, 2519, 2791, 3885, 38758, 3011, 2755, 2992, 6808, 42829, 3725, 3092, 1319, 3450, 38788, 3507, 1606, 2419, 2909, 37997, 3657, 2637, 2740, 3549, 28984, 3950, 2165, 2418, 4429, 36015, 3464, 2941, 2074, 2813, 22371, 3133, 2250, 1847, 2933, 24093, 2337, 1636, 1486, 2060, 21938, 1868, 1394, 1326, 1721, 15156, 1143, 1678, 1007, 1370, 16511, 1511, 996, 1306, 4078, 9888, 593, 817, 444, 523, 8983, 914, 712, 1227, 1204, 8080, 947, 1162, 722, 976, 11588, 679, 613, 958, 687, 8675, 659, 670, 576, 445, 6506, 786, 385, 395, 817, 10847, 1429, 1207, 1235, 867, 6176, 681, 708, 649, 772, 5455, 548, 337, 429, 906, 8155, 531, 438, 802, 1058, 7245, 512, 614, 942, 816, 12682, 1086, 1047, 1040, 21561]}, {\"name\": \"Dep_Del30 = 1.0\", \"type\": \"bar\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 135, 136, 137, 138, 140, 143, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 212, 213, 215, 216, 217, 219, 220, 223, 224, 225, 227, 228, 229, 230, 231, 232, 233, 235, 236, 237, 238, 239, 240, 241, 242, 243, 245, 246, 247, 250, 251, 252, 254, 255, 256, 257, 258, 259, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 338, 339, 340, 341, 342, 345, 346, 347, 350, 351, 352, 353, 355, 356, 357, 359, 400, 401, 405, 406, 407, 408, 409, 410, 411, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 432, 434, 435, 436, 438, 439, 440, 441, 443, 445, 449, 450, 451, 452, 455, 456, 457, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359], \"y\": [34, 11, 50, 42, 312, 22, 43, 20, 13, 262, 23, 40, 33, 16, 476, 23, 15, 24, 20, 306, 15, 48, 36, 11, 241, 7, 74, 6, 28, 652, 13, 32, 34, 40, 301, 14, 31, 38, 54, 406, 32, 24, 25, 22, 466, 34, 52, 59, 21, 392, 30, 58, 43, 21, 655, 65, 41, 111, 540, 82, 62, 21, 26, 11, 95, 1, 9, 4, 15, 170, 13, 4, 18, 7, 303, 10, 5, 9, 90, 4, 6, 9, 11, 145, 5, 4, 12, 16, 163, 18, 5, 10, 57, 1, 18, 11, 25, 2, 18, 174, 14, 7, 30, 24, 73, 25, 3, 7, 228, 10, 46, 38, 36, 103, 41, 3, 5, 14, 42, 21, 28, 31, 2, 51, 1, 25, 5, 1, 4, 8, 17, 4, 3, 11, 2, 5, 3, 47, 17, 4, 3, 26, 2, 6, 51, 20, 41, 3, 10, 8, 60, 35, 2, 42, 4, 4, 1, 53, 40, 9, 7, 53, 41, 8, 7, 1, 16, 39, 25, 25, 8, 3, 25, 2, 7, 20, 10, 44, 9, 2, 1, 6, 13, 5, 19, 1, 7, 1, 10, 8, 8, 57, 14, 9, 3, 23, 67, 5, 5, 25, 10, 3, 42, 15, 23, 12, 15, 2, 6, 17, 4, 2, 48, 70, 5, 1, 5, 4, 7, 2, 13, 5, 3, 4, 9, 1, 6, 1, 5, 29, 4, 2, 12, 5, 7, 1, 9, 13, 2, 3, 5, 3, 3, 1, 11, 4, 3, 1, 4, 16, 12, 4, 3, 24, 3, 1, 12, 1852, 93, 63, 90, 68, 495, 63, 88, 43, 40, 614, 52, 39, 40, 32, 1044, 42, 36, 24, 52, 647, 29, 34, 42, 85, 625, 81, 57, 85, 99, 2423, 52, 60, 61, 63, 1069, 71, 49, 87, 87, 1323, 60, 78, 86, 132, 2375, 91, 109, 70, 116, 1736, 95, 99, 122, 114, 1192, 103, 129, 120, 261, 18027, 434, 357, 301, 306, 3703, 246, 250, 287, 251, 3261, 217, 230, 173, 261, 4243, 216, 234, 202, 251, 3276, 213, 288, 202, 201, 2607, 211, 259, 240, 371, 6369, 162, 209, 182, 206, 2379, 238, 213, 239, 232, 2711, 200, 165, 213, 224, 3736, 183, 218, 188, 222, 3064, 187, 193, 183, 266, 2638, 197, 218, 296, 1018, 15402, 483, 440, 371, 466, 4916, 275, 333, 393, 352, 5282, 334, 392, 265, 395, 5407, 296, 298, 266, 344, 4445, 319, 381, 309, 382, 4399, 365, 320, 304, 668, 8019, 359, 391, 334, 297, 3907, 351, 354, 310, 322, 3757, 279, 299, 269, 368, 5308, 257, 265, 221, 372, 4305, 266, 336, 391, 320, 3822, 344, 399, 368, 1081, 13465, 493, 430, 393, 423, 4917, 437, 412, 297, 364, 5727, 427, 456, 346, 440, 6270, 481, 308, 349, 504, 5865, 523, 383, 387, 417, 5718, 512, 487, 437, 626, 9436, 527, 550, 520, 602, 5723, 590, 549, 482, 652, 5274, 529, 495, 416, 666, 7365, 595, 577, 463, 467, 5582, 549, 466, 392, 441, 6109, 446, 472, 552, 1230, 11615, 826, 577, 540, 527, 6989, 610, 763, 576, 748, 6267, 413, 747, 524, 571, 6033, 569, 523, 575, 617, 5368, 516, 564, 523, 561, 4489, 478, 406, 495, 790, 7147, 559, 583, 459, 529, 5219, 528, 508, 436, 846, 5787, 569, 578, 621, 639, 6732, 777, 690, 711, 742, 6512, 728, 635, 575, 604, 6959, 852, 740, 779, 1586, 10974, 808, 920, 853, 763, 6557, 961, 765, 687, 752, 6498, 766, 779, 534, 679, 8368, 878, 786, 790, 865, 7175, 784, 690, 604, 772, 7249, 941, 946, 844, 905, 8927, 710, 697, 698, 707, 6042, 727, 667, 722, 647, 8456, 834, 862, 759, 868, 7259, 680, 898, 728, 903, 7077, 894, 848, 881, 851, 6779, 815, 818, 637, 1545, 11765, 992, 992, 899, 899, 7725, 1013, 909, 874, 874, 7264, 829, 955, 744, 932, 8944, 1171, 1040, 782, 1016, 7491, 1075, 1072, 903, 757, 7802, 1105, 955, 974, 1059, 9898, 972, 854, 891, 793, 7560, 891, 889, 951, 812, 7098, 891, 848, 817, 911, 7943, 833, 751, 885, 997, 7143, 850, 807, 687, 1056, 8214, 760, 745, 816, 1452, 13103, 873, 1002, 723, 895, 8287, 1005, 876, 896, 883, 7804, 864, 937, 743, 896, 9554, 1206, 960, 916, 994, 8566, 1009, 1032, 920, 999, 7915, 1052, 1076, 1012, 1236, 10575, 1145, 961, 922, 878, 8051, 994, 981, 825, 966, 7903, 934, 923, 902, 898, 9609, 1107, 984, 1009, 1072, 9165, 901, 1142, 1059, 895, 8377, 922, 991, 834, 2121, 13364, 997, 998, 1000, 982, 7709, 946, 847, 926, 946, 8191, 997, 1024, 739, 1011, 8422, 1052, 938, 985, 1095, 8081, 872, 880, 998, 1011, 7994, 962, 890, 981, 1806, 10847, 880, 1011, 969, 939, 8789, 1073, 1004, 790, 1222, 9288, 1154, 1124, 848, 1239, 11981, 1389, 1314, 1039, 1235, 9273, 1188, 1219, 1139, 1057, 10152, 1124, 1146, 1104, 2701, 14031, 1020, 1100, 907, 892, 8386, 1090, 913, 908, 998, 7948, 1086, 1055, 1046, 1019, 9051, 1064, 1037, 1027, 1272, 9454, 1302, 1224, 1152, 1081, 9731, 1119, 1228, 1073, 1956, 11955, 1303, 1062, 1020, 1295, 9445, 1187, 1179, 1070, 1246, 9586, 1053, 961, 981, 1147, 10063, 963, 775, 809, 1141, 9603, 1078, 904, 886, 1467, 10249, 1119, 1095, 1107, 3421, 15130, 1115, 1218, 934, 1126, 10443, 1284, 1106, 1034, 1232, 11906, 1328, 1545, 965, 1271, 11343, 1403, 1115, 1155, 1324, 10118, 1355, 1127, 1026, 1304, 10580, 1433, 1361, 1207, 2117, 14795, 1202, 1424, 1153, 1257, 11608, 1317, 1119, 1288, 1261, 10394, 1037, 1329, 1317, 1237, 11842, 1331, 1196, 1011, 1233, 10976, 1350, 1249, 1357, 1162, 10568, 1071, 1144, 1151, 2999, 16019, 1243, 1331, 1236, 1136, 10237, 1199, 935, 1100, 1290, 10391, 1085, 1114, 874, 1170, 9978, 1065, 950, 810, 1266, 10702, 1491, 1165, 1215, 1405, 10725, 1370, 1137, 1282, 2400, 14294, 1456, 1376, 1006, 1558, 10635, 1381, 1231, 1104, 1304, 11252, 1164, 1305, 1204, 1543, 11887, 1222, 1070, 1002, 1691, 10944, 1068, 1089, 1099, 1328, 12827, 1295, 1407, 1286, 3958, 20059, 1115, 1236, 1287, 1308, 13230, 1419, 1139, 1411, 1391, 12481, 1251, 1388, 1068, 1293, 13840, 1350, 1409, 1228, 1318, 12561, 1186, 1360, 1247, 1391, 12893, 1478, 1397, 1587, 2664, 17551, 1572, 1679, 1486, 1469, 14308, 1603, 1751, 1588, 1856, 13843, 1592, 1859, 1614, 1989, 15772, 1867, 1635, 1507, 1759, 14074, 1594, 1774, 1708, 1807, 14793, 1462, 1709, 1480, 5626, 18441, 1313, 1289, 1187, 1557, 12717, 1366, 1034, 1239, 1654, 12021, 1277, 1254, 1311, 1368, 13857, 1417, 1370, 1496, 1655, 13566, 995, 1212, 1281, 1530, 14606, 1275, 1119, 1230, 2823, 17489, 1078, 1403, 1091, 1175, 12443, 983, 1045, 992, 1332, 12776, 931, 1073, 1068, 1109, 15236, 1289, 1122, 1118, 1418, 14444, 1412, 1177, 885, 1268, 15598, 1275, 1268, 1350, 5206, 17548, 1401, 1389, 1189, 1347, 11735, 1113, 1215, 1261, 1323, 12460, 1370, 1631, 1062, 1489, 13554, 1433, 1233, 1196, 1420, 11449, 1197, 1315, 1256, 1229, 12272, 1577, 1435, 1449, 2768, 15611, 1297, 1224, 1125, 1394, 12516, 1249, 1146, 1131, 1357, 13560, 1243, 1219, 1051, 1306, 14922, 1140, 957, 1119, 1545, 13226, 1427, 1410, 1203, 1611, 15342, 1524, 1328, 1340, 6293, 18331, 1099, 1205, 983, 1351, 13532, 1464, 1052, 995, 1368, 12983, 1078, 1070, 749, 1212, 14435, 1265, 994, 940, 1429, 13760, 1006, 863, 686, 1161, 13193, 1082, 748, 1030, 2353, 14582, 747, 789, 721, 857, 11245, 736, 741, 561, 736, 10519, 812, 718, 611, 642, 10113, 864, 476, 579, 729, 10142, 792, 656, 585, 641, 10805, 714, 800, 656, 3559, 11370, 710, 480, 429, 640, 7693, 870, 837, 623, 823, 7291, 677, 939, 539, 671, 7828, 902, 690, 624, 730, 6319, 697, 618, 586, 578, 6013, 633, 660, 540, 1308, 8356, 559, 572, 325, 493, 6383, 612, 555, 457, 595, 6272, 572, 447, 475, 720, 7139, 692, 602, 395, 864, 6996, 440, 531, 513, 474, 9355, 507, 630, 592, 2969, 8490, 443, 392, 351, 555, 6998, 455, 519, 390, 1151, 7808, 623, 475, 241, 552, 7023, 491, 352, 380, 498, 6808, 494, 427, 358, 599, 5604, 563, 354, 428, 816, 6046, 506, 440, 317, 464, 4124, 509, 349, 297, 432, 4448, 316, 243, 295, 403, 4235, 346, 176, 230, 435, 2771, 191, 252, 165, 174, 3410, 257, 133, 178, 699, 1486, 80, 71, 85, 107, 1246, 175, 72, 211, 220, 1138, 160, 205, 149, 166, 1679, 131, 125, 143, 120, 1138, 148, 173, 124, 78, 911, 179, 94, 87, 158, 1495, 258, 194, 197, 142, 889, 99, 153, 170, 146, 738, 78, 48, 80, 183, 1021, 119, 135, 214, 175, 1010, 127, 103, 190, 231, 1559, 242, 213, 199, 4244]}],\n                        {\"barmode\": \"stack\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Flight Counts by CRS_Dep_Time & Dep_Del30\"}, \"xaxis\": {\"title\": {\"text\": \"CRS_Dep_Time\"}, \"type\": \"linear\"}, \"yaxis\": {\"title\": {\"text\": \"Number of Flights\"}}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":28},{"cell_type":"code","source":["fig2 = MakeRegBarChart(train_and_val, outcomeName, 'CRS_Arr_Time', orderBy='CRS_Arr_Time', barmode='stack', xtype='linear')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"d1fe33ec-0c9d-4628-9f34-d2fb3e2d9c4d\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"d1fe33ec-0c9d-4628-9f34-d2fb3e2d9c4d\")) {\n                    Plotly.newPlot(\n                        'd1fe33ec-0c9d-4628-9f34-d2fb3e2d9c4d',\n                        [{\"name\": \"Dep_Del30 = 0.0\", \"type\": \"bar\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2400], \"y\": [5545, 4720, 4437, 4164, 19793, 5137, 3889, 4147, 5420, 14473, 3785, 4247, 4023, 4494, 15865, 3894, 2831, 3362, 3301, 11294, 3500, 3252, 3274, 3184, 11855, 4192, 3360, 3093, 3384, 12424, 2403, 2630, 2343, 2102, 8122, 2183, 2486, 1847, 2836, 8997, 1933, 2227, 2520, 2635, 8622, 1455, 1490, 1768, 1668, 7705, 1822, 1307, 1219, 1710, 11346, 1670, 1760, 1761, 2702, 4812, 770, 699, 612, 1031, 3023, 807, 702, 841, 820, 2787, 702, 850, 763, 609, 2327, 451, 885, 914, 775, 2135, 398, 843, 624, 478, 2122, 555, 452, 406, 506, 1732, 514, 259, 466, 326, 1513, 559, 593, 309, 275, 1526, 315, 299, 224, 351, 1402, 404, 359, 429, 326, 1075, 275, 231, 226, 246, 2115, 381, 255, 502, 541, 650, 307, 288, 333, 486, 279, 308, 258, 225, 229, 394, 362, 399, 299, 279, 348, 318, 84, 368, 327, 429, 270, 269, 355, 250, 145, 52, 226, 282, 67, 102, 52, 84, 71, 158, 75, 151, 101, 101, 93, 149, 83, 98, 151, 55, 93, 36, 168, 83, 47, 98, 49, 11, 12, 30, 52, 57, 21, 69, 108, 43, 45, 21, 114, 59, 47, 72, 61, 98, 68, 35, 53, 29, 39, 116, 70, 53, 181, 99, 75, 43, 39, 40, 80, 65, 114, 42, 24, 69, 24, 45, 11, 28, 6, 72, 37, 90, 100, 42, 148, 154, 94, 91, 75, 151, 172, 142, 123, 240, 108, 162, 171, 166, 157, 18, 73, 39, 7, 48, 45, 288, 66, 51, 79, 35, 165, 43, 16, 77, 158, 202, 147, 93, 221, 218, 146, 122, 236, 256, 386, 465, 199, 359, 454, 174, 402, 447, 181, 228, 281, 1380, 194, 396, 546, 640, 713, 225, 378, 504, 589, 724, 520, 542, 533, 858, 1186, 743, 690, 401, 723, 1267, 629, 910, 1100, 1092, 1616, 1408, 1255, 1391, 1628, 8072, 2541, 2960, 2025, 2396, 3237, 2104, 1995, 1962, 1683, 3175, 1776, 1718, 1928, 1329, 2455, 1332, 1729, 2050, 1495, 3577, 1220, 1435, 2124, 1793, 2720, 1303, 1586, 2003, 2269, 3098, 1454, 1781, 1794, 1731, 2856, 1726, 1452, 1880, 2193, 3461, 2255, 1933, 3142, 2730, 4301, 2825, 2634, 2498, 2570, 4302, 2770, 3268, 2481, 2946, 5120, 2388, 2784, 4102, 6098, 11700, 4306, 4467, 4874, 4922, 6530, 3425, 3949, 4299, 4837, 8527, 2905, 4247, 3691, 5060, 8478, 3648, 3125, 4245, 5811, 10290, 3087, 3667, 3512, 4668, 8720, 3177, 3125, 3491, 5930, 9550, 3471, 4127, 3699, 4691, 10798, 3989, 4523, 4257, 5199, 13293, 4379, 5099, 5276, 6001, 14037, 5286, 5912, 5700, 6240, 19672, 4256, 4669, 4275, 4604, 18913, 4336, 4326, 5010, 7266, 26081, 4626, 4263, 5382, 5771, 23517, 4573, 5231, 6074, 5926, 27441, 4981, 4811, 5532, 6934, 26716, 4710, 5944, 6351, 7484, 30483, 6159, 7770, 8391, 9580, 35135, 6761, 6978, 8046, 10584, 36061, 9054, 9503, 8635, 9262, 37067, 7554, 6199, 9306, 10414, 32499, 9580, 8836, 9527, 13534, 35911, 10348, 11353, 12592, 14505, 43080, 10720, 10282, 12434, 15417, 36324, 11911, 12886, 14172, 17022, 39445, 9964, 9706, 11876, 13532, 38508, 10589, 10846, 12674, 13420, 42301, 9768, 9932, 11106, 11433, 40171, 7883, 9126, 11324, 10953, 37515, 8712, 9819, 8895, 11153, 40694, 9267, 8993, 11176, 13285, 40833, 9879, 9261, 9594, 10151, 34341, 9562, 11433, 11745, 12181, 37524, 12599, 13047, 14113, 15549, 40660, 13989, 15813, 14914, 18383, 46874, 15871, 17477, 17494, 19342, 47934, 17119, 17682, 18015, 22625, 58646, 14693, 16669, 17536, 19330, 56216, 13584, 14520, 15201, 15231, 51770, 11954, 13826, 13033, 16304, 51121, 14186, 14038, 13756, 16598, 51640, 11681, 11614, 13293, 15610, 53704, 13781, 13302, 13966, 18136, 53298, 12049, 13211, 14403, 15414, 52165, 13358, 14003, 14169, 17553, 54836, 13491, 14814, 16034, 17852, 52706, 14664, 13947, 13553, 15498, 51683, 12109, 11347, 12243, 13938, 50733, 11690, 13647, 12982, 15957, 56303, 13912, 14414, 15499, 15780, 47578, 14044, 14813, 16050, 17491, 48534, 16079, 15402, 17185, 18725, 47726, 15781, 15781, 17931, 19630, 50278, 17820, 17407, 19141, 19081, 51001, 15687, 16313, 16134, 18218, 55684, 15874, 15092, 16740, 15988, 45541, 13788, 14838, 16739, 17659, 48347, 14471, 15137, 14396, 16619, 48635, 13256, 14565, 14919, 17031, 46696, 13659, 13682, 14206, 14521, 46766, 14586, 13634, 14556, 17969, 56015, 14549, 14529, 15974, 16460, 47644, 13905, 14739, 14356, 18162, 48239, 14833, 15737, 17804, 18661, 49152, 15165, 16375, 16752, 19500, 52044, 16414, 15380, 17927, 20684, 53120, 14347, 16721, 16535, 22131, 57691, 12662, 12768, 13872, 16037, 49191, 13346, 13523, 12036, 14015, 47802, 12634, 11465, 14111, 14078, 44425, 12188, 12651, 15119, 14431, 46412, 12861, 13183, 13635, 16356, 46363, 13484, 15233, 14383, 18059, 53020, 14401, 14703, 16390, 18555, 46398, 14337, 13897, 14425, 17820, 47722, 13540, 13392, 13983, 15597, 48334, 12544, 11891, 14351, 15336, 44865, 12723, 12706, 12614, 15186, 44940, 11237, 13033, 14617, 15971, 49295, 11665, 13829, 13687, 15368, 45841, 12916, 12997, 15070, 16481, 46381, 13089, 13593, 14651, 15383, 46059, 13965, 15244, 17077, 15212, 48767, 14107, 15603, 16557, 19405, 51266, 15636, 16045, 16910, 24853, 55397, 14870, 16584, 17419, 19666, 60735, 12432, 13139, 13809, 15455, 46231, 12225, 14314, 14474, 15461, 50063, 11141, 12308, 13601, 13148, 43840, 12292, 12876, 13234, 15004, 45368, 11596, 13073, 13935, 16549, 47872, 11826, 13344, 14274, 15247, 46226, 15809, 16349, 15762, 18351, 46330, 13566, 14407, 16096, 16865, 47331, 13768, 15258, 15598, 17596, 47599, 14688, 14332, 14341, 16108, 45637, 15063, 15458, 16026, 22578, 49094, 13600, 13235, 13739, 15469, 43067, 12665, 13373, 15414, 15141, 40110, 13861, 15019, 16283, 18782, 43757, 13932, 16052, 16795, 21074, 54192, 12723, 12870, 15640, 16268, 45960, 14416, 16307, 15850, 21083, 55355, 13426, 16925, 15014, 18096, 46249, 15157, 16099, 17836, 17244, 47716, 13991, 15408, 16704, 16598, 45861, 14425, 16092, 15529, 16099, 49519, 12473, 13730, 13794, 15726, 48794, 11775, 13028, 14131, 22254, 47392, 11009, 11662, 12742, 13708, 43205, 11910, 13089, 13220, 13838, 42155, 10426, 11829, 12300, 14348, 42976, 11987, 11966, 12981, 15558, 43029, 11830, 12526, 15656, 15972, 46757, 12889, 14505, 13959, 18796, 46684, 12554, 13704, 14124, 19232, 46642, 12947, 12619, 14479, 16485, 44831, 12934, 14298, 15011, 17316, 50115, 11427, 11112, 13505, 14732, 42308, 12406, 13586, 13903, 14936, 44150, 14333, 12975, 14401, 21580, 49780, 13984, 15292, 15659, 18281, 44608, 13809, 15021, 14996, 14705, 46575, 13213, 15008, 14649, 16480, 46487, 14249, 14277, 15503, 17420, 52059, 14367, 13488, 15547, 18502, 51633, 13714, 14731, 15105, 20141, 50985, 14258, 15561, 14383, 17116, 46373, 14727, 16016, 16349, 18661, 50403, 16971, 16399, 18198, 21048, 51488, 16284, 18430, 18917, 21753, 55969, 15791, 17166, 16977, 21396, 52058, 14528, 17441, 17770, 24538, 62608, 13126, 13570, 13040, 15947, 47395, 13208, 14646, 14445, 15919, 48832, 11682, 12016, 13777, 15079, 43055, 12816, 13724, 12354, 17580, 45460, 12732, 12019, 14437, 16639, 47051, 11972, 12916, 13188, 19905, 46213, 11719, 11718, 13706, 14814, 40708, 11620, 12781, 13630, 16450, 44880, 10724, 13037, 14221, 16794, 46513, 11655, 13621, 14418, 14544, 48780, 12025, 13188, 14109, 16112, 47000, 13803, 12549, 14376, 19534, 51214, 12070, 12685, 13470, 14703, 45054, 12686, 13976, 14685, 15026, 43425, 12650, 14370, 15054, 16641, 48471, 13922, 13477, 15368, 17131, 49223, 12154, 13524, 14216, 16958, 49403, 11975, 14735, 15969, 23286, 47465, 13140, 13844, 13404, 16239, 45702, 12885, 13055, 13876, 16008, 47502, 11940, 13879, 14744, 15947, 46605, 12542, 12792, 13341, 16360, 45196, 11761, 12493, 13463, 16133, 48824, 12354, 13453, 14305, 19281, 53203, 14019, 15249, 14259, 19721, 49506, 15027, 15644, 16295, 20514, 50183, 14565, 15863, 17405, 21504, 52592, 14410, 13985, 15576, 21976, 47167, 12203, 12619, 15241, 21171, 56130, 11954, 12488, 13266, 18445, 45334, 10111, 11361, 12357, 13965, 40331, 11025, 11229, 10799, 13417, 39267, 9747, 10963, 11436, 13567, 43407, 10356, 9824, 9975, 13231, 38375, 8797, 11484, 12129, 13015, 39669, 11147, 11503, 12955, 16419, 47473, 11907, 12528, 12630, 13747, 39537, 12091, 11898, 14087, 14812, 41110, 11946, 12467, 14492, 15744, 42523, 11524, 11511, 12918, 14648, 41279, 11437, 11405, 14535, 15103, 41372, 11549, 12372, 13421, 17506, 50259, 11345, 10891, 11895, 13622, 36608, 11880, 13015, 12307, 15291, 39997, 11630, 11699, 13581, 15257, 42901, 13535, 13428, 13156, 17051, 44207, 12612, 13475, 15048, 15609, 46292, 15377, 15687, 17085, 23065, 61353, 15789, 15830, 15819, 18447, 49371, 14373, 14525, 15351, 18941, 47970, 13236, 14107, 15799, 18745, 50595, 14460, 15118, 16032, 17969, 51596, 13733, 13843, 14879, 16119, 49935, 13126, 12654, 13027, 16421, 45746, 11646, 13163, 11543, 14038, 38134, 12246, 11529, 12516, 12572, 35828, 11916, 12725, 12826, 13825, 41251, 10036, 12149, 10985, 12232, 36319, 12421, 12256, 11807, 13904, 41745, 13446, 13743, 14640, 23364, 42376, 9297, 10685, 10469, 11551, 31608, 9909, 9343, 9849, 11666, 31896, 9048, 9547, 10581, 11715, 33360, 9300, 10059, 10489, 12327, 34199, 10283, 10401, 10326, 10563, 34852, 11240, 9860, 11393, 13880, 36059, 9154, 10325, 9946, 12268, 29274, 10565, 9889, 9854, 10437, 32388, 9829, 10768, 10523, 12059, 33024, 9638, 9592, 9946, 11338, 34208, 10479, 10941, 11282, 12109, 41319, 11857, 13707, 14549, 22601, 34525, 9114, 10606, 10095, 10683, 29940, 9006, 9914, 11083, 10817, 29764, 8785, 9258, 9202, 10715, 30176, 8046, 9639, 8947, 10115, 28856, 8887, 9034, 9956, 9699, 31031, 10357, 9835, 9594, 10684, 28263, 7624, 8883, 8639, 9393, 25403, 8068, 8161, 7989, 9311, 25765, 8589, 8802, 8656, 13022, 22297, 9448, 8738, 9152, 8984, 24224, 9096, 9779, 10893, 11571, 37562, 16108, 15766, 15969, 36942, 76]}, {\"name\": \"Dep_Del30 = 1.0\", \"type\": \"bar\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2400], \"y\": [1094, 886, 711, 896, 4574, 986, 841, 799, 1037, 3471, 746, 955, 773, 844, 3943, 860, 573, 649, 624, 2872, 731, 777, 702, 606, 3226, 849, 883, 671, 626, 3024, 599, 585, 532, 459, 2046, 467, 451, 408, 649, 2262, 408, 431, 467, 596, 2273, 386, 350, 431, 395, 2233, 433, 358, 316, 442, 3230, 397, 430, 404, 638, 1356, 219, 133, 126, 221, 953, 170, 162, 222, 231, 829, 128, 166, 185, 148, 724, 118, 169, 233, 171, 632, 93, 151, 141, 98, 754, 117, 100, 98, 122, 601, 57, 55, 85, 76, 487, 124, 105, 56, 73, 499, 76, 68, 55, 70, 430, 85, 66, 119, 72, 406, 51, 25, 50, 44, 690, 74, 53, 112, 79, 121, 56, 72, 46, 82, 61, 80, 33, 44, 36, 82, 65, 70, 31, 51, 43, 67, 18, 75, 85, 68, 34, 41, 59, 30, 24, 4, 30, 61, 14, 17, 32, 6, 30, 36, 12, 39, 14, 9, 24, 17, 7, 19, 35, 13, 22, 6, 62, 19, 14, 17, 3, 2, 3, 10, 15, 19, 15, 8, 26, 14, 10, 5, 17, 12, 10, 6, 15, 38, 9, 10, 12, 6, 10, 16, 10, 9, 46, 20, 20, 8, 7, 9, 5, 15, 12, 10, 10, 9, 4, 5, 6, 5, 1, 31, 4, 58, 14, 6, 44, 31, 49, 21, 13, 72, 78, 33, 40, 81, 29, 38, 58, 21, 74, 7, 34, 20, 1, 11, 7, 57, 9, 6, 9, 4, 13, 5, 3, 4, 24, 27, 15, 8, 6, 46, 11, 15, 12, 29, 77, 95, 59, 51, 30, 39, 66, 60, 16, 29, 53, 245, 11, 44, 101, 120, 110, 37, 56, 66, 77, 122, 116, 84, 71, 161, 134, 136, 91, 67, 122, 144, 81, 130, 179, 130, 172, 170, 107, 157, 165, 1081, 326, 303, 260, 244, 386, 340, 268, 277, 195, 436, 180, 226, 253, 200, 345, 173, 215, 258, 203, 501, 195, 144, 300, 302, 376, 197, 197, 249, 303, 445, 268, 222, 297, 304, 365, 286, 180, 242, 253, 523, 198, 224, 299, 368, 527, 304, 263, 365, 369, 593, 208, 300, 280, 301, 670, 245, 271, 385, 619, 1108, 460, 471, 421, 437, 622, 296, 334, 480, 433, 747, 242, 384, 354, 359, 872, 294, 353, 382, 466, 806, 284, 343, 289, 386, 604, 277, 275, 340, 574, 685, 280, 323, 255, 406, 679, 329, 356, 295, 371, 708, 305, 312, 322, 405, 638, 330, 324, 401, 357, 853, 286, 347, 267, 305, 788, 264, 234, 327, 433, 1059, 299, 273, 307, 433, 827, 251, 333, 382, 323, 870, 289, 287, 279, 474, 994, 330, 309, 436, 504, 1135, 329, 464, 420, 454, 1281, 361, 349, 464, 524, 1339, 506, 508, 459, 539, 1255, 396, 345, 573, 525, 1121, 543, 443, 509, 788, 1239, 566, 599, 589, 916, 1835, 595, 526, 649, 805, 1265, 617, 635, 789, 855, 1527, 519, 472, 574, 695, 1568, 528, 626, 713, 693, 1763, 529, 599, 589, 718, 1562, 429, 448, 583, 646, 1418, 457, 540, 487, 591, 1646, 529, 490, 588, 745, 1813, 503, 500, 577, 566, 1375, 526, 626, 651, 652, 1471, 661, 647, 694, 764, 1704, 661, 873, 813, 966, 1841, 807, 960, 880, 1062, 2067, 939, 929, 1029, 1212, 2655, 830, 857, 937, 1123, 2662, 813, 875, 938, 1002, 2424, 675, 854, 763, 1020, 2444, 763, 897, 825, 1082, 2575, 679, 722, 787, 1043, 2641, 820, 809, 877, 1295, 2732, 809, 927, 980, 1043, 2835, 945, 986, 985, 1148, 3129, 868, 1034, 1110, 1263, 2839, 1077, 1037, 1087, 1022, 3063, 842, 945, 934, 979, 3088, 855, 975, 944, 1208, 3561, 937, 1126, 999, 1123, 2937, 983, 935, 1090, 1246, 2816, 1049, 1060, 1105, 1301, 2849, 1007, 943, 1290, 1289, 3089, 1228, 1181, 1254, 1322, 3055, 1086, 1165, 1142, 1210, 3627, 1107, 1025, 1175, 1270, 3048, 1012, 1204, 1212, 1218, 3195, 1104, 985, 1104, 1243, 3389, 1033, 1061, 1095, 1340, 3027, 1032, 1028, 1117, 1161, 3192, 1090, 1076, 1126, 1474, 4028, 1095, 1137, 1337, 1186, 3111, 1014, 1069, 1136, 1418, 3333, 1199, 1269, 1447, 1548, 3644, 1185, 1329, 1254, 1573, 3724, 1336, 1255, 1498, 1695, 3710, 1245, 1353, 1285, 1917, 4123, 1087, 1061, 1261, 1506, 3826, 1124, 1167, 1039, 1221, 3734, 1123, 967, 1230, 1267, 3372, 1151, 1156, 1292, 1374, 3640, 1183, 1179, 1201, 1401, 3517, 1130, 1318, 1333, 1527, 4272, 1327, 1359, 1363, 1655, 3657, 1285, 1210, 1226, 1464, 3385, 1198, 1190, 1373, 1427, 3917, 1164, 1085, 1378, 1350, 3689, 1241, 1278, 1140, 1368, 3759, 1025, 1156, 1325, 1617, 4197, 1028, 1367, 1376, 1588, 3819, 1166, 1251, 1432, 1639, 3817, 1172, 1355, 1346, 1528, 4128, 1315, 1413, 1528, 1361, 4125, 1360, 1460, 1532, 1783, 4278, 1415, 1477, 1678, 2336, 4811, 1329, 1466, 1689, 1843, 5560, 1225, 1182, 1355, 1404, 3952, 1166, 1342, 1425, 1536, 4306, 1182, 1226, 1418, 1371, 4069, 1239, 1268, 1358, 1419, 4179, 1118, 1222, 1362, 1731, 4428, 1115, 1273, 1482, 1588, 4433, 1731, 1644, 1680, 2071, 4434, 1343, 1478, 1711, 1746, 4618, 1424, 1531, 1707, 1887, 4655, 1583, 1530, 1634, 2039, 4538, 1486, 1649, 1672, 2525, 5160, 1451, 1522, 1467, 1650, 4423, 1340, 1397, 1623, 1715, 4201, 1444, 1625, 1737, 2025, 4552, 1474, 1641, 1815, 2317, 5620, 1403, 1361, 1743, 1948, 5176, 1588, 1811, 1743, 2542, 6004, 1715, 1952, 1589, 1960, 5095, 1633, 1802, 1960, 1981, 5129, 1623, 1742, 2128, 2017, 4873, 1587, 1910, 1880, 1913, 5536, 1380, 1652, 1580, 1811, 5452, 1374, 1590, 1753, 3005, 5578, 1336, 1315, 1517, 1627, 5208, 1413, 1557, 1610, 1706, 5263, 1488, 1338, 1558, 1680, 4965, 1525, 1468, 1598, 1928, 5428, 1435, 1478, 1744, 1962, 5492, 1556, 1654, 1646, 2490, 5776, 1466, 1617, 1796, 2289, 5520, 1517, 1405, 1651, 2048, 5565, 1527, 1741, 1773, 2202, 6136, 1586, 1487, 1764, 2073, 5616, 1458, 1596, 1737, 2000, 5561, 1771, 1650, 1913, 2943, 6614, 1664, 1912, 2123, 2414, 5673, 1847, 1809, 1906, 1948, 6202, 1808, 1987, 2090, 2206, 6357, 1967, 1880, 2161, 2262, 6764, 1883, 1702, 2046, 2387, 6877, 1724, 1822, 2026, 2811, 7313, 1986, 2139, 1930, 2322, 6623, 1849, 2117, 2157, 2372, 7192, 2091, 2078, 2278, 2904, 6941, 2248, 2380, 2389, 2862, 7996, 2072, 2299, 2309, 2912, 7537, 2013, 2436, 2532, 3922, 9048, 1773, 1907, 1908, 2259, 7403, 1973, 2094, 2043, 2306, 7461, 1889, 1755, 2138, 2355, 7258, 2038, 2220, 1950, 2723, 7572, 1888, 1937, 2111, 2588, 7550, 1883, 2042, 2085, 3461, 7667, 1983, 1978, 2274, 2264, 6885, 1940, 2001, 2255, 2529, 7207, 1570, 2103, 2216, 2768, 7935, 1666, 2165, 2114, 2190, 8075, 1786, 2125, 2231, 2588, 7540, 2125, 2032, 2346, 3739, 8787, 1955, 1844, 2087, 2191, 7376, 1974, 2216, 2407, 2408, 7346, 1987, 2352, 2527, 2785, 8515, 2258, 2239, 2475, 2890, 8623, 2048, 2353, 2398, 2953, 8625, 2064, 2423, 2575, 4164, 8865, 2324, 2277, 2197, 2712, 8450, 2039, 1967, 2216, 2598, 8467, 1902, 2257, 2291, 2789, 8295, 2158, 2002, 2323, 2909, 8756, 2002, 1973, 2232, 2845, 9161, 2283, 2200, 2332, 3889, 10513, 2669, 2675, 2302, 3607, 9302, 2679, 2607, 2724, 3857, 9656, 2614, 2620, 3032, 3957, 10108, 2492, 2822, 2839, 4206, 9562, 2091, 2469, 2677, 4119, 11284, 2257, 2247, 2347, 3756, 9222, 1881, 1869, 2144, 2495, 8313, 1918, 2022, 1948, 2478, 7918, 1728, 1905, 2221, 2510, 8547, 1964, 1883, 1976, 2460, 8383, 1684, 2044, 2274, 2425, 8237, 2178, 2008, 2350, 3324, 10496, 2158, 2242, 2426, 2783, 8192, 2327, 2217, 2531, 2871, 8595, 2243, 2401, 2671, 3009, 9014, 2176, 2268, 2443, 2939, 9101, 2373, 2235, 2757, 2987, 9186, 2198, 2446, 2564, 3441, 10789, 2300, 2189, 2344, 2552, 7650, 2264, 2385, 2318, 3089, 8128, 2374, 2360, 2545, 3026, 8546, 2653, 2510, 2602, 3325, 9045, 2507, 2594, 2788, 3110, 9748, 2995, 2870, 3332, 4843, 13343, 2969, 3085, 3143, 3605, 10306, 2606, 2840, 2939, 3768, 9764, 2486, 2635, 2902, 3635, 10266, 2803, 2967, 3011, 3398, 11051, 2306, 2563, 2673, 2942, 10319, 2622, 2556, 2466, 3382, 10440, 2255, 2646, 2299, 2947, 9084, 2375, 2360, 2404, 2566, 8596, 2491, 2419, 2624, 2909, 9218, 2184, 2526, 2255, 2594, 8866, 2461, 2629, 2561, 2979, 10264, 2808, 2750, 3284, 5636, 9875, 1657, 2060, 2133, 2297, 7329, 1998, 1916, 2128, 2381, 7546, 2083, 1915, 2080, 2593, 7612, 1840, 2016, 2004, 2279, 8220, 2104, 2140, 1980, 2071, 7690, 2301, 1947, 2303, 2973, 7897, 1830, 2271, 2102, 2597, 6863, 2304, 2063, 2003, 2184, 7920, 1900, 2354, 2271, 2548, 7774, 1896, 1989, 2049, 2251, 8189, 2043, 2101, 2316, 2412, 10027, 2450, 2742, 3064, 4944, 8351, 1762, 1892, 2040, 2144, 7452, 1655, 1887, 2486, 2162, 6814, 1932, 2006, 1898, 2000, 7247, 1485, 1856, 1746, 1945, 6822, 1700, 1742, 1782, 1821, 7042, 2003, 1820, 1853, 2067, 6549, 1368, 1605, 1482, 1661, 5619, 1399, 1422, 1601, 1755, 5933, 1595, 1624, 1590, 2576, 5629, 1716, 1748, 1777, 1642, 5605, 1696, 1940, 2036, 2053, 8749, 3082, 2709, 2936, 6925, 29]}],\n                        {\"barmode\": \"stack\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Flight Counts by CRS_Arr_Time & Dep_Del30\"}, \"xaxis\": {\"title\": {\"text\": \"CRS_Arr_Time\"}, \"type\": \"linear\"}, \"yaxis\": {\"title\": {\"text\": \"Number of Flights\"}}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":29},{"cell_type":"markdown","source":["From the distributions of values for `CRS_Dep_Time` and `CRS_Arr_Time`, we can see clusters of flights defined by --00 to --59 blocks (these clusters are a remnant of the structure of the 2400-clock, since there are no valid times from --60 to --99). With that said, by analyzing any one of these clusters, it's clear that most flights are scheduled at 5-minute markers (such as 1200, 1205, 1210, etc) for both departure and arrival times. Since there really isn't a big difference between times separated by a couple of 5 minute intervals, we will choose to bin these values by 10-minute increments to ensure we still have enough data granularity to differentiate between populate times such as 1200 and 1230 but not too much granularity to have too many splits to consider (reducing to 10-minute granularity alone reduces the number of splits for a Decision Tree algorithm to consider from at most 1439 to just about 144 split points)."],"metadata":{}},{"cell_type":"code","source":["fig3 = MakeRegBarChart(train_and_val, outcomeName, 'CRS_Elapsed_Time', orderBy='CRS_Elapsed_Time', barmode='stack', xtype='linear')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"4e709d8d-f33c-42ff-9e07-2aea2194dd70\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"4e709d8d-f33c-42ff-9e07-2aea2194dd70\")) {\n                    Plotly.newPlot(\n                        '4e709d8d-f33c-42ff-9e07-2aea2194dd70',\n                        [{\"name\": \"Dep_Del30 = 0.0\", \"type\": \"bar\", \"x\": [1.0, 5.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0, 513.0, 514.0, 515.0, 516.0, 517.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 529.0, 530.0, 531.0, 532.0, 533.0, 534.0, 535.0, 537.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 576.0, 577.0, 578.0, 579.0, 580.0, 581.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0, 592.0, 593.0, 594.0, 595.0, 596.0, 597.0, 598.0, 599.0, 600.0, 602.0, 603.0, 604.0, 606.0, 607.0, 608.0, 610.0, 611.0, 612.0, 613.0, 614.0, 615.0, 616.0, 617.0, 618.0, 619.0, 620.0, 622.0, 623.0, 625.0, 627.0, 631.0, 632.0, 633.0, 636.0, 640.0, 641.0, 644.0, 645.0, 646.0, 647.0, 648.0, 650.0, 652.0, 654.0, 655.0, 656.0, 658.0, 660.0, 665.0, 667.0, 668.0, 669.0, 670.0, 672.0, 675.0, 676.0, 679.0, 680.0, 681.0, 683.0, 685.0, 686.0, 688.0, 690.0, 695.0, 698.0, 700.0, 702.0, 703.0, 704.0, 705.0, 712.0, 718.0], \"y\": [3, 1, 109, 1, 173, 442, 580, 623, 462, 133, 183, 145, 56, 100, 751, 784, 5237, 6711, 9829, 20023, 11592, 20063, 12216, 24676, 18597, 18058, 12999, 19682, 21073, 28481, 24351, 39573, 28615, 30109, 66116, 39498, 45844, 50034, 55127, 128584, 49460, 56196, 62751, 68154, 235046, 60741, 74730, 78564, 83207, 329285, 85192, 87726, 94708, 94069, 353815, 93332, 99784, 100208, 104154, 349646, 109476, 110373, 112726, 115361, 402953, 110246, 117389, 117979, 122942, 412708, 114533, 117239, 121822, 127016, 384170, 112349, 121992, 123376, 127074, 291560, 110856, 113545, 116680, 120997, 265627, 111232, 110720, 114070, 110395, 261405, 98164, 105014, 110509, 112597, 284512, 105786, 105904, 107354, 109784, 265714, 110681, 105629, 105533, 110876, 252791, 96383, 92954, 99616, 101230, 229238, 85546, 89860, 87262, 86777, 226153, 81844, 79809, 81847, 82543, 232023, 72743, 74949, 76738, 78711, 220087, 74083, 73824, 70620, 76475, 211287, 68493, 70121, 72451, 78556, 221551, 71524, 72564, 76983, 79482, 223452, 77031, 78469, 80189, 82341, 226518, 78912, 75920, 78759, 78615, 190987, 73527, 71285, 73724, 72786, 176659, 64673, 67758, 68455, 67263, 154682, 62248, 60346, 61019, 61176, 130378, 53180, 52657, 50694, 49454, 107607, 44568, 45916, 42620, 43688, 90507, 37705, 38308, 37864, 37382, 85054, 32969, 32242, 33311, 33259, 86884, 30879, 32461, 31702, 29188, 82178, 28600, 30094, 30221, 33007, 77440, 28641, 29504, 26466, 29275, 63487, 25474, 25620, 25565, 26430, 58788, 23220, 23905, 23864, 25005, 61885, 23025, 25412, 23031, 24458, 67887, 23838, 24364, 25327, 24173, 71315, 22358, 23302, 23962, 24383, 66184, 23180, 22145, 21011, 21666, 54893, 18789, 19694, 19972, 20100, 51315, 19084, 17634, 17967, 19846, 49016, 16819, 17357, 17744, 16926, 44732, 16101, 15406, 15194, 17470, 41635, 15113, 16150, 16416, 15599, 41250, 13937, 14366, 14765, 16274, 37944, 14603, 15887, 15466, 14342, 34063, 12742, 13918, 12976, 12317, 29349, 10916, 10293, 10799, 13030, 28570, 12015, 11891, 10962, 12080, 25049, 11798, 10827, 12522, 12357, 27642, 9891, 11321, 12545, 12500, 24561, 11099, 12451, 11264, 12566, 28183, 10924, 11867, 13288, 14382, 27156, 12655, 12306, 13586, 14345, 27858, 12641, 13937, 15710, 14469, 30334, 12649, 14390, 16087, 17154, 31595, 13292, 13033, 13050, 15133, 24624, 11000, 12786, 11619, 12695, 26756, 10149, 10147, 10506, 10200, 21083, 8455, 8095, 9596, 8226, 18675, 7305, 7851, 8550, 8634, 17911, 6863, 7518, 8103, 7716, 15831, 6435, 6161, 6759, 6881, 14854, 6298, 6148, 6196, 6230, 15434, 5639, 6004, 7195, 6058, 13131, 5908, 7034, 5947, 6132, 13389, 5928, 5891, 6268, 5882, 12294, 5432, 5675, 4925, 5244, 11036, 4698, 3712, 5116, 4438, 8388, 3962, 3458, 3503, 3799, 6876, 2954, 2786, 3261, 3165, 5613, 1692, 2308, 1762, 1737, 2023, 1548, 1541, 1210, 1055, 923, 672, 504, 767, 575, 767, 520, 297, 433, 523, 856, 93, 233, 126, 203, 396, 209, 99, 281, 148, 296, 233, 304, 299, 124, 685, 461, 217, 533, 424, 376, 84, 33, 345, 176, 252, 59, 78, 264, 214, 264, 289, 524, 124, 300, 400, 259, 219, 90, 238, 339, 188, 67, 84, 275, 724, 258, 176, 226, 88, 427, 55, 215, 121, 103, 205, 81, 98, 111, 289, 68, 62, 223, 297, 137, 57, 84, 302, 188, 84, 269, 350, 293, 44, 184, 16, 232, 66, 56, 162, 40, 83, 289, 216, 134, 95, 122, 270, 327, 100, 166, 87, 127, 160, 562, 153, 186, 166, 217, 150, 58, 166, 63, 44, 158, 86, 69, 34, 27, 132, 51, 81, 3, 61, 18, 89, 127, 112, 69, 83, 233, 11, 115, 7, 121, 123, 37, 86, 121, 65, 123, 136, 104, 52, 110, 10, 91, 182, 49, 129, 16, 434, 148, 69, 178, 9, 288, 49, 6, 160, 334, 242, 133, 113, 9, 330, 50, 119, 79, 16, 187, 29, 34, 35, 32, 165, 13, 4, 11, 21, 1, 14, 4, 34, 34, 19, 14, 14, 12, 24, 60, 137, 89, 197, 64, 123, 2, 93, 32, 6, 12, 2, 51, 7, 29, 4, 151, 9, 70, 27, 46, 81, 65, 195, 59, 55, 412, 68, 55, 75, 111, 47, 5, 81, 72, 83, 148, 113, 101, 62, 59, 77, 43, 16, 53, 102, 112, 3, 28, 1, 12, 20, 19, 37, 21]}, {\"name\": \"Dep_Del30 = 1.0\", \"type\": \"bar\", \"x\": [-99.0, 1.0, 4.0, 18.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0, 345.0, 346.0, 347.0, 348.0, 349.0, 350.0, 351.0, 352.0, 353.0, 354.0, 355.0, 356.0, 357.0, 358.0, 359.0, 360.0, 361.0, 362.0, 363.0, 364.0, 365.0, 366.0, 367.0, 368.0, 369.0, 370.0, 371.0, 372.0, 373.0, 374.0, 375.0, 376.0, 377.0, 378.0, 379.0, 380.0, 381.0, 382.0, 383.0, 384.0, 385.0, 386.0, 387.0, 388.0, 389.0, 390.0, 391.0, 392.0, 393.0, 394.0, 395.0, 396.0, 397.0, 398.0, 399.0, 400.0, 401.0, 402.0, 403.0, 404.0, 405.0, 406.0, 407.0, 408.0, 409.0, 410.0, 411.0, 412.0, 413.0, 414.0, 415.0, 416.0, 417.0, 418.0, 419.0, 420.0, 421.0, 422.0, 423.0, 424.0, 425.0, 426.0, 427.0, 428.0, 429.0, 430.0, 431.0, 432.0, 433.0, 434.0, 435.0, 436.0, 437.0, 438.0, 439.0, 440.0, 441.0, 442.0, 443.0, 444.0, 445.0, 446.0, 447.0, 448.0, 449.0, 450.0, 451.0, 452.0, 453.0, 454.0, 455.0, 456.0, 457.0, 458.0, 459.0, 460.0, 461.0, 462.0, 463.0, 464.0, 465.0, 466.0, 467.0, 468.0, 469.0, 470.0, 471.0, 472.0, 473.0, 474.0, 475.0, 476.0, 477.0, 478.0, 479.0, 480.0, 482.0, 483.0, 484.0, 485.0, 486.0, 487.0, 488.0, 489.0, 490.0, 491.0, 492.0, 493.0, 494.0, 495.0, 496.0, 497.0, 498.0, 499.0, 500.0, 501.0, 502.0, 503.0, 504.0, 505.0, 506.0, 507.0, 508.0, 509.0, 510.0, 511.0, 512.0, 513.0, 514.0, 515.0, 516.0, 517.0, 518.0, 519.0, 520.0, 521.0, 522.0, 523.0, 524.0, 525.0, 526.0, 527.0, 528.0, 530.0, 531.0, 532.0, 533.0, 535.0, 537.0, 539.0, 540.0, 541.0, 542.0, 543.0, 544.0, 545.0, 546.0, 547.0, 548.0, 549.0, 550.0, 551.0, 552.0, 553.0, 554.0, 555.0, 556.0, 557.0, 558.0, 559.0, 560.0, 561.0, 562.0, 563.0, 564.0, 565.0, 566.0, 567.0, 569.0, 570.0, 571.0, 572.0, 573.0, 574.0, 575.0, 578.0, 579.0, 580.0, 581.0, 583.0, 584.0, 585.0, 586.0, 587.0, 588.0, 589.0, 590.0, 591.0, 592.0, 593.0, 595.0, 596.0, 599.0, 600.0, 602.0, 604.0, 608.0, 610.0, 611.0, 612.0, 613.0, 614.0, 615.0, 616.0, 617.0, 618.0, 619.0, 620.0, 622.0, 623.0, 625.0, 627.0, 631.0, 632.0, 633.0, 636.0, 640.0, 641.0, 644.0, 646.0, 647.0, 648.0, 650.0, 652.0, 654.0, 655.0, 656.0, 658.0, 660.0, 665.0, 667.0, 669.0, 670.0, 672.0, 675.0, 676.0, 679.0, 680.0, 681.0, 683.0, 685.0, 686.0, 688.0, 690.0, 695.0, 698.0, 700.0, 702.0, 704.0, 705.0, 712.0, 718.0], \"y\": [1, 1, 1, 10, 15, 37, 42, 63, 55, 10, 16, 17, 5, 17, 75, 61, 120, 314, 340, 601, 481, 792, 536, 1052, 895, 950, 906, 1261, 1446, 2398, 1965, 2731, 2693, 3068, 7485, 3641, 4363, 5265, 5585, 15073, 5797, 6680, 7141, 7455, 27953, 6892, 8562, 8996, 9177, 41670, 10310, 10032, 10971, 10735, 43906, 11040, 11954, 12023, 12436, 45812, 12949, 13290, 13760, 14141, 52842, 13553, 14401, 14322, 15705, 54788, 14993, 14750, 15714, 16565, 50943, 14448, 15485, 15788, 16743, 38116, 14376, 14516, 14660, 15263, 34714, 13875, 13320, 13990, 13132, 32698, 11833, 12510, 13349, 13288, 36111, 12501, 12529, 13111, 13024, 33059, 12967, 12859, 12991, 13900, 33843, 12071, 11510, 12529, 12435, 30585, 10782, 11716, 11419, 11856, 30359, 11038, 10538, 10961, 11221, 32775, 9604, 10592, 10666, 10777, 29946, 9881, 9973, 9549, 10249, 27711, 9190, 9613, 9723, 10622, 29521, 9338, 9772, 10077, 10344, 30426, 10969, 10782, 10814, 11061, 30774, 11249, 10956, 11091, 11426, 26060, 10980, 10558, 10697, 10613, 23715, 9761, 10285, 10393, 9899, 21801, 9534, 9056, 9401, 9752, 18675, 8481, 7868, 7897, 7196, 15378, 6833, 6779, 6132, 6868, 12331, 5538, 5282, 5176, 5562, 11155, 4314, 4635, 4549, 4750, 11106, 4245, 4378, 4124, 4212, 10971, 3914, 3935, 4128, 4322, 10426, 3982, 3736, 3267, 3854, 9045, 3276, 3201, 3185, 3288, 7796, 3039, 2963, 3096, 3267, 8159, 2973, 3256, 3146, 3260, 9282, 3061, 3133, 3053, 3126, 9435, 2915, 3004, 3059, 3174, 8080, 2885, 2613, 2611, 2807, 6649, 2527, 2429, 2423, 2409, 6325, 2397, 2484, 2202, 2494, 5794, 2257, 2236, 2531, 2115, 5876, 2281, 2032, 1982, 2446, 5274, 2071, 2159, 2192, 2089, 5691, 1884, 1988, 1936, 2057, 5467, 2001, 2180, 2106, 1902, 4711, 1854, 1980, 1699, 1655, 4243, 1300, 1326, 1435, 1378, 3810, 1385, 1409, 1222, 1422, 3096, 1383, 1292, 1599, 1481, 3068, 1202, 1459, 1482, 1521, 3098, 1308, 1688, 1423, 1695, 3368, 1376, 1682, 1727, 1761, 3347, 1688, 1506, 1956, 1876, 3466, 1650, 1956, 1839, 2054, 3812, 1761, 2052, 2312, 2400, 4206, 1971, 1634, 1687, 2183, 3141, 1518, 1742, 1526, 1599, 3335, 1594, 1487, 1541, 1384, 2333, 1179, 1158, 1208, 1195, 2190, 1027, 1085, 1201, 1048, 1986, 941, 986, 1083, 1048, 1998, 885, 733, 984, 860, 1601, 835, 876, 850, 768, 1585, 747, 792, 921, 834, 1585, 948, 934, 854, 829, 1655, 939, 884, 1028, 1008, 1569, 828, 983, 817, 936, 1494, 793, 548, 765, 746, 1139, 614, 428, 457, 697, 1028, 483, 457, 523, 516, 750, 323, 391, 232, 265, 342, 295, 245, 204, 179, 80, 98, 65, 107, 67, 139, 70, 35, 50, 57, 106, 7, 25, 23, 13, 53, 14, 14, 27, 19, 18, 6, 31, 30, 18, 89, 37, 14, 53, 58, 38, 5, 6, 40, 10, 22, 7, 3, 14, 26, 32, 30, 62, 8, 30, 70, 22, 37, 11, 13, 48, 23, 15, 11, 34, 97, 33, 6, 20, 12, 54, 15, 20, 18, 11, 33, 8, 11, 24, 61, 3, 5, 48, 37, 7, 7, 18, 24, 22, 18, 48, 90, 41, 22, 37, 1, 52, 14, 16, 45, 9, 19, 70, 53, 20, 20, 15, 33, 85, 25, 60, 27, 17, 37, 90, 25, 39, 46, 33, 30, 1, 23, 1, 9, 6, 28, 1, 11, 5, 9, 5, 12, 1, 6, 27, 15, 14, 10, 25, 1, 11, 1, 11, 10, 2, 10, 16, 12, 20, 22, 14, 2, 20, 1, 17, 19, 3, 15, 6, 63, 20, 5, 28, 1, 28, 19, 28, 22, 15, 7, 2, 33, 6, 8, 10, 1, 12, 4, 1, 2, 13, 1, 2, 3, 1, 1, 4, 2, 3, 1, 3, 30, 4, 14, 4, 19, 1, 4, 1, 1, 3, 1, 7, 1, 2, 1, 12, 4, 6, 15, 18, 9, 19, 15, 13, 18, 7, 4, 4, 7, 5, 8, 2, 13, 9, 14, 23, 7, 8, 20, 4, 3, 9, 18, 7, 1, 1, 3, 8, 2, 5, 2]}],\n                        {\"barmode\": \"stack\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Flight Counts by CRS_Elapsed_Time & Dep_Del30\"}, \"xaxis\": {\"title\": {\"text\": \"CRS_Elapsed_Time\"}, \"type\": \"linear\"}, \"yaxis\": {\"title\": {\"text\": \"Number of Flights\"}}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":31},{"cell_type":"markdown","source":["For the `CRS_Elapsed_Time`, as we saw in the EDA Task 1, we can still capture the general distribution of the scheduled flight duration even when we bin by 1 hour durations, which leaves us with meaningful groups and much fewer splits to consider. For this reason, we will bin `CRS_Elapsed_Time` to 1 hour increments. \n\nAll three of the described binning transformations are applied with the code shown below and appended to our original *Airline Delays* dataset. Note that this binning operation is independently applied to each record in the original dataset, using the binning we decided based on the training dataset. Also note that by using the `Bucketizer` 'keep' flag, we explicitly choose to bin any invalid values into a special bucket, which will allow our models to be resiliant even in the event of encountering values that go beyond the limits defined. Note that for simplicity, we extend the `CRS_Elapsed_Time` bins to negative and positive infinity to ensure all values are binned properly. All new binned features will be suffixed with `_bin`, except for `Distance_Group`, which is already defined. A few examples of the new columns are shown below."],"metadata":{}},{"cell_type":"code","source":["# Augments the provided dataset for the given feature/variable with a binned version\n# of that variable, as defined by splits parameter\n# Column name suffixed with '_bin' will be the binned column\ndef BinFeature(df, featureName, splits):\n  if (featureName + \"_bin\" in df.columns):\n    print(\"Variable '\" + featureName + \"_bin' already exists\")\n    return df\n    \n  # Generate binned column for feature\n  bucketizer = Bucketizer(splits=splits, inputCol=featureName, outputCol=featureName + \"_bin\")\n  df_bin = bucketizer.setHandleInvalid(\"keep\").transform(df)\n  df_bin = df_bin.withColumn(featureName + \"_bin\", df_bin[featureName + \"_bin\"].cast(IntegerType()))    \n  return df_bin\n\n# Bin numerical features in entire airlines dataset\n# Note that splits are not based on test set but are applied to test set (as would be applied at inference time)\nairlines = BinFeature(airlines, 'CRS_Dep_Time', splits = [i for i in range(0, 2400 + 1, 10)]) # 10 min blocks\nairlines = BinFeature(airlines, 'CRS_Arr_Time', splits = [i for i in range(0, 2400 + 1, 10)]) # 10 min blocks\nairlines = BinFeature(airlines, 'CRS_Elapsed_Time', splits = [float(\"-inf\")] + [i for i in range(0, 660 + 1, 60)] + [float(\"inf\")]) # 1-hour blocks\nbinFeatureNames = ['CRS_Dep_Time_bin', 'CRS_Arr_Time_bin', 'CRS_Elapsed_Time_bin']\n\ndisplay(airlines.select(contNumFeatureNames + binFeatureNames + ['Distance_Group']).take(6))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CRS_Dep_Time</th><th>CRS_Arr_Time</th><th>CRS_Elapsed_Time</th><th>Distance</th><th>CRS_Dep_Time_bin</th><th>CRS_Arr_Time_bin</th><th>CRS_Elapsed_Time_bin</th><th>Distance_Group</th></tr></thead><tbody><tr><td>1449</td><td>2324</td><td>335.0</td><td>2588.0</td><td>144</td><td>232</td><td>6</td><td>11</td></tr><tr><td>1445</td><td>1800</td><td>375.0</td><td>2475.0</td><td>144</td><td>180</td><td>7</td><td>10</td></tr><tr><td>1450</td><td>2322</td><td>332.0</td><td>2475.0</td><td>145</td><td>232</td><td>6</td><td>10</td></tr><tr><td>1105</td><td>1228</td><td>83.0</td><td>369.0</td><td>110</td><td>122</td><td>2</td><td>2</td></tr><tr><td>2316</td><td>157</td><td>161.0</td><td>1129.0</td><td>231</td><td>15</td><td>3</td><td>5</td></tr><tr><td>1804</td><td>2019</td><td>135.0</td><td>749.0</td><td>180</td><td>201</td><td>3</td><td>3</td></tr></tbody></table></div>"]}}],"execution_count":33},{"cell_type":"markdown","source":["### Interacting Features\nDuring our in-depth EDA, we investigated a few interactions based on intuition. From our own experiences, we believed that certain temporal interaction terms and airport-related interactions would intuitively be indicative of a flight that is more likely to experience a departure delay.\n\nLet's consider the features `Month` and `Day_Of_Month`. On their own, we may be able to capture aggregated information about flights delays on a particular day of the month or a particular month on its own. But if we interact the two, we get the concept of `Day_Of_Year`, and upon closer inspection, there do appear to be certain days of the year that experience more traffic and more delays. Take the stacked bar chart comparing the ratio of delayed and no-delay flights shown below for `Day_Of_Year`, which is the concatenation of `Month` and `Day_Of_Month`. From this chart, we can see that there is a higher probability of departure delays for dates in the summer, as well as near the end of December and beginning of January, but not on holidays in that time frame (e.g. December 25th - Christmas Day). Because there does appear to be some relationship between `Day_Of_Year` and the likelihood of a departure delay, we choose to add this as one of our interaction terms."],"metadata":{}},{"cell_type":"code","source":["# Plot that demonstrates the probability of a departure delay, given the day of year (interaction of month & day of month)\nvar = \"Day_Of_Year\"\nd = train_and_val.select(\"Month\", \"Day_Of_Month\", outcomeName) \\\n                 .withColumn(var, F.concat(F.col('Month'), F.lit('-'), F.col('Day_Of_Month'))) \\\n                 .groupBy(var, \"Month\", \"Day_Of_Month\", outcomeName).count() \\\n                 .orderBy(\"Month\", \"Day_Of_Month\") \\\n                 .toPandas()\ndisplay(d)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Day_Of_Year</th><th>Month</th><th>Day_Of_Month</th><th>Dep_Del30</th><th>count</th></tr></thead><tbody><tr><td>1-1</td><td>1</td><td>1</td><td>0</td><td>49601</td></tr><tr><td>1-1</td><td>1</td><td>1</td><td>1</td><td>8211</td></tr><tr><td>1-2</td><td>1</td><td>2</td><td>0</td><td>54668</td></tr><tr><td>1-2</td><td>1</td><td>2</td><td>1</td><td>11590</td></tr><tr><td>1-3</td><td>1</td><td>3</td><td>1</td><td>11886</td></tr><tr><td>1-3</td><td>1</td><td>3</td><td>0</td><td>52368</td></tr><tr><td>1-4</td><td>1</td><td>4</td><td>1</td><td>10967</td></tr><tr><td>1-4</td><td>1</td><td>4</td><td>0</td><td>50166</td></tr><tr><td>1-5</td><td>1</td><td>5</td><td>1</td><td>11546</td></tr><tr><td>1-5</td><td>1</td><td>5</td><td>0</td><td>51417</td></tr><tr><td>1-6</td><td>1</td><td>6</td><td>1</td><td>10168</td></tr><tr><td>1-6</td><td>1</td><td>6</td><td>0</td><td>48720</td></tr><tr><td>1-7</td><td>1</td><td>7</td><td>1</td><td>10439</td></tr><tr><td>1-7</td><td>1</td><td>7</td><td>0</td><td>48701</td></tr><tr><td>1-8</td><td>1</td><td>8</td><td>0</td><td>50761</td></tr><tr><td>1-8</td><td>1</td><td>8</td><td>1</td><td>11353</td></tr><tr><td>1-9</td><td>1</td><td>9</td><td>0</td><td>50431</td></tr><tr><td>1-9</td><td>1</td><td>9</td><td>1</td><td>9467</td></tr><tr><td>1-10</td><td>1</td><td>10</td><td>0</td><td>50840</td></tr><tr><td>1-10</td><td>1</td><td>10</td><td>1</td><td>7611</td></tr><tr><td>1-11</td><td>1</td><td>11</td><td>0</td><td>55279</td></tr><tr><td>1-11</td><td>1</td><td>11</td><td>1</td><td>7650</td></tr><tr><td>1-12</td><td>1</td><td>12</td><td>1</td><td>11149</td></tr><tr><td>1-12</td><td>1</td><td>12</td><td>0</td><td>52288</td></tr><tr><td>1-13</td><td>1</td><td>13</td><td>0</td><td>53706</td></tr><tr><td>1-13</td><td>1</td><td>13</td><td>1</td><td>5690</td></tr><tr><td>1-14</td><td>1</td><td>14</td><td>1</td><td>4277</td></tr><tr><td>1-14</td><td>1</td><td>14</td><td>0</td><td>54179</td></tr><tr><td>1-15</td><td>1</td><td>15</td><td>1</td><td>7137</td></tr><tr><td>1-15</td><td>1</td><td>15</td><td>0</td><td>55528</td></tr><tr><td>1-16</td><td>1</td><td>16</td><td>1</td><td>6273</td></tr><tr><td>1-16</td><td>1</td><td>16</td><td>0</td><td>52838</td></tr><tr><td>1-17</td><td>1</td><td>17</td><td>0</td><td>49241</td></tr><tr><td>1-17</td><td>1</td><td>17</td><td>1</td><td>6744</td></tr><tr><td>1-18</td><td>1</td><td>18</td><td>1</td><td>6942</td></tr><tr><td>1-18</td><td>1</td><td>18</td><td>0</td><td>55018</td></tr><tr><td>1-19</td><td>1</td><td>19</td><td>1</td><td>5413</td></tr><tr><td>1-19</td><td>1</td><td>19</td><td>0</td><td>59414</td></tr><tr><td>1-20</td><td>1</td><td>20</td><td>1</td><td>4777</td></tr><tr><td>1-20</td><td>1</td><td>20</td><td>0</td><td>54938</td></tr><tr><td>1-21</td><td>1</td><td>21</td><td>0</td><td>53612</td></tr><tr><td>1-21</td><td>1</td><td>21</td><td>1</td><td>6057</td></tr><tr><td>1-22</td><td>1</td><td>22</td><td>1</td><td>8098</td></tr><tr><td>1-22</td><td>1</td><td>22</td><td>0</td><td>52854</td></tr><tr><td>1-23</td><td>1</td><td>23</td><td>0</td><td>50714</td></tr><tr><td>1-23</td><td>1</td><td>23</td><td>1</td><td>6796</td></tr><tr><td>1-24</td><td>1</td><td>24</td><td>1</td><td>4336</td></tr><tr><td>1-24</td><td>1</td><td>24</td><td>0</td><td>52374</td></tr><tr><td>1-25</td><td>1</td><td>25</td><td>1</td><td>4073</td></tr><tr><td>1-25</td><td>1</td><td>25</td><td>0</td><td>58823</td></tr><tr><td>1-26</td><td>1</td><td>26</td><td>1</td><td>3862</td></tr><tr><td>1-26</td><td>1</td><td>26</td><td>0</td><td>59394</td></tr><tr><td>1-27</td><td>1</td><td>27</td><td>1</td><td>2889</td></tr><tr><td>1-27</td><td>1</td><td>27</td><td>0</td><td>54229</td></tr><tr><td>1-28</td><td>1</td><td>28</td><td>1</td><td>3157</td></tr><tr><td>1-28</td><td>1</td><td>28</td><td>0</td><td>56570</td></tr><tr><td>1-29</td><td>1</td><td>29</td><td>0</td><td>58980</td></tr><tr><td>1-29</td><td>1</td><td>29</td><td>1</td><td>5345</td></tr><tr><td>1-30</td><td>1</td><td>30</td><td>1</td><td>5166</td></tr><tr><td>1-30</td><td>1</td><td>30</td><td>0</td><td>55741</td></tr><tr><td>1-31</td><td>1</td><td>31</td><td>1</td><td>3526</td></tr><tr><td>1-31</td><td>1</td><td>31</td><td>0</td><td>55179</td></tr><tr><td>2-1</td><td>2</td><td>1</td><td>1</td><td>4756</td></tr><tr><td>2-1</td><td>2</td><td>1</td><td>0</td><td>55276</td></tr><tr><td>2-2</td><td>2</td><td>2</td><td>0</td><td>54437</td></tr><tr><td>2-2</td><td>2</td><td>2</td><td>1</td><td>7306</td></tr><tr><td>2-3</td><td>2</td><td>3</td><td>1</td><td>5566</td></tr><tr><td>2-3</td><td>2</td><td>3</td><td>0</td><td>53488</td></tr><tr><td>2-4</td><td>2</td><td>4</td><td>0</td><td>51893</td></tr><tr><td>2-4</td><td>2</td><td>4</td><td>1</td><td>5906</td></tr><tr><td>2-5</td><td>2</td><td>5</td><td>0</td><td>53788</td></tr><tr><td>2-5</td><td>2</td><td>5</td><td>1</td><td>8072</td></tr><tr><td>2-6</td><td>2</td><td>6</td><td>0</td><td>55109</td></tr><tr><td>2-6</td><td>2</td><td>6</td><td>1</td><td>5287</td></tr><tr><td>2-7</td><td>2</td><td>7</td><td>0</td><td>50342</td></tr><tr><td>2-7</td><td>2</td><td>7</td><td>1</td><td>6313</td></tr><tr><td>2-8</td><td>2</td><td>8</td><td>1</td><td>6303</td></tr><tr><td>2-8</td><td>2</td><td>8</td><td>0</td><td>56236</td></tr><tr><td>2-9</td><td>2</td><td>9</td><td>1</td><td>7628</td></tr><tr><td>2-9</td><td>2</td><td>9</td><td>0</td><td>52429</td></tr><tr><td>2-10</td><td>2</td><td>10</td><td>1</td><td>5584</td></tr><tr><td>2-10</td><td>2</td><td>10</td><td>0</td><td>53999</td></tr><tr><td>2-11</td><td>2</td><td>11</td><td>1</td><td>6550</td></tr><tr><td>2-11</td><td>2</td><td>11</td><td>0</td><td>53219</td></tr><tr><td>2-12</td><td>2</td><td>12</td><td>1</td><td>6181</td></tr><tr><td>2-12</td><td>2</td><td>12</td><td>0</td><td>58561</td></tr><tr><td>2-13</td><td>2</td><td>13</td><td>1</td><td>5078</td></tr><tr><td>2-13</td><td>2</td><td>13</td><td>0</td><td>56349</td></tr><tr><td>2-14</td><td>2</td><td>14</td><td>1</td><td>5116</td></tr><tr><td>2-14</td><td>2</td><td>14</td><td>0</td><td>52076</td></tr><tr><td>2-15</td><td>2</td><td>15</td><td>1</td><td>8481</td></tr><tr><td>2-15</td><td>2</td><td>15</td><td>0</td><td>53118</td></tr><tr><td>2-16</td><td>2</td><td>16</td><td>1</td><td>10141</td></tr><tr><td>2-16</td><td>2</td><td>16</td><td>0</td><td>55238</td></tr><tr><td>2-17</td><td>2</td><td>17</td><td>1</td><td>7979</td></tr><tr><td>2-17</td><td>2</td><td>17</td><td>0</td><td>53054</td></tr><tr><td>2-18</td><td>2</td><td>18</td><td>1</td><td>7144</td></tr><tr><td>2-18</td><td>2</td><td>18</td><td>0</td><td>53853</td></tr><tr><td>2-19</td><td>2</td><td>19</td><td>0</td><td>56879</td></tr><tr><td>2-19</td><td>2</td><td>19</td><td>1</td><td>7872</td></tr><tr><td>2-20</td><td>2</td><td>20</td><td>1</td><td>8358</td></tr><tr><td>2-20</td><td>2</td><td>20</td><td>0</td><td>54064</td></tr><tr><td>2-21</td><td>2</td><td>21</td><td>0</td><td>54876</td></tr><tr><td>2-21</td><td>2</td><td>21</td><td>1</td><td>5978</td></tr><tr><td>2-22</td><td>2</td><td>22</td><td>0</td><td>56457</td></tr><tr><td>2-22</td><td>2</td><td>22</td><td>1</td><td>8548</td></tr><tr><td>2-23</td><td>2</td><td>23</td><td>0</td><td>58074</td></tr><tr><td>2-23</td><td>2</td><td>23</td><td>1</td><td>7481</td></tr><tr><td>2-24</td><td>2</td><td>24</td><td>1</td><td>8670</td></tr><tr><td>2-24</td><td>2</td><td>24</td><td>0</td><td>51777</td></tr><tr><td>2-25</td><td>2</td><td>25</td><td>0</td><td>54114</td></tr><tr><td>2-25</td><td>2</td><td>25</td><td>1</td><td>7271</td></tr><tr><td>2-26</td><td>2</td><td>26</td><td>0</td><td>58186</td></tr><tr><td>2-26</td><td>2</td><td>26</td><td>1</td><td>7556</td></tr><tr><td>2-27</td><td>2</td><td>27</td><td>0</td><td>57315</td></tr><tr><td>2-27</td><td>2</td><td>27</td><td>1</td><td>5492</td></tr><tr><td>2-28</td><td>2</td><td>28</td><td>0</td><td>55480</td></tr><tr><td>2-28</td><td>2</td><td>28</td><td>1</td><td>5087</td></tr><tr><td>2-29</td><td>2</td><td>29</td><td>1</td><td>860</td></tr><tr><td>2-29</td><td>2</td><td>29</td><td>0</td><td>14596</td></tr><tr><td>3-1</td><td>3</td><td>1</td><td>0</td><td>52919</td></tr><tr><td>3-1</td><td>3</td><td>1</td><td>1</td><td>9996</td></tr><tr><td>3-2</td><td>3</td><td>2</td><td>1</td><td>9358</td></tr><tr><td>3-2</td><td>3</td><td>2</td><td>0</td><td>54286</td></tr><tr><td>3-3</td><td>3</td><td>3</td><td>0</td><td>53711</td></tr><tr><td>3-3</td><td>3</td><td>3</td><td>1</td><td>8388</td></tr><tr><td>3-4</td><td>3</td><td>4</td><td>1</td><td>6749</td></tr><tr><td>3-4</td><td>3</td><td>4</td><td>0</td><td>55230</td></tr><tr><td>3-5</td><td>3</td><td>5</td><td>0</td><td>53220</td></tr><tr><td>3-5</td><td>3</td><td>5</td><td>1</td><td>8009</td></tr><tr><td>3-6</td><td>3</td><td>6</td><td>0</td><td>58412</td></tr><tr><td>3-6</td><td>3</td><td>6</td><td>1</td><td>7677</td></tr><tr><td>3-7</td><td>3</td><td>7</td><td>0</td><td>57104</td></tr><tr><td>3-7</td><td>3</td><td>7</td><td>1</td><td>5336</td></tr><tr><td>3-8</td><td>3</td><td>8</td><td>0</td><td>59876</td></tr><tr><td>3-8</td><td>3</td><td>8</td><td>1</td><td>6615</td></tr><tr><td>3-9</td><td>3</td><td>9</td><td>1</td><td>7013</td></tr><tr><td>3-9</td><td>3</td><td>9</td><td>0</td><td>61701</td></tr><tr><td>3-10</td><td>3</td><td>10</td><td>1</td><td>7178</td></tr><tr><td>3-10</td><td>3</td><td>10</td><td>0</td><td>58312</td></tr><tr><td>3-11</td><td>3</td><td>11</td><td>0</td><td>59268</td></tr><tr><td>3-11</td><td>3</td><td>11</td><td>1</td><td>6726</td></tr><tr><td>3-12</td><td>3</td><td>12</td><td>0</td><td>59255</td></tr><tr><td>3-12</td><td>3</td><td>12</td><td>1</td><td>7091</td></tr><tr><td>3-13</td><td>3</td><td>13</td><td>1</td><td>7925</td></tr><tr><td>3-13</td><td>3</td><td>13</td><td>0</td><td>57994</td></tr><tr><td>3-14</td><td>3</td><td>14</td><td>0</td><td>54551</td></tr><tr><td>3-14</td><td>3</td><td>14</td><td>1</td><td>7606</td></tr><tr><td>3-15</td><td>3</td><td>15</td><td>1</td><td>6647</td></tr><tr><td>3-15</td><td>3</td><td>15</td><td>0</td><td>60896</td></tr><tr><td>3-16</td><td>3</td><td>16</td><td>0</td><td>63381</td></tr><tr><td>3-16</td><td>3</td><td>16</td><td>1</td><td>6178</td></tr><tr><td>3-17</td><td>3</td><td>17</td><td>0</td><td>60139</td></tr><tr><td>3-17</td><td>3</td><td>17</td><td>1</td><td>5885</td></tr><tr><td>3-18</td><td>3</td><td>18</td><td>1</td><td>5987</td></tr><tr><td>3-18</td><td>3</td><td>18</td><td>0</td><td>60259</td></tr><tr><td>3-19</td><td>3</td><td>19</td><td>1</td><td>5987</td></tr><tr><td>3-19</td><td>3</td><td>19</td><td>0</td><td>60684</td></tr><tr><td>3-20</td><td>3</td><td>20</td><td>0</td><td>59614</td></tr><tr><td>3-20</td><td>3</td><td>20</td><td>1</td><td>7660</td></tr><tr><td>3-21</td><td>3</td><td>21</td><td>0</td><td>56123</td></tr><tr><td>3-21</td><td>3</td><td>21</td><td>1</td><td>6203</td></tr><tr><td>3-22</td><td>3</td><td>22</td><td>1</td><td>7091</td></tr><tr><td>3-22</td><td>3</td><td>22</td><td>0</td><td>60578</td></tr><tr><td>3-23</td><td>3</td><td>23</td><td>0</td><td>60477</td></tr><tr><td>3-23</td><td>3</td><td>23</td><td>1</td><td>7086</td></tr><tr><td>3-24</td><td>3</td><td>24</td><td>0</td><td>57988</td></tr><tr><td>3-24</td><td>3</td><td>24</td><td>1</td><td>7398</td></tr><tr><td>3-25</td><td>3</td><td>25</td><td>0</td><td>60230</td></tr><tr><td>3-25</td><td>3</td><td>25</td><td>1</td><td>6064</td></tr><tr><td>3-26</td><td>3</td><td>26</td><td>1</td><td>7160</td></tr><tr><td>3-26</td><td>3</td><td>26</td><td>0</td><td>59383</td></tr><tr><td>3-27</td><td>3</td><td>27</td><td>0</td><td>61263</td></tr><tr><td>3-27</td><td>3</td><td>27</td><td>1</td><td>6922</td></tr><tr><td>3-28</td><td>3</td><td>28</td><td>1</td><td>6748</td></tr><tr><td>3-28</td><td>3</td><td>28</td><td>0</td><td>59252</td></tr><tr><td>3-29</td><td>3</td><td>29</td><td>1</td><td>6438</td></tr><tr><td>3-29</td><td>3</td><td>29</td><td>0</td><td>61662</td></tr><tr><td>3-30</td><td>3</td><td>30</td><td>0</td><td>61993</td></tr><tr><td>3-30</td><td>3</td><td>30</td><td>1</td><td>7264</td></tr><tr><td>3-31</td><td>3</td><td>31</td><td>1</td><td>6935</td></tr><tr><td>3-31</td><td>3</td><td>31</td><td>0</td><td>58580</td></tr><tr><td>4-1</td><td>4</td><td>1</td><td>1</td><td>6115</td></tr><tr><td>4-1</td><td>4</td><td>1</td><td>0</td><td>59349</td></tr><tr><td>4-2</td><td>4</td><td>2</td><td>0</td><td>55936</td></tr><tr><td>4-2</td><td>4</td><td>2</td><td>1</td><td>9760</td></tr><tr><td>4-3</td><td>4</td><td>3</td><td>0</td><td>57311</td></tr><tr><td>4-3</td><td>4</td><td>3</td><td>1</td><td>10349</td></tr><tr><td>4-4</td><td>4</td><td>4</td><td>1</td><td>8377</td></tr><tr><td>4-4</td><td>4</td><td>4</td><td>0</td><td>56325</td></tr><tr><td>4-5</td><td>4</td><td>5</td><td>0</td><td>59463</td></tr><tr><td>4-5</td><td>4</td><td>5</td><td>1</td><td>6821</td></tr><tr><td>4-6</td><td>4</td><td>6</td><td>0</td><td>57327</td></tr><tr><td>4-6</td><td>4</td><td>6</td><td>1</td><td>9901</td></tr><tr><td>4-7</td><td>4</td><td>7</td><td>0</td><td>55345</td></tr><tr><td>4-7</td><td>4</td><td>7</td><td>1</td><td>8896</td></tr><tr><td>4-8</td><td>4</td><td>8</td><td>1</td><td>7772</td></tr><tr><td>4-8</td><td>4</td><td>8</td><td>0</td><td>57647</td></tr><tr><td>4-9</td><td>4</td><td>9</td><td>1</td><td>8698</td></tr><tr><td>4-9</td><td>4</td><td>9</td><td>0</td><td>56373</td></tr><tr><td>4-10</td><td>4</td><td>10</td><td>1</td><td>9018</td></tr><tr><td>4-10</td><td>4</td><td>10</td><td>0</td><td>58680</td></tr><tr><td>4-11</td><td>4</td><td>11</td><td>1</td><td>4886</td></tr><tr><td>4-11</td><td>4</td><td>11</td><td>0</td><td>60512</td></tr><tr><td>4-12</td><td>4</td><td>12</td><td>1</td><td>4521</td></tr><tr><td>4-12</td><td>4</td><td>12</td><td>0</td><td>63633</td></tr><tr><td>4-13</td><td>4</td><td>13</td><td>0</td><td>62708</td></tr><tr><td>4-13</td><td>4</td><td>13</td><td>1</td><td>6455</td></tr><tr><td>4-14</td><td>4</td><td>14</td><td>0</td><td>59883</td></tr><tr><td>4-14</td><td>4</td><td>14</td><td>1</td><td>4307</td></tr><tr><td>4-15</td><td>4</td><td>15</td><td>0</td><td>57410</td></tr><tr><td>4-15</td><td>4</td><td>15</td><td>1</td><td>7171</td></tr><tr><td>4-16</td><td>4</td><td>16</td><td>1</td><td>8215</td></tr><tr><td>4-16</td><td>4</td><td>16</td><td>0</td><td>55242</td></tr><tr><td>4-17</td><td>4</td><td>17</td><td>0</td><td>59117</td></tr><tr><td>4-17</td><td>4</td><td>17</td><td>1</td><td>7906</td></tr><tr><td>4-18</td><td>4</td><td>18</td><td>0</td><td>59553</td></tr><tr><td>4-18</td><td>4</td><td>18</td><td>1</td><td>4963</td></tr><tr><td>4-19</td><td>4</td><td>19</td><td>0</td><td>62547</td></tr><tr><td>4-19</td><td>4</td><td>19</td><td>1</td><td>5609</td></tr><tr><td>4-20</td><td>4</td><td>20</td><td>0</td><td>61922</td></tr><tr><td>4-20</td><td>4</td><td>20</td><td>1</td><td>6924</td></tr><tr><td>4-21</td><td>4</td><td>21</td><td>1</td><td>5946</td></tr><tr><td>4-21</td><td>4</td><td>21</td><td>0</td><td>58943</td></tr><tr><td>4-22</td><td>4</td><td>22</td><td>0</td><td>60551</td></tr><tr><td>4-22</td><td>4</td><td>22</td><td>1</td><td>5321</td></tr><tr><td>4-23</td><td>4</td><td>23</td><td>0</td><td>59963</td></tr><tr><td>4-23</td><td>4</td><td>23</td><td>1</td><td>5598</td></tr><tr><td>4-24</td><td>4</td><td>24</td><td>0</td><td>61025</td></tr><tr><td>4-24</td><td>4</td><td>24</td><td>1</td><td>6632</td></tr><tr><td>4-25</td><td>4</td><td>25</td><td>1</td><td>6654</td></tr><tr><td>4-25</td><td>4</td><td>25</td><td>0</td><td>58123</td></tr><tr><td>4-26</td><td>4</td><td>26</td><td>0</td><td>60980</td></tr><tr><td>4-26</td><td>4</td><td>26</td><td>1</td><td>6797</td></tr><tr><td>4-27</td><td>4</td><td>27</td><td>0</td><td>61497</td></tr><tr><td>4-27</td><td>4</td><td>27</td><td>1</td><td>7635</td></tr><tr><td>4-28</td><td>4</td><td>28</td><td>0</td><td>59797</td></tr><tr><td>4-28</td><td>4</td><td>28</td><td>1</td><td>5234</td></tr><tr><td>4-29</td><td>4</td><td>29</td><td>1</td><td>5601</td></tr><tr><td>4-29</td><td>4</td><td>29</td><td>0</td><td>59274</td></tr><tr><td>4-30</td><td>4</td><td>30</td><td>0</td><td>58395</td></tr><tr><td>4-30</td><td>4</td><td>30</td><td>1</td><td>6972</td></tr><tr><td>5-1</td><td>5</td><td>1</td><td>1</td><td>6870</td></tr><tr><td>5-1</td><td>5</td><td>1</td><td>0</td><td>60986</td></tr><tr><td>5-2</td><td>5</td><td>2</td><td>1</td><td>5546</td></tr><tr><td>5-2</td><td>5</td><td>2</td><td>0</td><td>59214</td></tr><tr><td>5-3</td><td>5</td><td>3</td><td>0</td><td>58859</td></tr><tr><td>5-3</td><td>5</td><td>3</td><td>1</td><td>8569</td></tr><tr><td>5-4</td><td>5</td><td>4</td><td>0</td><td>61820</td></tr><tr><td>5-4</td><td>5</td><td>4</td><td>1</td><td>7428</td></tr><tr><td>5-5</td><td>5</td><td>5</td><td>0</td><td>58115</td></tr><tr><td>5-5</td><td>5</td><td>5</td><td>1</td><td>6876</td></tr><tr><td>5-6</td><td>5</td><td>6</td><td>0</td><td>58921</td></tr><tr><td>5-6</td><td>5</td><td>6</td><td>1</td><td>6576</td></tr><tr><td>5-7</td><td>5</td><td>7</td><td>1</td><td>5236</td></tr><tr><td>5-7</td><td>5</td><td>7</td><td>0</td><td>60414</td></tr><tr><td>5-8</td><td>5</td><td>8</td><td>0</td><td>61893</td></tr><tr><td>5-8</td><td>5</td><td>8</td><td>1</td><td>6131</td></tr><tr><td>5-9</td><td>5</td><td>9</td><td>0</td><td>58152</td></tr><tr><td>5-9</td><td>5</td><td>9</td><td>1</td><td>7015</td></tr><tr><td>5-10</td><td>5</td><td>10</td><td>0</td><td>59079</td></tr><tr><td>5-10</td><td>5</td><td>10</td><td>1</td><td>8144</td></tr><tr><td>5-11</td><td>5</td><td>11</td><td>0</td><td>60787</td></tr><tr><td>5-11</td><td>5</td><td>11</td><td>1</td><td>8688</td></tr><tr><td>5-12</td><td>5</td><td>12</td><td>1</td><td>5830</td></tr><tr><td>5-12</td><td>5</td><td>12</td><td>0</td><td>59533</td></tr><tr><td>5-13</td><td>5</td><td>13</td><td>0</td><td>58924</td></tr><tr><td>5-13</td><td>5</td><td>13</td><td>1</td><td>6159</td></tr><tr><td>5-14</td><td>5</td><td>14</td><td>0</td><td>57366</td></tr><tr><td>5-14</td><td>5</td><td>14</td><td>1</td><td>7561</td></tr><tr><td>5-15</td><td>5</td><td>15</td><td>1</td><td>7875</td></tr><tr><td>5-15</td><td>5</td><td>15</td><td>0</td><td>59554</td></tr><tr><td>5-16</td><td>5</td><td>16</td><td>1</td><td>7535</td></tr><tr><td>5-16</td><td>5</td><td>16</td><td>0</td><td>57813</td></tr><tr><td>5-17</td><td>5</td><td>17</td><td>0</td><td>59857</td></tr><tr><td>5-17</td><td>5</td><td>17</td><td>1</td><td>8697</td></tr><tr><td>5-18</td><td>5</td><td>18</td><td>0</td><td>59953</td></tr><tr><td>5-18</td><td>5</td><td>18</td><td>1</td><td>9575</td></tr><tr><td>5-19</td><td>5</td><td>19</td><td>0</td><td>56505</td></tr><tr><td>5-19</td><td>5</td><td>19</td><td>1</td><td>9030</td></tr><tr><td>5-20</td><td>5</td><td>20</td><td>0</td><td>56217</td></tr><tr><td>5-20</td><td>5</td><td>20</td><td>1</td><td>9399</td></tr><tr><td>5-21</td><td>5</td><td>21</td><td>0</td><td>56973</td></tr><tr><td>5-21</td><td>5</td><td>21</td><td>1</td><td>9127</td></tr><tr><td>5-22</td><td>5</td><td>22</td><td>0</td><td>60470</td></tr><tr><td>5-22</td><td>5</td><td>22</td><td>1</td><td>8114</td></tr><tr><td>5-23</td><td>5</td><td>23</td><td>0</td><td>58846</td></tr><tr><td>5-23</td><td>5</td><td>23</td><td>1</td><td>6621</td></tr><tr><td>5-24</td><td>5</td><td>24</td><td>1</td><td>7406</td></tr><tr><td>5-24</td><td>5</td><td>24</td><td>0</td><td>58734</td></tr><tr><td>5-25</td><td>5</td><td>25</td><td>0</td><td>59129</td></tr><tr><td>5-25</td><td>5</td><td>25</td><td>1</td><td>9143</td></tr><tr><td>5-26</td><td>5</td><td>26</td><td>0</td><td>55387</td></tr><tr><td>5-26</td><td>5</td><td>26</td><td>1</td><td>9554</td></tr><tr><td>5-27</td><td>5</td><td>27</td><td>0</td><td>53176</td></tr><tr><td>5-27</td><td>5</td><td>27</td><td>1</td><td>8413</td></tr><tr><td>5-28</td><td>5</td><td>28</td><td>0</td><td>55717</td></tr><tr><td>5-28</td><td>5</td><td>28</td><td>1</td><td>6345</td></tr><tr><td>5-29</td><td>5</td><td>29</td><td>1</td><td>6732</td></tr><tr><td>5-29</td><td>5</td><td>29</td><td>0</td><td>58640</td></tr><tr><td>5-30</td><td>5</td><td>30</td><td>0</td><td>57303</td></tr><tr><td>5-30</td><td>5</td><td>30</td><td>1</td><td>7382</td></tr><tr><td>5-31</td><td>5</td><td>31</td><td>0</td><td>57991</td></tr><tr><td>5-31</td><td>5</td><td>31</td><td>1</td><td>9762</td></tr><tr><td>6-1</td><td>6</td><td>1</td><td>1</td><td>9977</td></tr><tr><td>6-1</td><td>6</td><td>1</td><td>0</td><td>59253</td></tr><tr><td>6-2</td><td>6</td><td>2</td><td>1</td><td>8493</td></tr><tr><td>6-2</td><td>6</td><td>2</td><td>0</td><td>56619</td></tr><tr><td>6-3</td><td>6</td><td>3</td><td>1</td><td>7141</td></tr><tr><td>6-3</td><td>6</td><td>3</td><td>0</td><td>58845</td></tr><tr><td>6-4</td><td>6</td><td>4</td><td>0</td><td>58847</td></tr><tr><td>6-4</td><td>6</td><td>4</td><td>1</td><td>7783</td></tr><tr><td>6-5</td><td>6</td><td>5</td><td>0</td><td>60504</td></tr><tr><td>6-5</td><td>6</td><td>5</td><td>1</td><td>9074</td></tr><tr><td>6-6</td><td>6</td><td>6</td><td>1</td><td>7110</td></tr><tr><td>6-6</td><td>6</td><td>6</td><td>0</td><td>60139</td></tr><tr><td>6-7</td><td>6</td><td>7</td><td>0</td><td>61574</td></tr><tr><td>6-7</td><td>6</td><td>7</td><td>1</td><td>8400</td></tr><tr><td>6-8</td><td>6</td><td>8</td><td>0</td><td>61480</td></tr><tr><td>6-8</td><td>6</td><td>8</td><td>1</td><td>9639</td></tr><tr><td>6-9</td><td>6</td><td>9</td><td>1</td><td>10261</td></tr><tr><td>6-9</td><td>6</td><td>9</td><td>0</td><td>58016</td></tr><tr><td>6-10</td><td>6</td><td>10</td><td>1</td><td>8935</td></tr><tr><td>6-10</td><td>6</td><td>10</td><td>0</td><td>59424</td></tr><tr><td>6-11</td><td>6</td><td>11</td><td>0</td><td>59808</td></tr><tr><td>6-11</td><td>6</td><td>11</td><td>1</td><td>9238</td></tr><tr><td>6-12</td><td>6</td><td>12</td><td>1</td><td>8982</td></tr><tr><td>6-12</td><td>6</td><td>12</td><td>0</td><td>62117</td></tr><tr><td>6-13</td><td>6</td><td>13</td><td>0</td><td>59535</td></tr><tr><td>6-13</td><td>6</td><td>13</td><td>1</td><td>9468</td></tr><tr><td>6-14</td><td>6</td><td>14</td><td>1</td><td>10622</td></tr><tr><td>6-14</td><td>6</td><td>14</td><td>0</td><td>59612</td></tr><tr><td>6-15</td><td>6</td><td>15</td><td>1</td><td>12070</td></tr><tr><td>6-15</td><td>6</td><td>15</td><td>0</td><td>58272</td></tr><tr><td>6-16</td><td>6</td><td>16</td><td>0</td><td>56230</td></tr><tr><td>6-16</td><td>6</td><td>16</td><td>1</td><td>11750</td></tr><tr><td>6-17</td><td>6</td><td>17</td><td>0</td><td>57295</td></tr><tr><td>6-17</td><td>6</td><td>17</td><td>1</td><td>10687</td></tr><tr><td>6-18</td><td>6</td><td>18</td><td>1</td><td>11021</td></tr><tr><td>6-18</td><td>6</td><td>18</td><td>0</td><td>57318</td></tr><tr><td>6-19</td><td>6</td><td>19</td><td>1</td><td>12260</td></tr><tr><td>6-19</td><td>6</td><td>19</td><td>0</td><td>56864</td></tr><tr><td>6-20</td><td>6</td><td>20</td><td>0</td><td>58506</td></tr><tr><td>6-20</td><td>6</td><td>20</td><td>1</td><td>10172</td></tr><tr><td>6-21</td><td>6</td><td>21</td><td>1</td><td>10861</td></tr><tr><td>6-21</td><td>6</td><td>21</td><td>0</td><td>60174</td></tr><tr><td>6-22</td><td>6</td><td>22</td><td>0</td><td>61132</td></tr><tr><td>6-22</td><td>6</td><td>22</td><td>1</td><td>10561</td></tr><tr><td>6-23</td><td>6</td><td>23</td><td>1</td><td>12214</td></tr><tr><td>6-23</td><td>6</td><td>23</td><td>0</td><td>56301</td></tr><tr><td>6-24</td><td>6</td><td>24</td><td>1</td><td>11056</td></tr><tr><td>6-24</td><td>6</td><td>24</td><td>0</td><td>57540</td></tr><tr><td>6-25</td><td>6</td><td>25</td><td>0</td><td>59966</td></tr><tr><td>6-25</td><td>6</td><td>25</td><td>1</td><td>9403</td></tr><tr><td>6-26</td><td>6</td><td>26</td><td>1</td><td>10583</td></tr><tr><td>6-26</td><td>6</td><td>26</td><td>0</td><td>60201</td></tr><tr><td>6-27</td><td>6</td><td>27</td><td>1</td><td>9446</td></tr><tr><td>6-27</td><td>6</td><td>27</td><td>0</td><td>60031</td></tr><tr><td>6-28</td><td>6</td><td>28</td><td>1</td><td>12662</td></tr><tr><td>6-28</td><td>6</td><td>28</td><td>0</td><td>57733</td></tr><tr><td>6-29</td><td>6</td><td>29</td><td>1</td><td>8220</td></tr><tr><td>6-29</td><td>6</td><td>29</td><td>0</td><td>63993</td></tr><tr><td>6-30</td><td>6</td><td>30</td><td>0</td><td>59186</td></tr><tr><td>6-30</td><td>6</td><td>30</td><td>1</td><td>9587</td></tr><tr><td>7-1</td><td>7</td><td>1</td><td>1</td><td>11026</td></tr><tr><td>7-1</td><td>7</td><td>1</td><td>0</td><td>56310</td></tr><tr><td>7-2</td><td>7</td><td>2</td><td>1</td><td>7489</td></tr><tr><td>7-2</td><td>7</td><td>2</td><td>0</td><td>58076</td></tr><tr><td>7-3</td><td>7</td><td>3</td><td>0</td><td>54621</td></tr><tr><td>7-3</td><td>7</td><td>3</td><td>1</td><td>5015</td></tr><tr><td>7-4</td><td>7</td><td>4</td><td>1</td><td>3884</td></tr><tr><td>7-4</td><td>7</td><td>4</td><td>0</td><td>53178</td></tr><tr><td>7-5</td><td>7</td><td>5</td><td>0</td><td>60358</td></tr><tr><td>7-5</td><td>7</td><td>5</td><td>1</td><td>8520</td></tr><tr><td>7-6</td><td>7</td><td>6</td><td>0</td><td>59642</td></tr><tr><td>7-6</td><td>7</td><td>6</td><td>1</td><td>10760</td></tr><tr><td>7-7</td><td>7</td><td>7</td><td>1</td><td>9089</td></tr><tr><td>7-7</td><td>7</td><td>7</td><td>0</td><td>59790</td></tr><tr><td>7-8</td><td>7</td><td>8</td><td>1</td><td>10227</td></tr><tr><td>7-8</td><td>7</td><td>8</td><td>0</td><td>58908</td></tr><tr><td>7-9</td><td>7</td><td>9</td><td>0</td><td>61341</td></tr><tr><td>7-9</td><td>7</td><td>9</td><td>1</td><td>8259</td></tr><tr><td>7-10</td><td>7</td><td>10</td><td>0</td><td>61741</td></tr><tr><td>7-10</td><td>7</td><td>10</td><td>1</td><td>9847</td></tr><tr><td>7-11</td><td>7</td><td>11</td><td>1</td><td>7880</td></tr><tr><td>7-11</td><td>7</td><td>11</td><td>0</td><td>62210</td></tr><tr><td>7-12</td><td>7</td><td>12</td><td>1</td><td>9361</td></tr><tr><td>7-12</td><td>7</td><td>12</td><td>0</td><td>61633</td></tr><tr><td>7-13</td><td>7</td><td>13</td><td>0</td><td>60445</td></tr><tr><td>7-13</td><td>7</td><td>13</td><td>1</td><td>11561</td></tr><tr><td>7-14</td><td>7</td><td>14</td><td>0</td><td>57114</td></tr><tr><td>7-14</td><td>7</td><td>14</td><td>1</td><td>11612</td></tr><tr><td>7-15</td><td>7</td><td>15</td><td>1</td><td>11920</td></tr><tr><td>7-15</td><td>7</td><td>15</td><td>0</td><td>56844</td></tr><tr><td>7-16</td><td>7</td><td>16</td><td>0</td><td>60637</td></tr><tr><td>7-16</td><td>7</td><td>16</td><td>1</td><td>9064</td></tr><tr><td>7-17</td><td>7</td><td>17</td><td>1</td><td>10486</td></tr><tr><td>7-17</td><td>7</td><td>17</td><td>0</td><td>60022</td></tr><tr><td>7-18</td><td>7</td><td>18</td><td>1</td><td>11384</td></tr><tr><td>7-18</td><td>7</td><td>18</td><td>0</td><td>58055</td></tr><tr><td>7-19</td><td>7</td><td>19</td><td>0</td><td>61245</td></tr><tr><td>7-19</td><td>7</td><td>19</td><td>1</td><td>10630</td></tr><tr><td>7-20</td><td>7</td><td>20</td><td>0</td><td>59514</td></tr><tr><td>7-20</td><td>7</td><td>20</td><td>1</td><td>12483</td></tr><tr><td>7-21</td><td>7</td><td>21</td><td>0</td><td>55666</td></tr><tr><td>7-21</td><td>7</td><td>21</td><td>1</td><td>12345</td></tr><tr><td>7-22</td><td>7</td><td>22</td><td>0</td><td>56395</td></tr><tr><td>7-22</td><td>7</td><td>22</td><td>1</td><td>11855</td></tr><tr><td>7-23</td><td>7</td><td>23</td><td>1</td><td>13228</td></tr><tr><td>7-23</td><td>7</td><td>23</td><td>0</td><td>55051</td></tr><tr><td>7-24</td><td>7</td><td>24</td><td>1</td><td>12599</td></tr><tr><td>7-24</td><td>7</td><td>24</td><td>0</td><td>58405</td></tr><tr><td>7-25</td><td>7</td><td>25</td><td>1</td><td>10801</td></tr><tr><td>7-25</td><td>7</td><td>25</td><td>0</td><td>58218</td></tr><tr><td>7-26</td><td>7</td><td>26</td><td>1</td><td>8890</td></tr><tr><td>7-26</td><td>7</td><td>26</td><td>0</td><td>62961</td></tr><tr><td>7-27</td><td>7</td><td>27</td><td>1</td><td>9794</td></tr><tr><td>7-27</td><td>7</td><td>27</td><td>0</td><td>61850</td></tr><tr><td>7-28</td><td>7</td><td>28</td><td>1</td><td>11131</td></tr><tr><td>7-28</td><td>7</td><td>28</td><td>0</td><td>57548</td></tr><tr><td>7-29</td><td>7</td><td>29</td><td>1</td><td>10077</td></tr><tr><td>7-29</td><td>7</td><td>29</td><td>0</td><td>59166</td></tr><tr><td>7-30</td><td>7</td><td>30</td><td>0</td><td>58416</td></tr><tr><td>7-30</td><td>7</td><td>30</td><td>1</td><td>10844</td></tr><tr><td>7-31</td><td>7</td><td>31</td><td>1</td><td>11257</td></tr><tr><td>7-31</td><td>7</td><td>31</td><td>0</td><td>60221</td></tr><tr><td>8-1</td><td>8</td><td>1</td><td>0</td><td>58525</td></tr><tr><td>8-1</td><td>8</td><td>1</td><td>1</td><td>11229</td></tr><tr><td>8-2</td><td>8</td><td>2</td><td>0</td><td>57465</td></tr><tr><td>8-2</td><td>8</td><td>2</td><td>1</td><td>12437</td></tr><tr><td>8-3</td><td>8</td><td>3</td><td>1</td><td>13081</td></tr><tr><td>8-3</td><td>8</td><td>3</td><td>0</td><td>57562</td></tr><tr><td>8-4</td><td>8</td><td>4</td><td>1</td><td>11433</td></tr><tr><td>8-4</td><td>8</td><td>4</td><td>0</td><td>57259</td></tr><tr><td>8-5</td><td>8</td><td>5</td><td>1</td><td>8471</td></tr><tr><td>8-5</td><td>8</td><td>5</td><td>0</td><td>61271</td></tr><tr><td>8-6</td><td>8</td><td>6</td><td>0</td><td>60277</td></tr><tr><td>8-6</td><td>8</td><td>6</td><td>1</td><td>9466</td></tr><tr><td>8-7</td><td>8</td><td>7</td><td>1</td><td>11618</td></tr><tr><td>8-7</td><td>8</td><td>7</td><td>0</td><td>58939</td></tr><tr><td>8-8</td><td>8</td><td>8</td><td>1</td><td>11672</td></tr><tr><td>8-8</td><td>8</td><td>8</td><td>0</td><td>56201</td></tr><tr><td>8-9</td><td>8</td><td>9</td><td>0</td><td>59307</td></tr><tr><td>8-9</td><td>8</td><td>9</td><td>1</td><td>10978</td></tr><tr><td>8-10</td><td>8</td><td>10</td><td>0</td><td>59506</td></tr><tr><td>8-10</td><td>8</td><td>10</td><td>1</td><td>11852</td></tr><tr><td>8-11</td><td>8</td><td>11</td><td>0</td><td>54896</td></tr><tr><td>8-11</td><td>8</td><td>11</td><td>1</td><td>12401</td></tr><tr><td>8-12</td><td>8</td><td>12</td><td>0</td><td>57466</td></tr><tr><td>8-12</td><td>8</td><td>12</td><td>1</td><td>10352</td></tr><tr><td>8-13</td><td>8</td><td>13</td><td>0</td><td>56575</td></tr><tr><td>8-13</td><td>8</td><td>13</td><td>1</td><td>11181</td></tr><tr><td>8-14</td><td>8</td><td>14</td><td>0</td><td>59490</td></tr><tr><td>8-14</td><td>8</td><td>14</td><td>1</td><td>10757</td></tr><tr><td>8-15</td><td>8</td><td>15</td><td>0</td><td>58101</td></tr><tr><td>8-15</td><td>8</td><td>15</td><td>1</td><td>9576</td></tr><tr><td>8-16</td><td>8</td><td>16</td><td>0</td><td>61565</td></tr><tr><td>8-16</td><td>8</td><td>16</td><td>1</td><td>8873</td></tr><tr><td>8-17</td><td>8</td><td>17</td><td>0</td><td>60956</td></tr><tr><td>8-17</td><td>8</td><td>17</td><td>1</td><td>10056</td></tr><tr><td>8-18</td><td>8</td><td>18</td><td>1</td><td>10687</td></tr><tr><td>8-18</td><td>8</td><td>18</td><td>0</td><td>55695</td></tr><tr><td>8-19</td><td>8</td><td>19</td><td>0</td><td>57036</td></tr><tr><td>8-19</td><td>8</td><td>19</td><td>1</td><td>9740</td></tr><tr><td>8-20</td><td>8</td><td>20</td><td>0</td><td>55024</td></tr><tr><td>8-20</td><td>8</td><td>20</td><td>1</td><td>11488</td></tr><tr><td>8-21</td><td>8</td><td>21</td><td>1</td><td>10816</td></tr><tr><td>8-21</td><td>8</td><td>21</td><td>0</td><td>58269</td></tr><tr><td>8-22</td><td>8</td><td>22</td><td>1</td><td>6728</td></tr><tr><td>8-22</td><td>8</td><td>22</td><td>0</td><td>59735</td></tr><tr><td>8-23</td><td>8</td><td>23</td><td>1</td><td>6927</td></tr><tr><td>8-23</td><td>8</td><td>23</td><td>0</td><td>62485</td></tr><tr><td>8-24</td><td>8</td><td>24</td><td>1</td><td>6488</td></tr><tr><td>8-24</td><td>8</td><td>24</td><td>0</td><td>64160</td></tr><tr><td>8-25</td><td>8</td><td>25</td><td>1</td><td>5445</td></tr><tr><td>8-25</td><td>8</td><td>25</td><td>0</td><td>60529</td></tr><tr><td>8-26</td><td>8</td><td>26</td><td>1</td><td>4770</td></tr><tr><td>8-26</td><td>8</td><td>26</td><td>0</td><td>60981</td></tr><tr><td>8-27</td><td>8</td><td>27</td><td>1</td><td>5387</td></tr><tr><td>8-27</td><td>8</td><td>27</td><td>0</td><td>59852</td></tr><tr><td>8-28</td><td>8</td><td>28</td><td>0</td><td>60855</td></tr><tr><td>8-28</td><td>8</td><td>28</td><td>1</td><td>6502</td></tr><tr><td>8-29</td><td>8</td><td>29</td><td>1</td><td>5593</td></tr><tr><td>8-29</td><td>8</td><td>29</td><td>0</td><td>59074</td></tr><tr><td>8-30</td><td>8</td><td>30</td><td>1</td><td>4812</td></tr><tr><td>8-30</td><td>8</td><td>30</td><td>0</td><td>62881</td></tr><tr><td>8-31</td><td>8</td><td>31</td><td>1</td><td>7047</td></tr><tr><td>8-31</td><td>8</td><td>31</td><td>0</td><td>61954</td></tr><tr><td>9-1</td><td>9</td><td>1</td><td>0</td><td>56813</td></tr><tr><td>9-1</td><td>9</td><td>1</td><td>1</td><td>6381</td></tr><tr><td>9-2</td><td>9</td><td>2</td><td>0</td><td>55713</td></tr><tr><td>9-2</td><td>9</td><td>2</td><td>1</td><td>4696</td></tr><tr><td>9-3</td><td>9</td><td>3</td><td>1</td><td>5340</td></tr><tr><td>9-3</td><td>9</td><td>3</td><td>0</td><td>54711</td></tr><tr><td>9-4</td><td>9</td><td>4</td><td>1</td><td>5336</td></tr><tr><td>9-4</td><td>9</td><td>4</td><td>0</td><td>58454</td></tr><tr><td>9-5</td><td>9</td><td>5</td><td>1</td><td>5218</td></tr><tr><td>9-5</td><td>9</td><td>5</td><td>0</td><td>56655</td></tr><tr><td>9-6</td><td>9</td><td>6</td><td>0</td><td>57069</td></tr><tr><td>9-6</td><td>9</td><td>6</td><td>1</td><td>5533</td></tr><tr><td>9-7</td><td>9</td><td>7</td><td>1</td><td>6730</td></tr><tr><td>9-7</td><td>9</td><td>7</td><td>0</td><td>59027</td></tr><tr><td>9-8</td><td>9</td><td>8</td><td>0</td><td>55350</td></tr><tr><td>9-8</td><td>9</td><td>8</td><td>1</td><td>6657</td></tr><tr><td>9-9</td><td>9</td><td>9</td><td>1</td><td>5008</td></tr><tr><td>9-9</td><td>9</td><td>9</td><td>0</td><td>56703</td></tr><tr><td>9-10</td><td>9</td><td>10</td><td>0</td><td>55175</td></tr><tr><td>9-10</td><td>9</td><td>10</td><td>1</td><td>6325</td></tr><tr><td>9-11</td><td>9</td><td>11</td><td>0</td><td>59168</td></tr><tr><td>9-11</td><td>9</td><td>11</td><td>1</td><td>4703</td></tr><tr><td>9-12</td><td>9</td><td>12</td><td>1</td><td>4396</td></tr><tr><td>9-12</td><td>9</td><td>12</td><td>0</td><td>57993</td></tr><tr><td>9-13</td><td>9</td><td>13</td><td>1</td><td>5405</td></tr><tr><td>9-13</td><td>9</td><td>13</td><td>0</td><td>61106</td></tr><tr><td>9-14</td><td>9</td><td>14</td><td>1</td><td>5595</td></tr><tr><td>9-14</td><td>9</td><td>14</td><td>0</td><td>62413</td></tr><tr><td>9-15</td><td>9</td><td>15</td><td>1</td><td>3710</td></tr><tr><td>9-15</td><td>9</td><td>15</td><td>0</td><td>59498</td></tr><tr><td>9-16</td><td>9</td><td>16</td><td>0</td><td>59312</td></tr><tr><td>9-16</td><td>9</td><td>16</td><td>1</td><td>4549</td></tr><tr><td>9-17</td><td>9</td><td>17</td><td>1</td><td>5772</td></tr><tr><td>9-17</td><td>9</td><td>17</td><td>0</td><td>59193</td></tr><tr><td>9-18</td><td>9</td><td>18</td><td>1</td><td>7434</td></tr><tr><td>9-18</td><td>9</td><td>18</td><td>0</td><td>60036</td></tr><tr><td>9-19</td><td>9</td><td>19</td><td>1</td><td>5574</td></tr><tr><td>9-19</td><td>9</td><td>19</td><td>0</td><td>58454</td></tr><tr><td>9-20</td><td>9</td><td>20</td><td>0</td><td>61267</td></tr><tr><td>9-20</td><td>9</td><td>20</td><td>1</td><td>6161</td></tr><tr><td>9-21</td><td>9</td><td>21</td><td>1</td><td>7618</td></tr><tr><td>9-21</td><td>9</td><td>21</td><td>0</td><td>60727</td></tr><tr><td>9-22</td><td>9</td><td>22</td><td>1</td><td>5364</td></tr><tr><td>9-22</td><td>9</td><td>22</td><td>0</td><td>58401</td></tr><tr><td>9-23</td><td>9</td><td>23</td><td>1</td><td>3852</td></tr><tr><td>9-23</td><td>9</td><td>23</td><td>0</td><td>60523</td></tr><tr><td>9-24</td><td>9</td><td>24</td><td>0</td><td>60569</td></tr><tr><td>9-24</td><td>9</td><td>24</td><td>1</td><td>4487</td></tr><tr><td>9-25</td><td>9</td><td>25</td><td>0</td><td>60946</td></tr><tr><td>9-25</td><td>9</td><td>25</td><td>1</td><td>6829</td></tr><tr><td>9-26</td><td>9</td><td>26</td><td>1</td><td>6674</td></tr><tr><td>9-26</td><td>9</td><td>26</td><td>0</td><td>57265</td></tr><tr><td>9-27</td><td>9</td><td>27</td><td>1</td><td>4483</td></tr><tr><td>9-27</td><td>9</td><td>27</td><td>0</td><td>63272</td></tr><tr><td>9-28</td><td>9</td><td>28</td><td>0</td><td>64183</td></tr><tr><td>9-28</td><td>9</td><td>28</td><td>1</td><td>5145</td></tr><tr><td>9-29</td><td>9</td><td>29</td><td>1</td><td>5415</td></tr><tr><td>9-29</td><td>9</td><td>29</td><td>0</td><td>58692</td></tr><tr><td>9-30</td><td>9</td><td>30</td><td>1</td><td>5364</td></tr><tr><td>9-30</td><td>9</td><td>30</td><td>0</td><td>59112</td></tr><tr><td>10-1</td><td>10</td><td>1</td><td>1</td><td>5058</td></tr><tr><td>10-1</td><td>10</td><td>1</td><td>0</td><td>59915</td></tr><tr><td>10-2</td><td>10</td><td>2</td><td>1</td><td>5907</td></tr><tr><td>10-2</td><td>10</td><td>2</td><td>0</td><td>61734</td></tr><tr><td>10-3</td><td>10</td><td>3</td><td>0</td><td>60047</td></tr><tr><td>10-3</td><td>10</td><td>3</td><td>1</td><td>4369</td></tr><tr><td>10-4</td><td>10</td><td>4</td><td>0</td><td>63441</td></tr><tr><td>10-4</td><td>10</td><td>4</td><td>1</td><td>4599</td></tr><tr><td>10-5</td><td>10</td><td>5</td><td>1</td><td>5280</td></tr><tr><td>10-5</td><td>10</td><td>5</td><td>0</td><td>64489</td></tr><tr><td>10-6</td><td>10</td><td>6</td><td>1</td><td>4859</td></tr><tr><td>10-6</td><td>10</td><td>6</td><td>0</td><td>58847</td></tr><tr><td>10-7</td><td>10</td><td>7</td><td>0</td><td>58633</td></tr><tr><td>10-7</td><td>10</td><td>7</td><td>1</td><td>4772</td></tr><tr><td>10-8</td><td>10</td><td>8</td><td>1</td><td>6696</td></tr><tr><td>10-8</td><td>10</td><td>8</td><td>0</td><td>57954</td></tr><tr><td>10-9</td><td>10</td><td>9</td><td>0</td><td>58521</td></tr><tr><td>10-9</td><td>10</td><td>9</td><td>1</td><td>8732</td></tr><tr><td>10-10</td><td>10</td><td>10</td><td>0</td><td>60096</td></tr><tr><td>10-10</td><td>10</td><td>10</td><td>1</td><td>4507</td></tr><tr><td>10-11</td><td>10</td><td>11</td><td>1</td><td>7294</td></tr><tr><td>10-11</td><td>10</td><td>11</td><td>0</td><td>60065</td></tr><tr><td>10-12</td><td>10</td><td>12</td><td>1</td><td>6058</td></tr><tr><td>10-12</td><td>10</td><td>12</td><td>0</td><td>63574</td></tr><tr><td>10-13</td><td>10</td><td>13</td><td>0</td><td>59011</td></tr><tr><td>10-13</td><td>10</td><td>13</td><td>1</td><td>5544</td></tr><tr><td>10-14</td><td>10</td><td>14</td><td>1</td><td>6490</td></tr><tr><td>10-14</td><td>10</td><td>14</td><td>0</td><td>58126</td></tr><tr><td>10-15</td><td>10</td><td>15</td><td>0</td><td>58500</td></tr><tr><td>10-15</td><td>10</td><td>15</td><td>1</td><td>6863</td></tr><tr><td>10-16</td><td>10</td><td>16</td><td>0</td><td>62375</td></tr><tr><td>10-16</td><td>10</td><td>16</td><td>1</td><td>5945</td></tr><tr><td>10-17</td><td>10</td><td>17</td><td>1</td><td>3849</td></tr><tr><td>10-17</td><td>10</td><td>17</td><td>0</td><td>61061</td></tr><tr><td>10-18</td><td>10</td><td>18</td><td>1</td><td>5303</td></tr><tr><td>10-18</td><td>10</td><td>18</td><td>0</td><td>63170</td></tr><tr><td>10-19</td><td>10</td><td>19</td><td>1</td><td>5774</td></tr><tr><td>10-19</td><td>10</td><td>19</td><td>0</td><td>63997</td></tr><tr><td>10-20</td><td>10</td><td>20</td><td>0</td><td>59983</td></tr><tr><td>10-20</td><td>10</td><td>20</td><td>1</td><td>4841</td></tr><tr><td>10-21</td><td>10</td><td>21</td><td>0</td><td>60442</td></tr><tr><td>10-21</td><td>10</td><td>21</td><td>1</td><td>4540</td></tr><tr><td>10-22</td><td>10</td><td>22</td><td>0</td><td>60130</td></tr><tr><td>10-22</td><td>10</td><td>22</td><td>1</td><td>5195</td></tr><tr><td>10-23</td><td>10</td><td>23</td><td>1</td><td>7146</td></tr><tr><td>10-23</td><td>10</td><td>23</td><td>0</td><td>60536</td></tr><tr><td>10-24</td><td>10</td><td>24</td><td>1</td><td>5793</td></tr><tr><td>10-24</td><td>10</td><td>24</td><td>0</td><td>58235</td></tr><tr><td>10-25</td><td>10</td><td>25</td><td>1</td><td>5205</td></tr><tr><td>10-25</td><td>10</td><td>25</td><td>0</td><td>62409</td></tr><tr><td>10-26</td><td>10</td><td>26</td><td>1</td><td>5926</td></tr><tr><td>10-26</td><td>10</td><td>26</td><td>0</td><td>63508</td></tr><tr><td>10-27</td><td>10</td><td>27</td><td>0</td><td>58875</td></tr><tr><td>10-27</td><td>10</td><td>27</td><td>1</td><td>4782</td></tr><tr><td>10-28</td><td>10</td><td>28</td><td>0</td><td>57130</td></tr><tr><td>10-28</td><td>10</td><td>28</td><td>1</td><td>6076</td></tr><tr><td>10-29</td><td>10</td><td>29</td><td>1</td><td>4808</td></tr><tr><td>10-29</td><td>10</td><td>29</td><td>0</td><td>58340</td></tr><tr><td>10-30</td><td>10</td><td>30</td><td>0</td><td>58919</td></tr><tr><td>10-30</td><td>10</td><td>30</td><td>1</td><td>5482</td></tr><tr><td>10-31</td><td>10</td><td>31</td><td>1</td><td>3669</td></tr><tr><td>10-31</td><td>10</td><td>31</td><td>0</td><td>53025</td></tr><tr><td>11-1</td><td>11</td><td>1</td><td>0</td><td>61125</td></tr><tr><td>11-1</td><td>11</td><td>1</td><td>1</td><td>4680</td></tr><tr><td>11-2</td><td>11</td><td>2</td><td>1</td><td>5957</td></tr><tr><td>11-2</td><td>11</td><td>2</td><td>0</td><td>61575</td></tr><tr><td>11-3</td><td>11</td><td>3</td><td>1</td><td>4725</td></tr><tr><td>11-3</td><td>11</td><td>3</td><td>0</td><td>58368</td></tr><tr><td>11-4</td><td>11</td><td>4</td><td>1</td><td>4832</td></tr><tr><td>11-4</td><td>11</td><td>4</td><td>0</td><td>59318</td></tr><tr><td>11-5</td><td>11</td><td>5</td><td>1</td><td>6676</td></tr><tr><td>11-5</td><td>11</td><td>5</td><td>0</td><td>57124</td></tr><tr><td>11-6</td><td>11</td><td>6</td><td>1</td><td>6357</td></tr><tr><td>11-6</td><td>11</td><td>6</td><td>0</td><td>59951</td></tr><tr><td>11-7</td><td>11</td><td>7</td><td>0</td><td>58567</td></tr><tr><td>11-7</td><td>11</td><td>7</td><td>1</td><td>4282</td></tr><tr><td>11-8</td><td>11</td><td>8</td><td>0</td><td>61460</td></tr><tr><td>11-8</td><td>11</td><td>8</td><td>1</td><td>4599</td></tr><tr><td>11-9</td><td>11</td><td>9</td><td>1</td><td>7888</td></tr><tr><td>11-9</td><td>11</td><td>9</td><td>0</td><td>61122</td></tr><tr><td>11-10</td><td>11</td><td>10</td><td>1</td><td>5096</td></tr><tr><td>11-10</td><td>11</td><td>10</td><td>0</td><td>58826</td></tr><tr><td>11-11</td><td>11</td><td>11</td><td>1</td><td>5056</td></tr><tr><td>11-11</td><td>11</td><td>11</td><td>0</td><td>59345</td></tr><tr><td>11-12</td><td>11</td><td>12</td><td>1</td><td>5390</td></tr><tr><td>11-12</td><td>11</td><td>12</td><td>0</td><td>59514</td></tr><tr><td>11-13</td><td>11</td><td>13</td><td>0</td><td>61856</td></tr><tr><td>11-13</td><td>11</td><td>13</td><td>1</td><td>5904</td></tr><tr><td>11-14</td><td>11</td><td>14</td><td>1</td><td>4262</td></tr><tr><td>11-14</td><td>11</td><td>14</td><td>0</td><td>59983</td></tr><tr><td>11-15</td><td>11</td><td>15</td><td>1</td><td>8423</td></tr><tr><td>11-15</td><td>11</td><td>15</td><td>0</td><td>57628</td></tr><tr><td>11-16</td><td>11</td><td>16</td><td>1</td><td>8476</td></tr><tr><td>11-16</td><td>11</td><td>16</td><td>0</td><td>60347</td></tr><tr><td>11-17</td><td>11</td><td>17</td><td>1</td><td>7214</td></tr><tr><td>11-17</td><td>11</td><td>17</td><td>0</td><td>57643</td></tr><tr><td>11-18</td><td>11</td><td>18</td><td>1</td><td>6920</td></tr><tr><td>11-18</td><td>11</td><td>18</td><td>0</td><td>57548</td></tr><tr><td>11-19</td><td>11</td><td>19</td><td>0</td><td>58411</td></tr><tr><td>11-19</td><td>11</td><td>19</td><td>1</td><td>5436</td></tr><tr><td>11-20</td><td>11</td><td>20</td><td>1</td><td>6316</td></tr><tr><td>11-20</td><td>11</td><td>20</td><td>0</td><td>60233</td></tr><tr><td>11-21</td><td>11</td><td>21</td><td>1</td><td>6022</td></tr><tr><td>11-21</td><td>11</td><td>21</td><td>0</td><td>57498</td></tr><tr><td>11-22</td><td>11</td><td>22</td><td>1</td><td>4672</td></tr><tr><td>11-22</td><td>11</td><td>22</td><td>0</td><td>54377</td></tr><tr><td>11-23</td><td>11</td><td>23</td><td>1</td><td>3068</td></tr><tr><td>11-23</td><td>11</td><td>23</td><td>0</td><td>52889</td></tr><tr><td>11-24</td><td>11</td><td>24</td><td>0</td><td>54683</td></tr><tr><td>11-24</td><td>11</td><td>24</td><td>1</td><td>3555</td></tr><tr><td>11-25</td><td>11</td><td>25</td><td>1</td><td>4319</td></tr><tr><td>11-25</td><td>11</td><td>25</td><td>0</td><td>61332</td></tr><tr><td>11-26</td><td>11</td><td>26</td><td>0</td><td>54770</td></tr><tr><td>11-26</td><td>11</td><td>26</td><td>1</td><td>7957</td></tr><tr><td>11-27</td><td>11</td><td>27</td><td>0</td><td>59028</td></tr><tr><td>11-27</td><td>11</td><td>27</td><td>1</td><td>6818</td></tr><tr><td>11-28</td><td>11</td><td>28</td><td>1</td><td>6249</td></tr><tr><td>11-28</td><td>11</td><td>28</td><td>0</td><td>60441</td></tr><tr><td>11-29</td><td>11</td><td>29</td><td>0</td><td>62289</td></tr><tr><td>11-29</td><td>11</td><td>29</td><td>1</td><td>5832</td></tr><tr><td>11-30</td><td>11</td><td>30</td><td>0</td><td>62752</td></tr><tr><td>11-30</td><td>11</td><td>30</td><td>1</td><td>5210</td></tr><tr><td>12-1</td><td>12</td><td>1</td><td>0</td><td>57756</td></tr><tr><td>12-1</td><td>12</td><td>1</td><td>1</td><td>4520</td></tr><tr><td>12-2</td><td>12</td><td>2</td><td>1</td><td>5688</td></tr><tr><td>12-2</td><td>12</td><td>2</td><td>0</td><td>56376</td></tr><tr><td>12-3</td><td>12</td><td>3</td><td>1</td><td>4526</td></tr><tr><td>12-3</td><td>12</td><td>3</td><td>0</td><td>57747</td></tr><tr><td>12-4</td><td>12</td><td>4</td><td>0</td><td>59878</td></tr><tr><td>12-4</td><td>12</td><td>4</td><td>1</td><td>4876</td></tr><tr><td>12-5</td><td>12</td><td>5</td><td>1</td><td>4868</td></tr><tr><td>12-5</td><td>12</td><td>5</td><td>0</td><td>56628</td></tr><tr><td>12-6</td><td>12</td><td>6</td><td>0</td><td>60372</td></tr><tr><td>12-6</td><td>12</td><td>6</td><td>1</td><td>4718</td></tr><tr><td>12-7</td><td>12</td><td>7</td><td>1</td><td>5496</td></tr><tr><td>12-7</td><td>12</td><td>7</td><td>0</td><td>61307</td></tr><tr><td>12-8</td><td>12</td><td>8</td><td>0</td><td>55077</td></tr><tr><td>12-8</td><td>12</td><td>8</td><td>1</td><td>5328</td></tr><tr><td>12-9</td><td>12</td><td>9</td><td>0</td><td>54096</td></tr><tr><td>12-9</td><td>12</td><td>9</td><td>1</td><td>5827</td></tr><tr><td>12-10</td><td>12</td><td>10</td><td>0</td><td>56691</td></tr><tr><td>12-10</td><td>12</td><td>10</td><td>1</td><td>4977</td></tr><tr><td>12-11</td><td>12</td><td>11</td><td>0</td><td>58674</td></tr><tr><td>12-11</td><td>12</td><td>11</td><td>1</td><td>5332</td></tr><tr><td>12-12</td><td>12</td><td>12</td><td>1</td><td>4791</td></tr><tr><td>12-12</td><td>12</td><td>12</td><td>0</td><td>56630</td></tr><tr><td>12-13</td><td>12</td><td>13</td><td>1</td><td>5930</td></tr><tr><td>12-13</td><td>12</td><td>13</td><td>0</td><td>59096</td></tr><tr><td>12-14</td><td>12</td><td>14</td><td>1</td><td>7672</td></tr><tr><td>12-14</td><td>12</td><td>14</td><td>0</td><td>58954</td></tr><tr><td>12-15</td><td>12</td><td>15</td><td>1</td><td>8134</td></tr><tr><td>12-15</td><td>12</td><td>15</td><td>0</td><td>53697</td></tr><tr><td>12-16</td><td>12</td><td>16</td><td>1</td><td>7703</td></tr><tr><td>12-16</td><td>12</td><td>16</td><td>0</td><td>54713</td></tr><tr><td>12-17</td><td>12</td><td>17</td><td>0</td><td>52762</td></tr><tr><td>12-17</td><td>12</td><td>17</td><td>1</td><td>10101</td></tr><tr><td>12-18</td><td>12</td><td>18</td><td>1</td><td>11148</td></tr><tr><td>12-18</td><td>12</td><td>18</td><td>0</td><td>54160</td></tr><tr><td>12-19</td><td>12</td><td>19</td><td>1</td><td>8281</td></tr><tr><td>12-19</td><td>12</td><td>19</td><td>0</td><td>57325</td></tr><tr><td>12-20</td><td>12</td><td>20</td><td>0</td><td>57408</td></tr><tr><td>12-20</td><td>12</td><td>20</td><td>1</td><td>10257</td></tr><tr><td>12-21</td><td>12</td><td>21</td><td>1</td><td>11014</td></tr><tr><td>12-21</td><td>12</td><td>21</td><td>0</td><td>57548</td></tr><tr><td>12-22</td><td>12</td><td>22</td><td>0</td><td>57020</td></tr><tr><td>12-22</td><td>12</td><td>22</td><td>1</td><td>10343</td></tr><tr><td>12-23</td><td>12</td><td>23</td><td>0</td><td>56407</td></tr><tr><td>12-23</td><td>12</td><td>23</td><td>1</td><td>10763</td></tr><tr><td>12-24</td><td>12</td><td>24</td><td>0</td><td>47431</td></tr><tr><td>12-24</td><td>12</td><td>24</td><td>1</td><td>6169</td></tr><tr><td>12-25</td><td>12</td><td>25</td><td>0</td><td>47940</td></tr><tr><td>12-25</td><td>12</td><td>25</td><td>1</td><td>4893</td></tr><tr><td>12-26</td><td>12</td><td>26</td><td>1</td><td>11577</td></tr><tr><td>12-26</td><td>12</td><td>26</td><td>0</td><td>54604</td></tr><tr><td>12-27</td><td>12</td><td>27</td><td>0</td><td>52188</td></tr><tr><td>12-27</td><td>12</td><td>27</td><td>1</td><td>14647</td></tr><tr><td>12-28</td><td>12</td><td>28</td><td>0</td><td>52850</td></tr><tr><td>12-28</td><td>12</td><td>28</td><td>1</td><td>13090</td></tr><tr><td>12-29</td><td>12</td><td>29</td><td>0</td><td>53775</td></tr><tr><td>12-29</td><td>12</td><td>29</td><td>1</td><td>12438</td></tr><tr><td>12-30</td><td>12</td><td>30</td><td>0</td><td>54669</td></tr><tr><td>12-30</td><td>12</td><td>30</td><td>1</td><td>11984</td></tr><tr><td>12-31</td><td>12</td><td>31</td><td>1</td><td>5953</td></tr><tr><td>12-31</td><td>12</td><td>31</td><td>0</td><td>48752</td></tr></tbody></table></div>"]}}],"execution_count":35},{"cell_type":"markdown","source":["Along a similar vein of thinking, we decided to add the interaction of `CRS_Dep_Time` and `Day_Of_Week` along with the interaction of `CRS_Arr_Time` and `Day_Of_Week` to produce `Dep_Time_Of_Week` and `Arr_Time_Of_Week` respectively. We discovered that there are certain times of day that encounter a higher likelihood of departure delays, depending on the day of the week these times fall on. But to ensure there are not too many categories in this new categorical feature, we will interact the binned times with the `Day_Of_Week` for each interaction.\n\nFinally, we considered that there may be some inherent relationship between the origin airport and the destination airport with respect to departure delays that may be well captured via an interaction between the two features. Namely, during our EDA, we saw that more popular flights (such as between SFO (San Francisco) and LAX (Los Angeles)) also saw higher levels of departure delays, whereas less popular flights (such as between SEA (Seattle) and PHX (Pheonix)) saw lower levels of departure delays. Thus, we chose to interact `Origin` and `Dest` to form the categorical feature `Origin_Dest` for our dataset. All the interactions discussed are added using the provided code and a few examples are shown below:"],"metadata":{}},{"cell_type":"code","source":["# Given a tuple specifying the two features to interact and the new name of the feature,\n# Creates an interaction term corresponding to each tuple\ndef AddInteractions(df, featurePairsAndNewFeatureNames):\n  for (feature1, feature2, newName) in featurePairsAndNewFeatureNames:\n    if (newName in df.columns):\n      print(\"Variable '\" + newName + \"' already exists\")\n      continue\n    \n    # Generate interaction feature (concatenation of two features)\n    df = df.withColumn(newName, F.concat(F.col(feature1), F.lit('-'), F.col(feature2)))\n    \n  return df\n\n# Make interaction features on airlines dataset\n# Note that interactions are independentently defined for each record\ninteractions = [('Month', 'Day_Of_Month', 'Day_Of_Year'), \n                ('Origin', 'Dest', 'Origin_Dest'),\n                ('Day_Of_Week', 'CRS_Dep_Time_bin', 'Dep_Time_Of_Week'),\n                ('Day_Of_Week', 'CRS_Arr_Time_bin', 'Arr_Time_Of_Week')]\nintFeatureNames = [i[2] for i in interactions]\nairlines = AddInteractions(airlines, interactions)\n\ndisplay(airlines.select(['Month', 'Day_Of_Month', 'Day_Of_Year', 'Day_Of_Week', 'CRS_Dep_Time_bin', 'Dep_Time_Of_Week', 'Day_Of_Week', 'CRS_Arr_Time_bin', 'Arr_Time_Of_Week', 'Origin', 'Dest', 'Origin_Dest']).take(6))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Month</th><th>Day_Of_Month</th><th>Day_Of_Year</th><th>Day_Of_Week</th><th>CRS_Dep_Time_bin</th><th>Dep_Time_Of_Week</th><th>Day_Of_Week</th><th>CRS_Arr_Time_bin</th><th>Arr_Time_Of_Week</th><th>Origin</th><th>Dest</th><th>Origin_Dest</th></tr></thead><tbody><tr><td>6</td><td>1</td><td>6-1</td><td>6</td><td>144</td><td>6-144</td><td>6</td><td>232</td><td>6-232</td><td>SAN</td><td>BOS</td><td>SAN-BOS</td></tr><tr><td>6</td><td>1</td><td>6-1</td><td>6</td><td>144</td><td>6-144</td><td>6</td><td>180</td><td>6-180</td><td>JFK</td><td>LAX</td><td>JFK-LAX</td></tr><tr><td>6</td><td>1</td><td>6-1</td><td>6</td><td>145</td><td>6-145</td><td>6</td><td>232</td><td>6-232</td><td>LAX</td><td>JFK</td><td>LAX-JFK</td></tr><tr><td>6</td><td>1</td><td>6-1</td><td>6</td><td>110</td><td>6-110</td><td>6</td><td>122</td><td>6-122</td><td>BWI</td><td>BOS</td><td>BWI-BOS</td></tr><tr><td>6</td><td>1</td><td>6-1</td><td>6</td><td>231</td><td>6-231</td><td>6</td><td>15</td><td>6-15</td><td>MCO</td><td>BQN</td><td>MCO-BQN</td></tr><tr><td>6</td><td>25</td><td>6-25</td><td>2</td><td>180</td><td>2-180</td><td>2</td><td>201</td><td>2-201</td><td>ROC</td><td>ATL</td><td>ROC-ATL</td></tr></tbody></table></div>"]}}],"execution_count":37},{"cell_type":"markdown","source":["### Adding a Holiday Feature\nWith the `Day_Of_Year` variable in mind, we'd noted during the EDA that the likelihood of a departure delay, as well as the number of flights occuring on a given day of the year seemed to have some relationship with the commonly celebrated holidays in the United States. Take Christmas Day, which always falls on December 25th. If we examine the plot shown previously, there generally appeared to be a lower probability of delay on Christmas Day and Christmas Eve, with higher probabilities immediately before and after those two days. Intuitively, one would expect a higher probability of departure delay as people try to get home for the holidays or leave promptly after the holidays are over; but on the day of holidays, people generally stay home (and thus experience less probability of departure delay). \n\nThere are a variety of cases where holidays and days near holidays seem to reflect something about the likelihood of a flight experiencing a departure delay. For this reason, we attempted to capture this information by joining a dataset of government holidays to our original *Airlines Delays* dataset and construct the `Holiday` feature. This feature is a categorical feature indicating whether a flight occurs before, after, or on a holiday, or is not in any way related to a holiday. Because the *Holidays* dataset is much smaller compared to the *Airline Delays* dataset and will fit in memory, we will join this dataset to *Airline Delays* via a broadcast join after it has been prepared with before and after limits for specific government holidays. Note that the limits for whether a flight occurs before or after a holiday is dependent on the day of the week in addition to government holidays that are near the flight date. This feature construction is done in the following code with a few examples shown below with new feature:"],"metadata":{}},{"cell_type":"code","source":["def AddHolidayFeature(df):\n  if ('Holiday' in df.columns):\n      print(\"Variable 'Holiday' already exists\")\n      return df\n  \n  # Import dataset of government holidays\n  holiday_df_raw = spark.read.csv(\"dbfs:/user/shajikk@ischool.berkeley.edu/scratch/\" + 'holidays.csv').toPandas()\n  holiday_df_raw.columns = ['ID', 'FL_DATE', 'Holiday']\n\n  # Get limits for a given date when we'll likely see \"near holiday\" conditions hold\n  # This is more ofr the purpose of helping to capture likely long-weekend conditions\n  # that could influence departure delays near holidays\n  def get_limits(date):\n    given_date = dt.datetime.strptime(date,'%Y-%m-%d')\n    this_day = given_date.strftime('%a')\n\n    lastSun = given_date + relativedelta(weekday=SU(-1))\n    lastMon = given_date + relativedelta(weekday=MO(-1))\n    lastTue = given_date + relativedelta(weekday=TU(-1))\n    lastWed = given_date + relativedelta(weekday=WE(-1))\n    lastThu = given_date + relativedelta(weekday=TH(-1))\n    lastFri = given_date + relativedelta(weekday=FR(-1))\n    lastSat = given_date + relativedelta(weekday=SA(-1))\n    thisSun = given_date + relativedelta(weekday=SU(1))\n    thisMon = given_date + relativedelta(weekday=MO(1))\n    thisTue = given_date + relativedelta(weekday=TU(1))\n    thisWed = given_date + relativedelta(weekday=WE(1))\n    thisThu = given_date + relativedelta(weekday=TH(1))\n    thisFri = given_date + relativedelta(weekday=FR(1))\n    thisSat = given_date + relativedelta(weekday=SA(1)) \n\n    if this_day == 'Sun' : prev, nxt = lastFri, thisMon\n    if this_day == 'Mon' : prev, nxt = lastFri, thisMon\n    if this_day == 'Tue' : prev, nxt = lastFri, thisTue\n    if this_day == 'Wed' : prev, nxt = lastFri, thisWed\n    if this_day == 'Thu' : prev, nxt = lastWed, thisSun\n    if this_day == 'Fri' : prev, nxt = lastThu, thisMon\n    if this_day == 'Sat' : prev, nxt = lastFri, thisMon\n\n    return prev.strftime(\"%Y-%m-%d\"), prev.strftime('%a'), nxt.strftime(\"%Y-%m-%d\"), nxt.strftime('%a')\n\n  # Construct a holiday dataframe for days that fall before, after, or on a holiday\n  # Consider holidays for all years 2015-2019 individually\n  holiday_df = pd.DataFrame()\n  for index, row in holiday_df_raw.iterrows():\n      prev, prev_day, nxt, nxt_day = get_limits(row['FL_DATE'])\n      line = pd.DataFrame({\"ID\": 0, \"date\": prev, \"holiday\" : 'before'}, index=[index-0.5])\n      holiday_df = holiday_df.append(line, ignore_index=False)\n\n      line = pd.DataFrame({\"ID\": 0, \"date\": row['FL_DATE'], \"holiday\" : 'holiday'}, index=[index])\n      holiday_df = holiday_df.append(line, ignore_index=False)\n\n      line = pd.DataFrame({\"ID\": 0, \"date\": nxt, \"holiday\" : 'after'}, index=[index+0.5])\n      holiday_df = holiday_df.append(line, ignore_index=False)\n\n  holiday_df = holiday_df.sort_index().reset_index(drop=True).drop(\"ID\",  axis=1)\n\n  # Convert holidays pandas dataframe to a pyspark dataframe for easier joining\n  schema = StructType([StructField(\"FL_DATE\", StringType(), True), StructField(\"Holiday\", StringType(), True)])\n  holiday = spark.createDataFrame(holiday_df, schema)\n  \n  # Add new holiday/no holiday column to dataset\n  return df.join(F.broadcast(holiday), df.FL_Date == holiday.FL_DATE, how='left').drop(holiday.FL_DATE).na.fill(\"not holiday\")\n\n# Add holidays indicator to airlines dataset\n# Note that holidays are known well in advance of a flight and are not specific to the training dataset\nholFeatureNames = ['Holiday']\nairlines = AddHolidayFeature(airlines)\ndisplay(airlines.select('Year', 'Month', 'Day_Of_Month', 'Day_Of_Week', 'Holiday').sample(fraction=0.0001, seed=9).sample(fraction=0.01, seed=6).take(10))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Year</th><th>Month</th><th>Day_Of_Month</th><th>Day_Of_Week</th><th>Holiday</th></tr></thead><tbody><tr><td>2019</td><td>6</td><td>19</td><td>3</td><td>not holiday</td></tr><tr><td>2019</td><td>5</td><td>7</td><td>2</td><td>not holiday</td></tr><tr><td>2019</td><td>5</td><td>11</td><td>6</td><td>not holiday</td></tr><tr><td>2018</td><td>6</td><td>19</td><td>2</td><td>not holiday</td></tr><tr><td>2018</td><td>12</td><td>31</td><td>1</td><td>holiday</td></tr><tr><td>2018</td><td>12</td><td>12</td><td>3</td><td>not holiday</td></tr><tr><td>2018</td><td>11</td><td>14</td><td>3</td><td>not holiday</td></tr><tr><td>2017</td><td>6</td><td>23</td><td>5</td><td>not holiday</td></tr><tr><td>2017</td><td>6</td><td>19</td><td>1</td><td>not holiday</td></tr><tr><td>2015</td><td>7</td><td>31</td><td>5</td><td>not holiday</td></tr></tbody></table></div>"]}}],"execution_count":39},{"cell_type":"markdown","source":["### Adding an Origin Activity Feature\nAnother intuition based feature that we believed would affect the likelihood of departure delay would be the amount of airline traffic an airport was experiencing around the time that departure was scheduled. Given that busier airports are likely to have busier air traffic control towers and more planes lined up to depart (not to mention more traffic inside of the airport itself as people try to get to their flights), it seemed likely that the amount of activity happening at the origin airport would be indicative of the likelihood of a departure delay. With the `Origin_Activity` feature, we attempt to define a numerical metric that aggregates the \"amount of traffic\" occuring at a given airport during a specific scheduled departure time block on a given day of the year. This aggregated dataset can then be joined back to the *Airline Delays* dataset via a broadcast join, which gives each flight record a count of the scheduled flight activity that would be occuring in the same departure time block and origin airport. This feature is generated below and a few examples are displayed below:"],"metadata":{}},{"cell_type":"code","source":["def AddOriginActivityFeature(df):\n  if ('Origin_Activity' in df.columns):\n      print(\"Variable 'Origin_Activity' already exists\")\n      return df\n  \n  # Construct a flight bucket attribute to group flights occuring on the same day in the same time block originating from the same airport\n  # Compute aggregated statistics for these flight buckets\n  df = df.withColumn(\"flightbucket\", F.concat_ws(\"-\", F.col(\"Year\"), F.col(\"Month\"), F.col(\"Day_Of_Month\"), F.col(\"CRS_Dep_Time_bin\"), F.col(\"Origin\")))\n  originActivityAgg = df.groupBy(\"flightbucket\").count()\n  \n  # Join aggregated statistics back to original dataframe\n  df = df.join(F.broadcast(originActivityAgg), df.flightbucket == originActivityAgg.flightbucket, how='left') \\\n         .drop(originActivityAgg.flightbucket) \\\n         .drop('flightbucket') \\\n         .withColumnRenamed('count', 'Origin_Activity')\n  return df\n\n# Add OriginActivity feature\n# Note that the scheduled origin activity is known well in advance of a flight and is not specific to the training dataset\norgFeatureNames = ['Origin_Activity']\nairlines = AddOriginActivityFeature(airlines)\ndisplay(airlines.select('Year', 'Month', 'Day_Of_Month', 'CRS_Dep_Time_bin', 'Origin', 'Origin_Activity').sample(fraction=0.0001, seed=7).take(6))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Year</th><th>Month</th><th>Day_Of_Month</th><th>CRS_Dep_Time_bin</th><th>Origin</th><th>Origin_Activity</th></tr></thead><tbody><tr><td>2019</td><td>6</td><td>1</td><td>74</td><td>PDX</td><td>5</td></tr><tr><td>2019</td><td>6</td><td>4</td><td>94</td><td>MAF</td><td>1</td></tr><tr><td>2019</td><td>6</td><td>14</td><td>223</td><td>LAS</td><td>3</td></tr><tr><td>2019</td><td>6</td><td>3</td><td>73</td><td>PDX</td><td>2</td></tr><tr><td>2019</td><td>6</td><td>22</td><td>123</td><td>ORD</td><td>3</td></tr><tr><td>2019</td><td>6</td><td>17</td><td>142</td><td>SYR</td><td>1</td></tr></tbody></table></div>"]}}],"execution_count":41},{"cell_type":"markdown","source":["### Applying Breiman's Theorem to Categorical Features"],"metadata":{}},{"cell_type":"markdown","source":["As discussed in the previous secition in EDA task #2, in our original *Airline Delays* dataset, we have three categorical features to consider, and with the addition of our interaction terms and our holiday feature, we have a total of 8 categorical features to consider for training our model. While some of these categorical features have few distinct values, some of them, especially our interaction terms like `Origin_Dest`, can have a very large number of distinct values. Depending on the model we choose following our algorithm exploration section, these large number of distinct values can be cause for concern with respect to the scalability of our algoirthms. For SVMs, this can lead to very large one-hot encoded vectors. For Logistic Regression, this can lead to many (if not too many) unique coefficients to estimate. And with Decision Trees, too many categories can lead to an inordinate number of possible splits for the algorithm to consider and finding the \"best\" split would be computationally prohibitive.\n\nHowever, as we saw in our EDA task, we do have a way of ordering the categories in each categorical feature in a more meaningful way by applying Breiman's Theorem to each of our categorical features. Let's consider again one of our original categorical features `Op_Unique_Carrier` that we'd explored in EDA task #2. The cateogries by themselves, do not have any implicit ordering. Yet, using these distinct categories, we can develop aggregated statistics on the outcome variable `Dep_Del30` to understand how some categories compare to others and rank them--this is the idea behind Breiman's Theorem. Below, we define a function for generating such \"Breiman Ranks\" given a training dataset, with the example shown for the `Op_Unique_Carrier` feature."],"metadata":{}},{"cell_type":"code","source":["# Applies Breiman's Theorem to the categorical feature\n# Generates the ranking of the categories in the provided categorical feature\n# Orders the categories by the average outcome ascending, from integer 1 to n\n# Note that this should only be run on the training data\ndef GenerateBreimanRanks(df, catFeatureName, outcomeName):\n  window = Window.orderBy('avg(' + outcomeName + ')')\n  breimanRanks = df.groupBy(catFeatureName).avg(outcomeName) \\\n                   .sort(F.asc('avg(' + outcomeName + ')')) \\\n                   .withColumn(catFeatureName + \"_brieman\", F.row_number().over(window))\n  return breimanRanks\n\n# Generate example Breiman ranks for Op_Unique_Carrier\nexBreimanRanks = GenerateBreimanRanks(train_and_val, 'Op_Unique_Carrier', outcomeName)\ndisplay(exBreimanRanks)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Op_Unique_Carrier</th><th>avg(Dep_Del30)</th><th>Op_Unique_Carrier_brieman</th></tr></thead><tbody><tr><td>HA</td><td>0.033542917204872985</td><td>1</td></tr><tr><td>AS</td><td>0.06905222712211065</td><td>2</td></tr><tr><td>DL</td><td>0.08529200285416323</td><td>3</td></tr><tr><td>US</td><td>0.08998934214794334</td><td>4</td></tr><tr><td>YX</td><td>0.11116389081807818</td><td>5</td></tr><tr><td>AA</td><td>0.11117867242701317</td><td>6</td></tr><tr><td>OO</td><td>0.11333882967506877</td><td>7</td></tr><tr><td>WN</td><td>0.11723854777220556</td><td>8</td></tr><tr><td>MQ</td><td>0.122757807728906</td><td>9</td></tr><tr><td>EV</td><td>0.12610044862283</td><td>10</td></tr><tr><td>9E</td><td>0.12643153190454035</td><td>11</td></tr><tr><td>UA</td><td>0.1267613877794305</td><td>12</td></tr><tr><td>YV</td><td>0.12680899499746526</td><td>13</td></tr><tr><td>OH</td><td>0.13657707010203773</td><td>14</td></tr><tr><td>VX</td><td>0.13910511232319497</td><td>15</td></tr><tr><td>G4</td><td>0.140810152113623</td><td>16</td></tr><tr><td>NK</td><td>0.14342171719363164</td><td>17</td></tr><tr><td>F9</td><td>0.16404717806819843</td><td>18</td></tr><tr><td>B6</td><td>0.16958981336445994</td><td>19</td></tr></tbody></table></div>"]}}],"execution_count":44},{"cell_type":"markdown","source":["As evident in the output above, we can generate aggregated statistics on the outcome variable for each distinct carrier based ont the sample records present in the dataset for that carrier. Using these aggregated statistics, we can order the categories and assign a ranking from 1 to \\\\(n\\\\), where \\\\(n\\\\) is the number of distinct categories (in this case 19). This ranking is saved in the new feature `Op_Unique_Carrier_brieman`. Given that the table of Breiman ranks is small and can fit in memory (even for \"larger\" categorical features like our interaction terms), we can take these training-set-generated Breiman ranks and independently apply them to the entire *Airline Delays* dataset via a broadcast join, similar to the ones shown previously. This code is shown below. In doing so, we effectively transform our categorical feature into a numerical feature, which reduces the need for 1-hot encoding in SVM as well as the number of coefficients to estimate and splits to consider in the Logistic Regression and Decision Tree algorithms respectively. Note that to properly handle unseen values, we will encode unseen categorical features with a `-1` Brieman rank, as is common practice when transforming categorical features to numerical form."],"metadata":{}},{"cell_type":"code","source":["# Using the provided Breiman's Ranks, applies Breiman's Theorem to the categorical feature\n# and creates a column in the original table using the mapping in breimanRanks variable\n# Note that this effectively transforms the categorical feature to a numerical feature\n# The new column will be the original categorical feature name, suffixed with '_brieman'\ndef ApplyBreimansTheorem(df, breimanRanks, catFeatureName, outcomeName):\n  if (catFeatureName + \"_brieman\" in df.columns):\n    print(\"Variable '\" + catFeatureName + \"_brieman\" + \"' already exists\")\n    return df\n  \n  res = df.join(F.broadcast(breimanRanks), catFeatureName, how='left') \\\n          .drop(breimanRanks['avg(' + outcomeName + ')']) \\\n          .fillna(-1, [catFeatureName + \"_brieman\"])\n  return res"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":46},{"cell_type":"markdown","source":["With these two functions, we can apply Breiman's Theorem to each of our 8 categorical features separately and generate new columns numerical that will be suffixed with `_brieman`. Note that the Breiman ranks will always be generated by referring to the training dataset only. Once these are generated, they can be applied to any dataset, as the ranks are depending on the training dataset and should not be influenced by our test set. This is done below (note that we'll split the dataset again to ensure that our training dataset has all new features that were generated in the previous sections)."],"metadata":{}},{"cell_type":"code","source":["# Regenerate splits for Breiman ranking prep (so have context of new \n# features added that require application of Breiman's Theorem)\nmini_train, train, val, test = SplitDataset(airlines)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">mini_train size = 2129\ntrain size = 21526836\nval size = 3076829\ntest size = 7498430\n</div>"]}}],"execution_count":48},{"cell_type":"code","source":["# Apply breiman ranking to all datasets, based on ranking developed from training data\nbreimanRanksDict = {} # save to apply later as needed\nfeaturesToApplyBreimanRanks = catFeatureNames + intFeatureNames + holFeatureNames\nfor feature in featuresToApplyBreimanRanks:\n  # Get ranks for feature, based on training data only\n  ranksDict = GenerateBreimanRanks(train, feature, outcomeName)\n  breimanRanksDict[feature] = ranksDict\n  \n  # Apply Breiman's theorem & do feature transformation for all datasets\n  mini_train = ApplyBreimansTheorem(mini_train, ranksDict, feature, outcomeName)\n  train = ApplyBreimansTheorem(train, ranksDict, feature, outcomeName)\n  val = ApplyBreimansTheorem(val, ranksDict, feature, outcomeName)\n  test = ApplyBreimansTheorem(test, ranksDict, feature, outcomeName)\n  airlines = ApplyBreimansTheorem(airlines, ranksDict, feature, outcomeName)\n  \nbriFeatureNames = [entry + \"_brieman\" for entry in breimanRanksDict]\n\n# Show examples of Breiman features\nselectCols = []\nfor feature in featuresToApplyBreimanRanks:\n  selectCols.append(feature)\n  selectCols.append(feature + \"_brieman\")\ndisplay(train.select(selectCols).take(10))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Op_Unique_Carrier</th><th>Op_Unique_Carrier_brieman</th><th>Origin</th><th>Origin_brieman</th><th>Dest</th><th>Dest_brieman</th><th>Day_Of_Year</th><th>Day_Of_Year_brieman</th><th>Origin_Dest</th><th>Origin_Dest_brieman</th><th>Dep_Time_Of_Week</th><th>Dep_Time_Of_Week_brieman</th><th>Arr_Time_Of_Week</th><th>Arr_Time_Of_Week_brieman</th><th>Holiday</th><th>Holiday_brieman</th></tr></thead><tbody><tr><td>AA</td><td>5</td><td>CLT</td><td>217</td><td>ATL</td><td>79</td><td>7-1</td><td>326</td><td>CLT-ATL</td><td>1757</td><td>5-2</td><td>422</td><td>5-13</td><td>1000</td><td>before</td><td>4</td></tr><tr><td>AA</td><td>5</td><td>CLT</td><td>217</td><td>RDU</td><td>245</td><td>7-1</td><td>326</td><td>CLT-RDU</td><td>1884</td><td>5-3</td><td>336</td><td>5-11</td><td>992</td><td>before</td><td>4</td></tr><tr><td>HA</td><td>1</td><td>HNL</td><td>7</td><td>ITO</td><td>5</td><td>7-1</td><td>326</td><td>HNL-ITO</td><td>203</td><td>5-50</td><td>80</td><td>5-55</td><td>403</td><td>before</td><td>4</td></tr><tr><td>DL</td><td>3</td><td>FAR</td><td>116</td><td>MSP</td><td>82</td><td>7-1</td><td>326</td><td>FAR-MSP</td><td>1489</td><td>5-50</td><td>80</td><td>5-55</td><td>403</td><td>before</td><td>4</td></tr><tr><td>AA</td><td>5</td><td>MCO</td><td>301</td><td>MIA</td><td>147</td><td>7-1</td><td>326</td><td>MCO-MIA</td><td>3051</td><td>5-50</td><td>80</td><td>5-60</td><td>328</td><td>before</td><td>4</td></tr><tr><td>HA</td><td>1</td><td>HNL</td><td>7</td><td>OGG</td><td>22</td><td>7-1</td><td>326</td><td>HNL-OGG</td><td>194</td><td>5-50</td><td>80</td><td>5-54</td><td>491</td><td>before</td><td>4</td></tr><tr><td>OO</td><td>7</td><td>BJI</td><td>44</td><td>MSP</td><td>82</td><td>7-1</td><td>326</td><td>BJI-MSP</td><td>809</td><td>5-51</td><td>22</td><td>5-61</td><td>312</td><td>before</td><td>4</td></tr><tr><td>AA</td><td>5</td><td>TUL</td><td>88</td><td>DFW</td><td>171</td><td>7-1</td><td>326</td><td>TUL-DFW</td><td>2255</td><td>5-51</td><td>22</td><td>5-61</td><td>312</td><td>before</td><td>4</td></tr><tr><td>AA</td><td>5</td><td>SAT</td><td>120</td><td>DFW</td><td>171</td><td>7-1</td><td>326</td><td>SAT-DFW</td><td>2272</td><td>5-51</td><td>22</td><td>5-61</td><td>312</td><td>before</td><td>4</td></tr><tr><td>DL</td><td>3</td><td>CLT</td><td>217</td><td>ATL</td><td>79</td><td>7-1</td><td>326</td><td>CLT-ATL</td><td>1757</td><td>5-51</td><td>22</td><td>5-61</td><td>312</td><td>before</td><td>4</td></tr></tbody></table></div>"]}}],"execution_count":49},{"cell_type":"markdown","source":["With the application of Breiman's Theorem to our dataset, we now have a series of new features that we will leverage in section V for our chosen algorithm implementation, which are listed below. Note that we have checkpointed this work and saved the updated dataset to parquet format to be read from prior to model training (to avoid needing to re-compute these features)."],"metadata":{}},{"cell_type":"code","source":["print(\"All Available Features:\")\nprint(\"------------------------\")\nprint(\" - Numerical Features: \\t\\t\", numFeatureNames) # numerical features\nprint(\" - Cont. Numerical Features:\\t\", contNumFeatureNames) # numerical features, but have binned versions in binFeatureNames\nprint(\" - Categorical Features: \\t\", catFeatureNames) # categorical features\nprint(\" - Binned Features: \\t\\t\", binFeatureNames) # numerical features\nprint(\" - Interaction Features: \\t\", intFeatureNames) # categorical features\nprint(\" - Holiday Feature: \\t\\t\", holFeatureNames) # categorical features\nprint(\" - Origin Activity Feature: \\t\", orgFeatureNames) # numerical features\nprint(\" - Breiman Ranked Features: \\t\", briFeatureNames) # numerical features"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">All Available Features:\n------------------------\n - Numerical Features: \t\t [&#39;Year&#39;, &#39;Month&#39;, &#39;Day_Of_Month&#39;, &#39;Day_Of_Week&#39;, &#39;Distance_Group&#39;]\n - Cont. Numerical Features:\t [&#39;CRS_Dep_Time&#39;, &#39;CRS_Arr_Time&#39;, &#39;CRS_Elapsed_Time&#39;, &#39;Distance&#39;]\n - Categorical Features: \t [&#39;Op_Unique_Carrier&#39;, &#39;Origin&#39;, &#39;Dest&#39;]\n - Binned Features: \t\t [&#39;CRS_Dep_Time_bin&#39;, &#39;CRS_Arr_Time_bin&#39;, &#39;CRS_Elapsed_Time_bin&#39;]\n - Interaction Features: \t [&#39;Day_Of_Year&#39;, &#39;Origin_Dest&#39;, &#39;Dep_Time_Of_Week&#39;, &#39;Arr_Time_Of_Week&#39;]\n - Holiday Feature: \t\t [&#39;Holiday&#39;]\n - Origin Activity Feature: \t [&#39;Origin_Activity&#39;]\n - Breiman Ranked Features: \t [&#39;Op_Unique_Carrier_brieman&#39;, &#39;Origin_brieman&#39;, &#39;Dest_brieman&#39;, &#39;Day_Of_Year_brieman&#39;, &#39;Origin_Dest_brieman&#39;, &#39;Dep_Time_Of_Week_brieman&#39;, &#39;Arr_Time_Of_Week_brieman&#39;, &#39;Holiday_brieman&#39;]\n</div>"]}}],"execution_count":51},{"cell_type":"markdown","source":["### Balancing the Training Dataset\nIn the EDA task #3 from the previous section, we saw that our entire *Airline Delays* dataset is highly imbalanced, with only 11% of the flight data constituting flights with departure delays. As discussed previously, in order to develop a useful model that isn't biased by the majority class in the training dataset. To address this dataset imbalance issue, we will concentrate on two primary methods: SMOTE and Majority Class Splitting."],"metadata":{}},{"cell_type":"markdown","source":["#### SMOTE (Synthetic Minority Over-sampling Technique) \n\nA dataset is imbalanced if the classes are not approximately equally represented. Training a machine learning model with an imbalanced dataset causes the model to develop a certain bias towards the majority class. To tackle the issue of class imbalance, Synthetic Minority Over-sampling Technique (SMOTE) was introduced by Chawla et al. in 2002.(Chawla, Nitesh V., et al. âSMOTE: synthetic minority over-sampling technique.â Journal of artificial intelligence research16 (2002): 321â357).\n\nUnder-sampling of the majority class or/and over-sampling of the minority class have been proposed as a good means of increasing the sensitivity of a classifier to the minority class. However, under-sampling the majority class samples could potentially lead to loss of important information. Also, over-sampling the minority class could lead to overfitting. The reason is fairly straightforward. Consider the effect on the decision regions in feature space when minority over-sampling is done by replication (sampling with replacement). With replication, the decision region that results in a classification decision for the minority class can actually become smaller and more specific as the minority samples in the region are replicated. This is the opposite of the desired effect. \n\nSMOTE provides a new approach to over-sampling. It is an approach in which the minority class is over-sampled by creating âsyntheticâ examples rather than by over-sampling with replacement. This approach is inspired by a technique that proved successful in handwritten character recognition (Ha & Bunke, 1997). They created extra training data by performing certain operations on real data. In their case, operations like rotation and skew were natural ways to perturb the training data. SMOTe generates synthetic examples in a less application-specific manner, by operating in âfeature spaceâ rather than âdata spaceâ. The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining the k nearest neighbors. Our implementation currently uses seven nearest neighbors.\n\nSynthetic samples are generated in the following way: \n- Take the difference between the feature vector (of the sample) under consideration and the feature vector of its nearest neighbor(s). \n- Multiply this difference by a random number between 0 and 1 to scale the difference.\n- Add the scaled difference to the feature vector under consideration. \n\nThe diagrams below highlight the steps of capturing the region of k-nearest neighbors for a given datapoint (in orange), connecting the datapoint under consideration to is k-nearest neighbors (also in orange) via the blue dotted lines in feature space, and generating a white synthetic datapoint along these blue dotted lines."],"metadata":{}},{"cell_type":"markdown","source":["##### Visualizing SMOTE\n<img src=\"https://github.com/nsandadi/Images/blob/master/Visualizing%20SMOTE.png?raw=true\" width=80%>\n\nSource: https://www.youtube.com/watch?v=FheTDyCwRdE"],"metadata":{}},{"cell_type":"markdown","source":["By following these steps, we can generate a new random point along the line segment between two specific feature vectors to be a new synthetic datapoint. This approach effectively forces the decision region of the minority class to become more general. The synthetic examples cause the classifier to create larger and less specific decision regions (that contain nearby minority class points), rather than smaller and more specific regions. More general regions are now learned for the minority class samples rather than those being subsumed by the majority class samples around them. SMOTE provides more related minority class samples to learn from, thus allowing a learner to carve broader decision regions, leading to more coverage of the minority class. The effect is that models, in theory, will generalize better."],"metadata":{}},{"cell_type":"markdown","source":["##### Deviations from the original paper\n\n1. The number of minority class samples from our training set were approximately two million. However, running K Nearest Neighbors on each of these ~2M samples is not scalable as KNN needs to store the list of ~2M feature vectors in memory. We considered and implemented two approaches to address this scalability challenge:\n  > i. Find KNN of each minority sample (feature vector) from a random sample (0.005%) of all the minority sample (feature vectors). This will produce a list of feature vectors small enough to fit in memory.\n  \n  > ii. Create clusters of minority sample data using K-means algorithm, run KNN on each cluster in parallel and generate synthetic data for each cluster. This approach uses the entire training data. We split the data into 1000 clusters.\n\n  > Out of the above two approaches, we found the second approach took far less time to run (~2.5 hrs vs. 24+ hrs). Also, when we compared the distribution of minority samples from the original training set to all the minority samples after applying SMOTE, the data generated by the second approach matched the original feature distributions of the training set better than the data generated by the first approach. Thus, for the remainder of this analysis, we will proceed with the second approach for balancing our dataset using SMOTE. \n  \n2. The original paper shows that a combination of over-sampling the minority class using SMOTE and under-sampling the majority class can achieve better classifier performance (in ROC space) than plain under-sampling the majority class. We tried random under-sampling with SMOTE but it did not give us better results compared to creating synthetic data without under-sampling the majority class. There are existing \"strategic\" methods for under-sampling such as Near-Miss, Edited Nearest Neighbors Rule and One-Sided Selection. However, these are all implementions in imblearn library which converts the feature vector into numpy array. We cannot use these approaches directly due to scalability issues. For future work, we will try to find a scalable solution for a \"strategic\" under-sampling technique, similar to what we did with creating synthetic data in (1) using K-means.\n\nWe have provided an additional notebook with the full implementation of SMOTE for this project, which can be found here:\n\nhttps://dbc-b1c912e7-d804.cloud.databricks.com/?o=7564214546094626#notebook/2791835342809045/command/814519033153637"],"metadata":{}},{"cell_type":"markdown","source":["##### Implementing SMOTE at Scale\nThe code below provides a summary of the functions we generated for SMOTEing our training dataset. These functions are documented below for reference and have been applied via the notebook mentioned previously."],"metadata":{}},{"cell_type":"code","source":["# HELPER FUNCTIONS\n\nfrom pyspark.ml.clustering import KMeans\n\n# Train a k-means model on the minority samples (feature vectors)\ndef kmeans_model(featureVect, k):\n  \"\"\"\n  Function to run k-means algorithm.\n    arg:\n        featureVect - (dataframe) feature vectors of minority samples\n        k - (int) number of clusters\n    returns:\n        smote_rdd - (dataframe) predictions of k-means for each minority sample\n  \"\"\"\n  kmeans = KMeans().setK(k).setSeed(1)\n  model = kmeans.fit(featureVect)\n  predict = model.transform(featureVect)\n  return predict\n\n\n# Calculate the Euclidean distance between two feature vectors\ndef euclidean_distance(row1, row2):\n  \"\"\"\n  Function to calculate Euclidean distance.\n   arg:\n       row1, row2 - (list) feature vector\n   returns:\n       distance - (float) euclidean distance between two feature vectors\n  \"\"\"\n  distance = 0.0\n  for i in range(len(row1)-1):\n      distance += (row1[i] - row2[i])**2\n  return math.sqrt(distance)\n  \n  \n# Locate the nearest neighbors\ndef get_neighbors(train, test_row, num_neighbors):\n  \"\"\"\n  Function to calculate nearest neighbors.\n   arg:\n       train - (list) list of feature vectors from which to find nearest neighbors\n       test_row - (list) feature vector under consideration whose nearest neighbors must be found\n       num_neighbors - (int) number of nearest neighbors\n   returns:\n       neighbors - (list) nearest neighbors\n  \"\"\"\n  distances = list()\n  for train_row in train:\n      dist = euclidean_distance(test_row, train_row)\n      distances.append((train_row, dist))\n  distances.sort(key=lambda tup: tup[1])\n  neighbors = list()\n  for i in range(num_neighbors):\n      neighbors.append(distances[i+1][0])\n  return neighbors\n  \n  \n# Generate synthetic records\ndef synthetic(list1, list2):\n  \"\"\"\n  Function to generate synthetic data.\n   arg:\n       list1, list2 - (list) feature vectors from which synthetic data point is generated\n   returns:\n       synthetic_records - (list) synthetic data\n  \"\"\"\n  synthetic_records = []\n  for i in range(len(list1)):\n    synthetic_records.append(round(list1[i] + ((list2[i]-list1[i])*random.uniform(0, 1))))\n  return synthetic_records\n\n  \n# RUNNING SMOTE AT SCALE\n# Convert the k-means predictions dataframe into rdd, find nearest neighbors and generate synthetic data\ndef SmoteSampling(predict, k):\n  \"\"\"\n  Function to create an rdd of sunthetic data.\n    arg:\n        predict - (dataframe) k-means predictions\n        k - (int) number of nearest neighbors\n    returns:\n        smote_rdd - (rdd) synthetic data in the form of rows of feature vectors with label 1 or minority class\n  \"\"\"\n  smote_rdd = predict.rdd.map(lambda x: (x[0], [list(x[1])])) \\\n                         .reduceByKey(lambda x,y: x+y) \\\n                         .flatMap(lambda x: [(n, get_neighbors(x[1], n, k)) for n in x[1]]) \\\n                         .flatMap(lambda x: [synthetic(x[0],n) for n in x[1]]) \\\n                         .map(lambda x: Row(features = DenseVector(x), label = 1)) \\\n                         .cache()\n  return smote_rdd\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":58},{"cell_type":"markdown","source":["##### Using SMOTEd Training Data\nWe applied our version of the SMOTE algorithm on the original subset of the training data we have worked with preivously. Since the feature engineering described in earlier in this section has not been applied to our SMOTEd training data, we will apply the same feature engineering steps here as an additional step before being able to use the SMOTEd data for training. The result will also be saved to parquet format to help with training moving forward."],"metadata":{}},{"cell_type":"code","source":["# Apply Feature Engineering described above to smoted training data\n# Provided Breiman ranks dict should be based on unsmoted training data\ndef ApplyFeatureEngineeringToSmotedTrainingData(df, breimanRanksDict):\n  # Select features to ensure features use pascal casing\n  outcomeName = 'Dep_Del30'\n  numFeatureNames = ['Year', 'Month', 'Day_Of_Month', 'Day_Of_Week', 'Distance_Group']\n  contNumFeatureNames = ['CRS_Dep_Time', 'CRS_Arr_Time', 'CRS_Elapsed_Time', 'Distance']\n  catFeatureNames = ['Op_Unique_Carrier', 'Origin', 'Dest']\n  df = df.select([outcomeName] + numFeatureNames + contNumFeatureNames + catFeatureNames)\n  \n  \n  # Bin Continuous Features\n  df = BinFeature(df, 'CRS_Dep_Time', splits = [i for i in range(0, 2400 + 1, 10)]) # 10 min blocks\n  df = BinFeature(df, 'CRS_Arr_Time', splits = [i for i in range(0, 2400 + 1, 10)]) # 10 min blocks\n  df = BinFeature(df, 'CRS_Elapsed_Time', splits = [float(\"-inf\")] + [i for i in range(0, 660 + 1, 60)] + [float(\"inf\")]) # 1-hour blocks\n\n  # Add Interaction Features\n  interactions = [('Month', 'Day_Of_Month', 'Day_Of_Year'), \n                  ('Origin', 'Dest', 'Origin_Dest'),\n                  ('Day_Of_Week', 'CRS_Dep_Time_bin', 'Dep_Time_Of_Week'),\n                  ('Day_Of_Week', 'CRS_Arr_Time_bin', 'Arr_Time_Of_Week')]\n  df = AddInteractions(df, interactions)\n  intFeatureNames = [i[2] for i in interactions]\n\n  # Add FL_Date column (for holiday feature generation)\n  df = df.withColumn('FL_Date', F.concat_ws(\"-\", F.col(\"Year\"), F.col(\"Month\"), F.col(\"Day_Of_Month\")).cast(DateType()))\n  \n  # Add Holiday Feature\n  df = AddHolidayFeature(df)\n  holFeatureNames = ['Holiday']\n\n  # Add Origin Activity Feature\n  df = AddOriginActivityFeature(df)\n\n  # Apply Breiman Ranking\n  featuresToApplyBreimanRanks = catFeatureNames + intFeatureNames + holFeatureNames\n  for feature in featuresToApplyBreimanRanks:\n    # Apply Breiman's method & do feature transformation for all datasets\n    df = ApplyBreimansTheorem(df, breimanRanksDict[feature], feature, outcomeName)\n    \n  return df\n\n# Read prepared data from parquet for training\ndef ReadDataFromParquet(dataName):\n  # Read data back directly from disk \n  return spark.read.option(\"header\", \"true\").parquet(f\"dbfs/user/team20/finalnotebook/airlines_\" + dataName + \".parquet\")\n\n# Prep Smoted training data\ntrain_smoted = ReadDataFromParquet('smoted_train_kmeans')\ntrain_smoted = ApplyFeatureEngineeringToSmotedTrainingData(train_smoted, breimanRanksDict)\ntrain_smoted = WriteAndRefDataToParquet(train_smoted, 'augmented1_smoted_train_kmeans')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":60},{"cell_type":"markdown","source":["#### Majority Class Splitting\nAnother method for balancing the training dataset is with the use of we call the \"Majority Class Splitting\" technique, which is described in the paper \"New Applications of Ensembles of Classifiers\" by Barandela et. al (http://marmota.dlsi.uji.es/WebBIB/papers/2003/paa-2.pdf). Referring to the paper, this is a dataset balancing approach where instead of oversampling the minority class to balance the dataset (similar to what we did with SMOTE), we take an majority lass undersampling approach to get a data subset that is balanced between majority and minority classes. \n\nHowever, unlike the traditional majority class undersampling techniques, majority class splitting will generate multiple balanced subsets of the original dataset. Let's consider a hypothetical case where the ratio of majority to minority classes is 3:1. With the majority class splitting approach, we will take the majority class and randomly split the majority class into 3 parts, where each part is approximately the same size as the minority class. For each of these majority class samples, we will join the sample back with the full minority class. This will in turn generate 3 balanced subsets of the original dataset, each of which contains the full minority class. This technique is depicted in the diagram below:"],"metadata":{}},{"cell_type":"markdown","source":["<img src=\"https://github.com/nsandadi/Images/blob/master/Majority%20Class%20Splitting.png?raw=true\" width=50%>"],"metadata":{}},{"cell_type":"markdown","source":["In the case of the training dataset for the *Airline Delays*, we have a ratio of 7:1 for the majority and minority class, which will generate 7 subsets of data using the majority splitting technique. While this is a possible dataset balance approach for us to use in model training, this approach is best-suited for ensemble approaches, where each model in the ensemble is assigned one balanced subset of data for training. With this approach, each model in the ensemble will have a balanced dataset to learn from, reducing bias in the indiviual models, but no majority class data is lost as would be the case for traditional undersampling techniques. We will explore the use of majority class splitting when we explore ensemble approaches to predicting departure dleays in section V of the report."],"metadata":{}},{"cell_type":"markdown","source":["## IV. Algorithm Exploration\n\n### Considerations for Algorithm Exploration\nIn our original problem statement introduced in section I, we pointed out that the goal of this analysis is to develop a model that is able to predict significant departure delays (30 minutes or more); this inherently is a classification task, where our positive class is where `Dep_Del30 == 1` (delay) and our negative class is `Dep_Del30 == 0` (no delay). As we introduced near the start of section II, to accomplish this classification task, we considered a vareity of models suitable for classification problems for the purpose of our algorithm exploration. Based on our experience working with machine learning models in W207, we decided to consider the following models:\n\n- Logistic Regression\n- Decision Trees\n- Naive Bayes\n- Support Vector Machines\n\nIn picking these models for our initial exploration, we considered a variety of factors in addition to the requirement that we select a model that is well-suited for our classification task. Our three additional considerations for our algorithm selection included the following:\n\n- the resulting model must be interpretable / explainable\n- the algorithm must scale \n- the algorithm must handle continuous and categorical variables\n\nBecause we want to be able to not only predict whether a significant departure delay occurs for a given flight, but also determine the underlying factors that may lead to departure delays, we were also interested in looking at explainable models, thus the consideration of Decision Trees, Logistic Regression, and Naive Bayes. Additionally, given the size of our *Airline Delays* dataset, we wanted to make sure that the models we considered could handle large datasets, such as Decision Trees and Naive Bayes. Finally, given that our dataset includes both numerical and categorical features, we wanted to make sure that we chose a model that was well suited for handling both numerical and categorical features, which all four of these models are able to do so. While not all four of these models satisfy all three of our additional conditions, we decided for the sake of exploration to look at all four regardless."],"metadata":{}},{"cell_type":"markdown","source":["### Applying our Candidate Algorithms\n\nFor the sake of the algorithm exploration, we decided to keep things fairly simple and work off of the original dataset without any major feature engineering or dataset balancing applied to the dataset. That is, for all four algorithms, we will consider all 12 relevant features for predicting departure delays described in section I and our custom-made outcome variable `Dep_Del30`. \n\nNote that because we are not balancing the dataset for this exploration, simply taking a baseline model which predicts the outcome to be 'no delay' (the majority class) at inference time will achieve a high accuracy of about 89%, which practically speaking, is not a useful model as it would fail to identify any true positives. Regardless, for simplicity of this algorithm exploration, we will make use of the original unbalanced, un-feature engineered dataset for high-level exploration. We will also fix any relevant hyperparameters and will not look at exploring any tuning of these hyperparameters.\n\nIn the next few sections of code, we prepare the dataset for our algorithm exploration, as well as our model training and evaluation functions. Note that we will be considering a variety of metrics, including accuracy, precision, recall, F1-score, as well as aggregated metrics such as area under the curve, and the full confusion matrix. This will allow us to understand the full story of how these models perform in a baseline scenario."],"metadata":{}},{"cell_type":"code","source":["# Define outcome & features to use in model development\n# numFeatureNames & contNumFeatureNAmes are continuous features\n# catFeatureNames are categorical features\noutcomeName = 'Dep_Del30'\nnumFeatureNames = ['Year', 'Month', 'Day_Of_Month', 'Day_Of_Week', 'Distance_Group']\ncontNumFeatureNames = ['CRS_Dep_Time', 'CRS_Arr_Time', 'CRS_Elapsed_Time', 'Distance']\ncatFeatureNames = ['Op_Unique_Carrier', 'Origin', 'Dest']\n\n# subset the dataset to the features in numFeatureNames, contNumFeatureNames  & catFeatureNames (the original features) & our outcome\nmini_train_algo = mini_train.select([outcomeName] + numFeatureNames + contNumFeatureNames + catFeatureNames)\ntrain_algo = train.select([outcomeName] + numFeatureNames + contNumFeatureNames + catFeatureNames)\nval_algo = val.select([outcomeName] + numFeatureNames + contNumFeatureNames + catFeatureNames)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":66},{"cell_type":"code","source":["# This function is for training all four of our candidate models in baseline scenarios \n# Only support vector machines (svm) use one hot encoding for the categorical variable \ndef train_model(df,algorithm,categoricalCols,continuousCols,labelCol,svmflag):\n\n    indexers = [ StringIndexer(inputCol=cat, outputCol= cat + \"_indexed\", handleInvalid=\"keep\") for cat in categoricalCols ]\n  \n    # If it is svm do hot encoding\n    if svmflag == True:\n      encoder = OneHotEncoderEstimator(inputCols=[indexer.getOutputCol() for indexer in indexers],\n                                 outputCols=[\"{0}_encoded\".format(indexer.getOutputCol()) for indexer in indexers])\n      assembler = VectorAssembler(inputCols=encoder.getOutputCols() + continuousCols, outputCol=\"features\")\n    # else skip it\n    else:\n      assembler = VectorAssembler(inputCols = continuousCols + [cat + \"_indexed\" for cat in categoricalCols], outputCol = \"features\")\n      \n    # choose the appropriate model constrution, depending on the algorithm  \n    if algorithm == 'lr':\n      lr = LogisticRegression(labelCol = outcomeName, featuresCol=\"features\", maxIter=100, regParam=0.1, elasticNetParam=0)\n      pipeline = Pipeline(stages=indexers + [assembler,lr])\n\n    elif algorithm == 'dt':\n      dt = DecisionTreeClassifier(labelCol = outcomeName, featuresCol = \"features\", seed = 6, maxDepth = 8, maxBins=366)\n      pipeline = Pipeline(stages=indexers + [assembler,dt])\n      \n    elif algorithm == 'nb':\n      # set the CRS_Elapsed_Time to 0 if its negative\n      df = df.withColumn('CRS_Elapsed_Time', when(df['CRS_Elapsed_Time'] < 0, 0.0).otherwise(df['CRS_Elapsed_Time']))\n\n      nb = NaiveBayes(labelCol = outcomeName, featuresCol = \"features\", smoothing = 1)\n      pipeline = Pipeline(stages=indexers + [assembler,nb])\n      \n    elif algorithm == 'svm':\n      svc = LinearSVC(labelCol = outcomeName, featuresCol = \"features\", maxIter=50, regParam=0.1)\n      pipeline = Pipeline(stages=indexers + [encoder,assembler,svc])\n      \n    else:\n      pass\n    \n    tr_model=pipeline.fit(df)\n\n    return tr_model"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":67},{"cell_type":"code","source":["# Model Evaluation\n# This function takes predictions dataframe and outcomeName, evaluates the predictions,\n# and calculates the scores for multiple metrics.\n# If the returnval is true it will return the values otherwise it will print it.\n# Predictions must have two columns: prediction & label\ndef EvaluateModelPredictions(predict_df, dataName=None, outcomeName='label', ReturnVal=False):\n    \n    if not ReturnVal :\n      print(\"Model Evaluation - \" + dataName)\n      print(\"-----------------------------\")\n      \n    evaluation_df = (predict_df \\\n                     .withColumn('metric', F.concat(F.col(outcomeName), F.lit('-'), F.col(\"prediction\"))).groupBy(\"metric\") \\\n                     .count() \\\n                     .toPandas() \\\n                     .assign(label = lambda df: df.metric.map({'1-1.0': 'TP', '1-0.0': 'FN', '0-0.0': 'TN', '0-1.0' : 'FP'})))\n    metric = evaluation_df.set_index(\"label\").to_dict()['count']\n    \n    # Default missing metrics to 0\n    for key in ['TP', 'TN', 'FP', 'FN']:\n      metric[key] = metric.get(key, 0)\n      \n\t# Compute metrics\n    total = metric['TP'] + metric['FN'] + metric['TN'] + metric['FP']\n    accuracy = 0 if (total == 0) else (metric['TP'] + metric['TN'])/total\n    precision = 0 if ((metric['TP'] + metric['FP']) == 0) else metric['TP'] /(metric['TP'] + metric['FP'])\n    recall = 0 if ((metric['TP'] + metric['FN']) == 0) else metric['TP'] /(metric['TP'] + metric['FN'])\n    fscore = 0 if (precision+recall) == 0 else 2 * precision * recall /(precision+recall)\n    \n    # Compute Area under ROC & PR Curve\n    evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=outcomeName)\n    areaUnderROC = evaluator.evaluate(predict_df, {evaluator.metricName: \"areaUnderROC\"})\n    areaUnderPRC = evaluator.evaluate(predict_df, {evaluator.metricName: \"areaUnderPR\"})\n    \n    if ReturnVal : return {'Accuracy' : round(accuracy, 7), \n                           'Precision' : round(precision, 7), \n                           'Recall' : round(recall, 7), \n                           'f-score' : round(fscore, 7), \n                           'areaUnderROC' : round(areaUnderROC, 7), \n                           'AreaUnderPRC' : round(areaUnderPRC, 7),\n                           'metric' : metric}\n    \n    print(\"Accuracy = {}, Precision = {}, Recall = {}, f-score = {}, AreaUnderROC = {}, AreaUnderPRC = {}\".format(\n        round(accuracy, 7), round(precision, 7),round(recall, 7),round(fscore, 7), round(areaUnderROC, 7), round(areaUnderPRC, 7))),\n    print(\"\\nConfusion Matrix:\\n\", pd.DataFrame.from_dict(metric, orient='index', columns=['count']), '\\n')\n\n# This function takes a trained model, generates predictions,\n# And calls model evaluation function to evaluate the predictions\ndef PredictAndEvaluate(model, data, dataName, outcomeName):\n  predictions = model.transform(data)\n  EvaluateModelPredictions(predictions, dataName, outcomeName)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":68},{"cell_type":"code","source":["# Train the model using the \"train\" dataset and evaluate against the \"val\" dataset\nalgorithms = ['lr','dt','nb','svm']\nfor algorithm in algorithms:\n  newnumFeatureNames = numFeatureNames + contNumFeatureNames\n\n  # Train on training data & evaluate validation data\n  tr_model = train_model(train_algo, algorithm, catFeatureNames, newnumFeatureNames, outcomeName, svmflag=algorithm == 'svm')\n  PredictAndEvaluate(tr_model, val_algo, 'val with ' + algorithm, outcomeName)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model Evaluation - val with lr\n-----------------------------\nAccuracy = 0.8855706, Precision = 0, Recall = 0.0, f-score = 0, AreaUnderROC = 0.6288745, AreaUnderPRC = 0.1603632\n\nConfusion Matrix:\n       count\nFN   341760\nTN  2644885\nTP        0\nFP        0 \n\nModel Evaluation - val with dt\n-----------------------------\nAccuracy = 0.88558, Precision = 0.5224359, Recall = 0.0009539, f-score = 0.0019043, AreaUnderROC = 0.6010569, AreaUnderPRC = 0.1523681\n\nConfusion Matrix:\n       count\nTP      326\nFN   341434\nTN  2644587\nFP      298 \n\nModel Evaluation - val with nb\n-----------------------------\nAccuracy = 0.5849453, Precision = 0.1540864, Recall = 0.5851328, f-score = 0.2439358, AreaUnderROC = 0.4069267, AreaUnderPRC = 0.0894408\n\nConfusion Matrix:\n       count\nTP   199975\nFN   141785\nTN  1547049\nFP  1097836 \n\nModel Evaluation - val with svm\n-----------------------------\nAccuracy = 0.8856789, Precision = 0, Recall = 0.0, f-score = 0, AreaUnderROC = 0.5232673, AreaUnderPRC = 0.1273751\n\nConfusion Matrix:\n       count\nFN   341395\nTN  2644886\nTP        0\nFP        0 \n\n</div>"]}}],"execution_count":69},{"cell_type":"markdown","source":["### Analyzing Candidate Algorithm Results & Choosing our Algorithm \n\nBased on the modeling results displayed above for all four of our candidate models, we observed the following:     \n- Both Logistic Regression and SVM had high accuracy but failed to predict any of the true positives. Both of these models also failed to predict any false positives. Based on this we concluded both the models were predicting \"no delay\" all the time.\n- Naive Bayes identified the most number of true positives, but it also had roughly 5 times as many false positives. It had an accuracy slightly better than a coin toss.\n- Decision Tree identified some true positives, it identified a similar set of false positives. It also demonstrated good accuracy and precision. Its recall rate wasn't very high. Overall emperically, this model looked much more balanced fit for our further analysis.\n\nTheoretically speaking, Logistic Regression is very easy to model, interpret, and train. The main limitation of Logistic Regression is the multi-collinearity present among some of the features. Logisitc regression is also susceptible to overfitting due to imbalanced data. \n\nSupport Vector Machines on the other hand is not suitable for large datasets. As these algorithms use hyperplanes to separate the two classes in feature space, it is much harder to interpret them and larger data sets require a much longer time to process in relation to our other candidate models. \n\nWith Naive Bayes, this model is fairly simple to process and scales really well. Much like Logistic Regression, Naive Bayes does makes the naive assumption that the features under consieration are independent of each other, which is not true in many cases, including for the our scenario.\n\nBy comparison to all three of these algorithms, the Decision Tree algorithm seems to be the most promising for our scenario, especially from a theoretical perspective. Compared to the other candidate algorithms, we saw the following benefits (note that all four the the requirements described previously are satisfied by the Decision Tree algorithm):\n- the algorithm is highly interpretable, given that the decision rules can be easily interpretted by anyone\n- they require little-to-no data preparation during pre-processing function to successfully (can work with both categorical & numerical features)\n- the algorithm also doesn't require normalization or scaling of our features and can handle null or unknown values gracefully\n- they can still easily benefit from certain data preparation, such as Breiman's theorem applications & binning of numerical features\n- they automatically do feature selection and can highlight feature importance using information gain metrics\n- they can automatically generate relevant interaction terms\n- the algorithm requires very little hyperparameter tuning\n- inference is fast & explainable\n- the algorithm itself can be parallelize at training, which can help with scalability\n\nWith that said, one of the consequences that do come with Decision Trees is that they can tend to overfit as they try to memorize the data, leading to an increase in variance in the model (which is the case with the results of our candidate model shown above). While this might be a limitation to make us pause and reconsider this algorithm, Decision Trees can easily be extended to the Random Forest algorithm to help with the bias-variance tradeoff that may be present in a single decision tree. Thus, for these reasons, we will continue our analysis using **Decision Trees** as our algorithm of choice and look further to extending to Random Forests and other ensembles of trees approaches in the next section."],"metadata":{}},{"cell_type":"markdown","source":["## V. Algorithm Implementation\n\nWith Decision Trees as our chosen algorithm, we will proceed to explore the algorithm in a toy example, apply it to our feature engineered dataset, and expand on the basic algorithm to random forests and ensembles of random forests."],"metadata":{}},{"cell_type":"markdown","source":["### Toy Example: Decision Trees\nGiven that in the previous section, we decided on Decision Trees as our algorithm of choice, we will now proceed to describe the math behind the algorithm with our toy example.\n\n#### Dataset\nFor the toy example, we will leverage a toy dataset for motivating the algorithm explanation, which consists of a 10 records from the original *Airline Delays* dataset and includes our outcome variable `Dep_Del30`, 2 numerical features `Day_Of_Week` and `CRS_Dep_Time`, as well as 2 categorical features `Origin` and `Op_Unique_Carrier`. These are displayed below:"],"metadata":{}},{"cell_type":"code","source":["# Load the toy example dataset\ntoy_dataset = spark.read.option(\"header\", \"true\").parquet(f\"dbfs/user/team20/finalnotebook/airlines_toy_dataset.parquet\")\ndisplay(toy_dataset)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Dep_Del30</th><th>Day_Of_Week</th><th>CRS_Dep_Time</th><th>Origin</th><th>Op_Unique_Carrier</th></tr></thead><tbody><tr><td>0</td><td>5</td><td>1735</td><td>HOU</td><td>B6</td></tr><tr><td>0</td><td>2</td><td>2035</td><td>SMF</td><td>WN</td></tr><tr><td>1</td><td>6</td><td>1509</td><td>DCA</td><td>OH</td></tr><tr><td>0</td><td>6</td><td>1500</td><td>SDF</td><td>WN</td></tr><tr><td>1</td><td>3</td><td>2210</td><td>HOU</td><td>WN</td></tr><tr><td>1</td><td>3</td><td>1755</td><td>MCO</td><td>WN</td></tr><tr><td>0</td><td>2</td><td>1425</td><td>DEN</td><td>OO</td></tr><tr><td>0</td><td>5</td><td>615</td><td>SJC</td><td>DL</td></tr><tr><td>0</td><td>6</td><td>1940</td><td>DEN</td><td>AA</td></tr><tr><td>1</td><td>7</td><td>1425</td><td>MSP</td><td>EV</td></tr></tbody></table></div>"]}}],"execution_count":73},{"cell_type":"markdown","source":["#### Introduction to Decision Trees\nDecision trees predict the label (or class) by evaluating a set of rules that follow an IF-THEN-ELSE pattern in a question and answer style. The questions are the nodes, and the answers (true or false) are the branches in the tree to the child nodes, thus construct a tree-like structure of questions and answers. A decision tree model estimates the minimum number of true/false questions needed, to assess the probability of making a correct decision. \n\nFor this analysis, we leveraged the CART algorithm (Classification and Regression Trees). The Decision Tree algorithm is a greedy algorithm that considers all features to select the best feature and the best split point for that feature at each given node in the tree. Initially, we have a root node for the tree. The root node receives the entire training set as input and all subsequent nodes receive a subset of rows as input. Each node asks a true/false question about one of the features using a threshold and in response, the dataset is split into two subsets. The subsets become input to the child nodes that are added to the tree for the next level of splitting. The goal of the algorithm is to produce the purest distribution of labels at each leaf node in the tree, using the training data.\n\nIf a node contains examples of only a single type of label, it has 100% purity and becomes a leaf node. The subset of data at the leaf node doesn't need to be split any further. On the other hand, if a node still contains mixed labels in its data subset, the decision tree algorithm chooses another question and threshold, based on which the subset is split further. The trick to building an effective tree is to decide which feature to select at each node and the best threshold for that feature. To do this, we need to quantify how well a feature and threshold can split the dataset at each step of the algorithm.\n\n#### Entropy\nEntropy is a measure of disorder in the dataset. It characterizes the (im)purity of an arbitrary collection of examples. In decision trees, at each node, we split the data and try to group together samples that belong in the same class. The objective is to maximize the purity of the groups each time a new child node of the tree is created. The goal is to decrease the entropy as much as possible at each split. Entropy ranges between 0 and 1, where an entropy of 0 indicates a pure set (i.e the subset of observations contains only one label). \n\n#### Gini Impurity and Information Gain\nWe quantify the amount of uncertainity at a single node by a metric called the gini impurity. We can quantify how much a split reduces the uncertainity by using a metric called the information gain. Information gain is the expected reduction in entropy caused by partitioning the examples according to a given feature and threshold. These two metrics are used to select the best feature and threshold at each split point. The best feature reduces the uncertainity the most. Given the feature and threshold, the algorithm recursively builds the tree at each of the new child nodes. This process continues until all the nodes are pure or we reach a stopping criteria (such as a minimum number of examples)."],"metadata":{}},{"cell_type":"markdown","source":["#### Mathematical definition of entropy\n\nThe general formula for entropy is:\n$$ E = \\sum_i -p_i {\\log_2 p_i} $$ where \\\\(p_i\\\\) is the frequentist probability of elements in class \\\\(i\\\\).\n\nSince our outcome variable `Dep_Del30` is binary, all the observations in our toy dataset fall into one of two classes (`0` or `1`). Suppose we have \\\\(N\\\\) observations in the dataset. Let's assume that \\\\(n\\\\) observations belong to label `1` and \\\\(m = N - n\\\\) observations belong to label `0`. \\\\(p\\\\) and \\\\(q\\\\), the ratios of elements of each label in the dataset are given by:\n\n$$p = \\frac{n}{N}$$ $$q = \\frac{m}{N} = 1-p $$\n\nThus, entropy is given by the following equation:\n$$E = -p {\\log_2 (p)} -q {\\log_2 (q)}$$"],"metadata":{}},{"cell_type":"markdown","source":["#### Entropy at Level 0\n\nIn our toy dataset, we have ten observations. Four of them have label `1` and six of them have label `0`. Thus, entropy at the root node is given by:\n\n$$ Entropy = -\\frac{4}{10} {\\log_2 (\\frac{4}{10})} -\\frac{6}{10} {\\log_2 (\\frac{6}{10})} = 0.966 $$\n\nIn this case, our entropy is close to 1, as we have a distribution close to 50/50 for the observations belonging to each class. Given the entropy at the root node, we can use this information to grow the next level in the tree."],"metadata":{}},{"cell_type":"markdown","source":["<img src=\"https://github.com/nsandadi/Images/blob/master/Decision_Tree_toy_example.jpg?raw=true\" width=70%>"],"metadata":{}},{"cell_type":"markdown","source":["#### Entropy at Level 1\nThe data subset that goes down each branch of the tree has its own entropy value. We can calculate the expected entropy for each possible attribute. This is the degree to which the entropy would change if we branch on a particular feature. We calculate the weighted entropy of the split by adding the entropies of the two child nodes, weighted by the proportion of examples from the parent node that ended up at that child.\n\n#### Weighted entropy calculations\n$$ E(DayOfWeek) = -\\frac{6}{10} {\\log_2 (0.9042)} -\\frac{4}{10} {\\log_2 (1)} = 0.94 $$\n$$ E(Carrier) = -\\frac{6}{10} {\\log_2 (0.9042)} -\\frac{4}{10} {\\log_2 (0)} = 0.54 $$\n$$ E(Origin) = -\\frac{5}{10} {\\log_2 (0.72)} -\\frac{5}{10} {\\log_2 (0)} = 0.36 $$\n\n#### Information Gain at Level 1\nInformation gain gives the number of bits of information gained about the dataset by choosing a specific feature and threshold as the first branch of the decision tree, and is calculated as:\n$$ IG = Entropy (Parent) - Weighted Entropy (Child Nodes) $$\n\nBased on the information gain calculations shown in the diagram above, the highest information gain is 0.606 when we use the feature `Origin` with the decision rule that the `Origin` i in the set of airports [\"MCO\", \"MSP\", \"DCA\", \"HOU\"]. Thus, among the features and split points considered in this toy example, the best feature to split on is `Origin` at level 1. This procedure can continue recursively until the appropriate stopping criteria is achieved."],"metadata":{}},{"cell_type":"markdown","source":["### Evaluating Models\n\nBefore going into training decision trees and analyzing the results they give, let us consider the evaluation metrics that we'll use to evaluate whether these models are \"good\" models.\n\nAs we noted in previous sections, while accuracy may be an intuitive metric for us to use to evaluate our model performance, it is not necessarily the best metric use. It's especially an issue if our dataset is imbalanced, because if we predict the majority class, 89% of the time, we'd be right. In which case, we'd have to concentrate on metrics that tell us the whole story like area under the curve & our confusion matrix.\n \nHowever, since we'll focus on training our models on balanced datasets (using either SMOTE or Majority Class Splitting), accuracy becomes a more valid metric. With that said, we will still look at other metrics as well, including precision, recall, f-score, area under the curve (including AUROC and AUPRC), as well as the confusion matrix to ensure we get the full story of how our models perform. By having all the metrics, we can choose which metric to prioritize depending on the business case of interest. If we were to prioritize recall, for example, this would ensure a model that is great for helping airlines and airports prepare for delays from a resource perspective. By comparison, if we were to prioritize precision, this would help passengers better plan for delays and not miss their flights. At the end of the day, it depends on what use case we want to prioritize and for these reasons, we'll evaluate all metrics in aggregate as we proceed through this section."],"metadata":{}},{"cell_type":"markdown","source":["### Training Decision Tree on SMOTEd (Balanced) Training Dataset\n\nFor our first step towards modeling departure delays, we trained a decision tree model using all the feature engineering described in prior sections on the SMOTEd (balanced) training dataset. One of the best characteristics of a decision tree is its interpretability. From the printout of the model below, we can see that the model chose `CRS_Dep_Time_bin` as the most important feature to split on first, followed by `Origin_Activity` and `Origin_Dest_brieman`. `Distance` and `Carrier` are considered less important features and these features are chosen further down the tree. At the root node, the decision tree splits on `CRS_Dep_Time_bin` and the threshold chosen is 115.5 (note that the bin 115 corresponds to the 10-minute block 1150, which is approximately noon). Thus, we can infer that a departure time approximately before or after noon along with origin airport can give us information about a departure delay. \n\nWe did some hyper-parameter tuning on the decision tree model using maxDepth. This parameter represents the maximum depth the tree is allowed to grow. In general, the deeper we allow the tree to grow, the more complex the model will become because there will be more splits and it captures more information about the data. However, this is one of the root causes of overfitting in decision trees. The model will fit perfectly to the training data but will not be able to generalize well on test set. Yet selecting too low a value for maxDepth will make the model underfit to the data. Thus, selecting the right maxDepth is important to build a good model.\n\nFor selecting the optimal hyperparameter value, we tried maxDepth values of 5, 10, 15, 20, 30, 50 and 100. The Accuracy does not increase much after maxDepth = 30 and Area Under ROC (AUROC) for the validation set is highest for maxDepth = 15. Since, we can easily overfit the data using a higher maxDepth, we select maxDepth = 15 for our decision tree model. Note however that even for our model trained with maxDepth = 15, the model performs much better on the SMOTEd training data used for training, but less so on the original training data and the held-out validation set. In fact, we see fairy good performance across most all our metrics for the data used for training, but see a definite drop, especially in terms of precision, F-score, and Area Under PRC. These outcomes do seem to suggest that the single decision tree likely overfit to the training data."],"metadata":{}},{"cell_type":"code","source":["# Read prepared data from parquet for training\ndef ReadDataFromParquet(dataName):\n  # Read data back directly from disk \n  return spark.read.option(\"header\", \"true\").parquet(f\"dbfs/user/team20/finalnotebook/airlines_\" + dataName + \".parquet\")\n\ndef ReadDataFromParquet1(dataName):\n  # Read data back directly from disk \n  return spark.read.option(\"header\", \"true\").parquet(f\"dbfs:/user/team20/finalnotebook/airlines_\" + dataName + \".parquet\")\n\nairlines = ReadDataFromParquet('augmented')\nmini_train = ReadDataFromParquet('augmented_mini_train')\ntrain = ReadDataFromParquet('augmented_train')\nval = ReadDataFromParquet('augmented_val')\ntest = ReadDataFromParquet('augmented_test')\ntrain_smoted = ReadDataFromParquet1('augmented2_smoted_train_kmeans')\n\n###########################################\n# Define all variables for easy reference #\n###########################################\n\n# Numerical Variables to use for training\noutcomeName = 'Dep_Del30'\nnumFeatureNames = ['Year', 'Month', 'Day_Of_Month', 'Day_Of_Week', 'Distance_Group'] ##\ncontNumFeatureNames = ['CRS_Dep_Time', 'CRS_Arr_Time', 'CRS_Elapsed_Time', 'Distance']\ncatFeatureNames = ['Op_Unique_Carrier', 'Origin', 'Dest']\nbinFeatureNames = ['CRS_Dep_Time_bin', 'CRS_Arr_Time_bin', 'CRS_Elapsed_Time_bin'] ##\nintFeatureNames = ['Day_Of_Year', 'Origin_Dest', 'Dep_Time_Of_Week', 'Arr_Time_Of_Week']\nholFeatureNames = ['Holiday']\norgFeatureNames = ['Origin_Activity'] ##\nbriFeatureNames = ['Op_Unique_Carrier_brieman', 'Origin_brieman', 'Dest_brieman', 'Day_Of_Year_brieman', 'Origin_Dest_brieman', 'Dep_Time_Of_Week_brieman', 'Arr_Time_Of_Week_brieman', 'Holiday_brieman'] ##"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":81},{"cell_type":"code","source":["# Encodes a string column of labels to a column of label indices\n# Set HandleInvalid to \"keep\" so that the indexer adds new indexes when it sees new labels\n# Apply string indexer to categorical, binned, and interaction features (all string formatted), as applicable\ndef PrepStringIndexer(stringfeatureNames):\n  return [StringIndexer(inputCol=f, outputCol=f+\"_idx\", handleInvalid=\"keep\") for f in stringfeatureNames]\n\n# Use VectorAssembler() to merge our feature columns into a single vector column, which will be passed into the model. \n# We will not transform the dataset just yet as we will be passing the VectorAssembler into our ML Pipeline.\ndef PrepVectorAssembler(numericalFeatureNames, stringFeatureNames):\n  return VectorAssembler(inputCols = numericalFeatureNames + [f + \"_idx\" for f in stringFeatureNames], outputCol = \"features\")\n\n# Trains a simple Decision Tree model\ndef TrainDecisionTreeModel(trainingData, stages, outcomeName, maxDepth, maxBins):\n  dt = DecisionTreeClassifier(labelCol = outcomeName, featuresCol = \"features\", seed = 6, maxDepth = maxDepth, maxBins=maxBins) \n  pipeline = Pipeline(stages = stages + [dt])\n  dt_model = pipeline.fit(trainingData)\n  return dt_model\n\n# Visualize the decision tree model that was trained in text form\n# Note that the featureNames need to be in the same order they were provided\n# to the vector assembler prior to training the model\ndef PrintDecisionTreeModel(model, featureNames):\n  lines = model.toDebugString.split(\"\\n\")\n  featuresUsed = set()\n  print(\"\\n\")\n  \n  for line in lines:\n    parts = line.split(\" \")\n\n    # Replace \"feature #\" with feature name\n    if (\"feature\" in line):\n      featureNumIdx = parts.index(\"(feature\") + 1\n      featureNum = int(parts[featureNumIdx])\n      parts[featureNumIdx] = featureNames[featureNum] # replace feature number with actual feature name\n      parts[featureNumIdx - 1] = \"\" # remove word \"feature\"\n      featuresUsed.add(featureNames[featureNum])\n      \n    # For cateogrical features, summarize sets of values selected for easier reading\n    if (\"in\" in parts):\n      setIdx = parts.index(\"in\") + 1\n      vals = ast.literal_eval(parts[setIdx][:-1])\n      vals = list(vals)\n      numVals = len(vals)\n      if (len(vals) > 5):\n        newVals = random.sample(vals, 5)\n        newVals = [str(int(d)) for d in newVals]\n        newVals.append(\"...\")\n        vals = newVals\n      parts[setIdx] = str(vals) + \" (\" + str(numVals) + \" total values)\"\n      \n    line = \" \".join(parts)\n    print(line)\n    \n  print(\"\\n\", \"Provided Features: \", featureNames)\n  print(\"\\n\", \"    Used Features: \", featuresUsed)\n  print(\"\\n\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":82},{"cell_type":"code","source":["# Prep features to use for decision tree model\nfeatureNames = numFeatureNames + binFeatureNames + orgFeatureNames + briFeatureNames\nva_base = PrepVectorAssembler(numericalFeatureNames = featureNames, stringFeatureNames = [])\n\n# Train, evaluate, & display the model\ndt_model = TrainDecisionTreeModel(train_smoted, [va_base], outcomeName, maxDepth=15, maxBins=200)\nPredictAndEvaluate(dt_model, train_smoted, 'train_smoted', outcomeName)\nPredictAndEvaluate(dt_model, train, 'train', outcomeName)\nPredictAndEvaluate(dt_model, val, 'val', outcomeName)\nPrintDecisionTreeModel(dt_model.stages[-1], featureNames)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model Evaluation - train_smoted\n-----------------------------\nAccuracy = 0.680256, Precision = 0.6810461, Recall = 0.6967006, f-score = 0.6887844, AreaUnderROC = 0.6167985, AreaUnderPRC = 0.6230655\n\nConfusion Matrix:\n        count\nTP  13321477\nFN   5799328\nTN  12289752\nFP   6238839 \n\nModel Evaluation - train\n-----------------------------\nAccuracy = 0.6692392, Precision = 0.1723143, Recall = 0.4942987, f-score = 0.2555448, AreaUnderROC = 0.5280442, AreaUnderPRC = 0.1332813\n\nConfusion Matrix:\n        count\nTP   1222207\nFN   1250401\nTN  13186123\nFP   5870685 \n\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6720968, Precision = 0.174178, Recall = 0.4935288, f-score = 0.2574838, AreaUnderROC = 0.5283781, AreaUnderPRC = 0.1338269\n\nConfusion Matrix:\n       count\nTP   174762\nFN   179345\nTN  1891185\nFP   828591 \n\n\n\nDecisionTreeClassificationModel (uid=DecisionTreeClassifier_04e8ad4e08c0) of depth 15 with 26923 nodes\n  If  CRS_Dep_Time_bin &lt;= 115.5)\n   If  Origin_Activity &lt;= 1.5)\n    If  Origin_Dest_brieman &lt;= 63.0)\n     If  CRS_Dep_Time_bin &lt;= 72.5)\n      If  CRS_Elapsed_Time_bin &lt;= 2.5)\n       If  Dest_brieman &lt;= 221.5)\n        If  Op_Unique_Carrier_brieman &lt;= 17.5)\n         If  Op_Unique_Carrier_brieman &lt;= 1.5)\n          Predict: 1.0\n         Else  Op_Unique_Carrier_brieman &gt; 1.5)\n          If  Op_Unique_Carrier_brieman &lt;= 9.5)\n           If  Op_Unique_Carrier_brieman &lt;= 6.5)\n            If  Dest_brieman &lt;= 141.5)\n             If  Op_Unique_Carrier_brieman &lt;= 3.5)\n              If  CRS_Dep_Time_bin &lt;= 67.5)\n               If  Origin_brieman &lt;= 305.5)\n                Predict: 0.0\n               Else  Origin_brieman &gt; 305.5)\n                Predict: 1.0\n              Else  CRS_Dep_Time_bin &gt; 67.5)\n               If  Origin_brieman &lt;= 143.5)\n                If  Op_Unique_Carrier_brieman &lt;= 2.5)\n                 Predict: 1.0\n                Else  Op_Unique_Carrier_brieman &gt; 2.5)\n                 Predict: 0.0\n               Else  Origin_brieman &gt; 143.5)\n                If  Origin_brieman &lt;= 228.5)\n                 Predict: 1.0\n                Else  Origin_brieman &gt; 228.5)\n                 Predict: 0.0\n             Else  Op_Unique_Carrier_brieman &gt; 3.5)\n              If  Dest_brieman &lt;= 77.5)\n               If  Origin_brieman &lt;= 85.5)\n                If  Origin_brieman &lt;= 75.5)\n                 Predict: 1.0\n                Else  Origin_brieman &gt; 75.5)\n                 Predict: 0.0\n               Else  Origin_brieman &gt; 85.5)\n                Predict: 1.0\n              Else  Dest_brieman &gt; 77.5)\n               Predict: 1.0\n            Else  Dest_brieman &gt; 141.5)\n             If  Op_Unique_Carrier_brieman &lt;= 5.5)\n              Predict: 1.0\n             Else  Op_Unique_Carrier_brieman &gt; 5.5)\n              If  CRS_Arr_Time_bin &lt;= 64.5)\n               If  CRS_Dep_Time_bin &lt;= 53.5)\n                If  Day_Of_Month &lt;= 22.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 22.5)\n                 Predict: 0.0\n               Else  CRS_Dep_Time_bin &gt; 53.5)\n                Predict: 0.0\n              Else  CRS_Arr_Time_bin &gt; 64.5)\n               If  Month &lt;= 10.5)\n                Predict: 1.0\n               Else  Month &gt; 10.5)\n                If  Day_Of_Month &lt;= 27.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 27.5)\n                 Predict: 0.0\n           Else  Op_Unique_Carrier_brieman &gt; 6.5)\n            If  Dest_brieman &lt;= 27.5)\n             Predict: 1.0\n            Else  Dest_brieman &gt; 27.5)\n             If  Dest_brieman &lt;= 58.5)\n              If  Op_Unique_Carrier_brieman &lt;= 7.5)\n               If  Distance_Group &lt;= 2.5)\n                Predict: 0.0\n               Else  Distance_Group &gt; 2.5)\n                Predict: 1.0\n              Else  Op_Unique_Carrier_brieman &gt; 7.5)\n               Predict: 1.0\n             Else  Dest_brieman &gt; 58.5)\n              If  Dest_brieman &lt;= 77.5)\n               Predict: 1.0\n              Else  Dest_brieman &gt; 77.5)\n               Predict: 0.0\n          Else  Op_Unique_Carrier_brieman &gt; 9.5)\n           If  Op_Unique_Carrier_brieman &lt;= 10.5)\n            If  Origin_brieman &lt;= 229.5)\n             Predict: 1.0\n            Else  Origin_brieman &gt; 229.5)\n             If  Origin_brieman &lt;= 234.5)\n              If  Dest_brieman &lt;= 129.5)\n               If  Dest_brieman &lt;= 102.5)\n                Predict: 1.0\n               Else  Dest_brieman &gt; 102.5)\n                Predict: 0.0\n              Else  Dest_brieman &gt; 129.5)\n               Predict: 1.0\n             Else  Origin_brieman &gt; 234.5)\n              If  Year &lt;= 2017.5)\n               Predict: 1.0\n              Else  Year &gt; 2017.5)\n               If  Dest_brieman &lt;= 210.5)\n                Predict: 1.0\n               Else  Dest_brieman &gt; 210.5)\n                If  Origin_brieman &lt;= 303.5)\n                 Predict: 1.0\n                Else  Origin_brieman &gt; 303.5)\n                 Predict: 0.0\n           Else  Op_Unique_Carrier_brieman &gt; 10.5)\n            If  Origin_brieman &lt;= 18.5)\n             Predict: 1.0\n            Else  Origin_brieman &gt; 18.5)\n             If  Dest_brieman &lt;= 169.5)\n              If  Dest_brieman &lt;= 76.5)\n               If  Op_Unique_Carrier_brieman &lt;= 15.5)\n                If  CRS_Arr_Time_bin &lt;= 4.5)\n                 Predict: 0.0\n                Else  CRS_Arr_Time_bin &gt; 4.5)\n                 Predict: 1.0\n               Else  Op_Unique_Carrier_brieman &gt; 15.5)\n                If  Dest_brieman &lt;= 57.5)\n                 Predict: 0.0\n                Else  Dest_brieman &gt; 57.5)\n                 Predict: 1.0\n              Else  Dest_brieman &gt; 76.5)\n               If  Origin_brieman &lt;= 246.5)\n                Predict: 0.0\n               Else  Origin_brieman &gt; 246.5)\n                If  Op_Unique_Carrier_brieman &lt;= 14.5)\n                 Predict: 0.0\n                Else  Op_Unique_Carrier_brieman &gt; 14.5)\n                 Predict: 1.0\n             Else  Dest_brieman &gt; 169.5)\n              If  Dest_brieman &lt;= 220.5)\n               If  Op_Unique_Carrier_brieman &lt;= 15.5)\n                If  Origin_Dest_brieman &lt;= -0.5)\n                 Predict: 1.0\n                Else  Origin_Dest_brieman &gt; -0.5)\n                 Predict: 0.0\n               Else  Op_Unique_Carrier_brieman &gt; 15.5)\n                If  Op_Unique_Carrier_brieman &lt;= 16.5)\n                 Predict: 0.0\n                Else  Op_Unique_Carrier_brieman &gt; 16.5)\n                 Predict: 1.0\n              Else  Dest_brieman &gt; 220.5)\n               If  Op_Unique_Carrier_brieman &lt;= 11.5)\n                If  CRS_Elapsed_Time_bin &lt;= 1.5)\n                 Predict: 1.0\n                Else  CRS_Elapsed_Time_bin &gt; 1.5)\n                 Predict: 0.0\n               Else  Op_Unique_Carrier_brieman &gt; 11.5)\n                Predict: 1.0\n        Else  Op_Unique_Carrier_brieman &gt; 17.5)\n         If  Day_Of_Week &lt;= 6.5)\n          If  Month &lt;= 1.5)\n           If  Year &lt;= 2015.5)\n            If  Day_Of_Month &lt;= 5.5)\n             Predict: 0.0\n            Else  Day_Of_Month &gt; 5.5)\n             Predict: 1.0\n           Else  Year &gt; 2015.5)\n            Predict: 1.0\n          Else  Month &gt; 1.5)\n           Predict: 1.0\n         Else  Day_Of_Week &gt; 6.5)\n          If  Distance_Group &lt;= 2.5)\n           Predict: 1.0\n          Else  Distance_Group &gt; 2.5)\n           If  CRS_Arr_Time_bin &lt;= 77.0)\n            Predict: 0.0\n           Else  CRS_Arr_Time_bin &gt; 77.0)\n            Predict: 1.0\n       Else  Dest_brieman &gt; 221.5)\n        If  CRS_Arr_Time_bin &lt;= 73.5)\n         If  Dest_brieman &lt;= 312.5)\n          If  Year &lt;= 2017.5)\n           Predict: 1.0\n          Else  Year &gt; 2017.5)\n           If  Origin_brieman &lt;= 181.5)\n            If  Dest_brieman &lt;= 231.5)\n             Predict: 1.0\n            Else  Dest_brieman &gt; 231.5)\n             If  Dest_brieman &lt;= 267.5)\n              If  Dest_brieman &lt;= 253.5)\n               If  Dest_brieman &lt;= 235.5)\n                Predict: 0.0\n               Else  Dest_brieman &gt; 235.5)\n                If  Month &lt;= 11.5)\n                 Predict: 1.0\n                Else  Month &gt; 11.5)\n                 Predict: 0.0\n              Else  Dest_brieman &gt; 253.5)\n               Predict: 0.0\n             Else  Dest_brieman &gt; 267.5)\n              Predict: 1.0\n           Else  Origin_brieman &gt; 181.5)\n            Predict: 1.0\n         Else  Dest_brieman &gt; 312.5)\n          If  Op_Unique_Carrier_brieman &lt;= 6.5)\n           If  Dest_brieman &lt;= 324.5)\n            If  Day_Of_Week &lt;= 4.5)\n             Predict: 1.0\n            Else  Day_Of_Week &gt; 4.5)\n             Predict: 0.0\n           Else  Dest_brieman &gt; 324.5)\n            If  Op_Unique_Carrier_brieman &lt;= 5.5)\n             Predict: 1.0\n            Else  Op_Unique_Carrier_brieman &gt; 5.5)\n             If  Origin_brieman &lt;= 260.5)\n              Predict: 1.0\n             Else  Origin_brieman &gt; 260.5)\n              If  Origin_brieman &lt;= 263.5)\n               Predict: 0.0\n              Else  Origin_brieman &gt; 263.5)\n               Predict: 1.0\n          Else  Op_Unique_Carrier_brieman &gt; 6.5)\n           If  Origin_brieman &lt;= 263.5)\n            If  Dest_brieman &lt;= 351.0)\n             If  Op_Unique_Carrier_brieman &lt;= 7.5)\n              If  Distance_Group &lt;= 1.5)\n               Predict: 0.0\n              Else  Distance_Group &gt; 1.5)\n               Predict: 1.0\n             Else  Op_Unique_Carrier_brieman &gt; 7.5)\n              If  Dest_brieman &lt;= 337.5)\n               If  Op_Unique_Carrier_brieman &lt;= 10.5)\n                Predict: 1.0\n               Else  Op_Unique_Carrier_brieman &gt; 10.5)\n                If  Origin_brieman &lt;= 68.5)\n                 Predict: 1.0\n                Else  Origin_brieman &gt; 68.5)\n                 Predict: 0.0\n              Else  Dest_brieman &gt; 337.5)\n               If  Distance_Group &lt;= 2.5)\n                Predict: 1.0\n               Else  Distance_Group &gt; 2.5)\n                If  Origin_brieman &lt;= 85.5)\n                 Predict: 0.0\n                Else  Origin_brieman &gt; 85.5)\n                 Predict: 1.0\n            Else  Dest_brieman &gt; 351.0)\n             Predict: 1.0\n           Else  Origin_brieman &gt; 263.5)\n            If  Dest_brieman &lt;= 324.5)\n             If  Month &lt;= 6.5)\n              Predict: 1.0\n             Else  Month &gt; 6.5)\n              If  Day_Of_Month &lt;= 13.5)\n               Predict: 0.0\n              Else  Day_Of_Month &gt; 13.5)\n               If  Day_Of_Month &lt;= 25.5)\n                If  Day_Of_Week &lt;= 3.5)\n                 Predict: 1.0\n                Else  Day_Of_Week &gt; 3.5)\n                 Predict: 0.0\n               Else  Day_Of_Month &gt; 25.5)\n                Predict: 0.0\n            Else  Dest_brieman &gt; 324.5)\n             Predict: 1.0\n        Else  CRS_Arr_Time_bin &gt; 73.5)\n         If  Year &lt;= 2017.5)\n          If  Origin_brieman &lt;= 312.5)\n           If  Origin_brieman &lt;= 85.5)\n            If  Origin_brieman &lt;= 75.5)\n             If  Op_Unique_Carrier_brieman &lt;= 2.5)\n              If  CRS_Elapsed_Time_bin &lt;= 1.5)\n               If  Day_Of_Week &lt;= 2.5)\n                Predict: 1.0\n               Else  Day_Of_Week &gt; 2.5)\n                Predict: 0.0\n              Else  CRS_Elapsed_Time_bin &gt; 1.5)\n               Predict: 1.0\n             Else  Op_Unique_Carrier_brieman &gt; 2.5)\n              Predict: 1.0\n            Else  Origin_brieman &gt; 75.5)\n             If  Distance_Group &lt;= 2.5)\n              Predict: 1.0\n             Else  Distance_Group &gt; 2.5)\n              If  CRS_Dep_Time_bin &lt;= 60.5)\n               If  Month &lt;= 7.5)\n                Predict: 1.0\n               Else  Month &gt; 7.5)\n                Predict: 0.0\n              Else  CRS_Dep_Time_bin &gt; 60.5)\n               If  Dest_brieman &lt;= 330.5)\n                Predict: 1.0\n               Else  Dest_brieman &gt; 330.5)\n                Predict: 0.0\n           Else  Origin_brieman &gt; 85.5)\n            If  Origin_brieman &lt;= 305.5)\n             If  Month &lt;= 1.5)\n              If  CRS_Arr_Time_bin &lt;= 87.0)\n               Predict: 1.0\n              Else  CRS_Arr_Time_bin &gt; 87.0)\n               If  Day_Of_Month &lt;= 5.5)\n                Predict: 0.0\n               Else  Day_Of_Month &gt; 5.5)\n                Predict: 1.0\n             Else  Month &gt; 1.5)\n              Predict: 1.0\n            Else  Origin_brieman &gt; 305.5)\n             If  Day_Of_Week &lt;= 1.5)\n              Predict: 0.0\n             Else  Day_Of_Week &gt; 1.5)\n              Predict: 1.0\n          Else  Origin_brieman &gt; 312.5)\n           If  Year &lt;= 2016.5)\n            If  Dest_brieman &lt;= 348.5)\n             If  Dest_brieman &lt;= 307.5)\n              Predict: 1.0\n             Else  Dest_brieman &gt; 307.5)\n              If  Origin_brieman &lt;= 336.5)\n               If  Op_Unique_Carrier_brieman &lt;= 6.5)\n                Predict: 1.0\n               Else  Op_Unique_Carrier_brieman &gt; 6.5)\n                If  CRS_Dep_Time_bin &lt;= 54.5)\n                 Predict: 1.0\n                Else  CRS_Dep_Time_bin &gt; 54.5)\n                 Predict: 0.0\n              Else  Origin_brieman &gt; 336.5)\n               Predict: 1.0\n            Else  Dest_brieman &gt; 348.5)\n             Predict: 1.0\n           Else  Year &gt; 2016.5)\n            Predict: 1.0\n         Else  Year &gt; 2017.5)\n          If  Op_Unique_Carrier_brieman &lt;= 5.5)\n           If  CRS_Elapsed_Time_bin &lt;= 1.5)\n            If  Day_Of_Week &lt;= 1.5)\n             Predict: 0.0\n            Else  Day_Of_Week &gt; 1.5)\n             Predict: 1.0\n           Else  CRS_Elapsed_Time_bin &gt; 1.5)\n            Predict: 1.0\n          Else  Op_Unique_Carrier_brieman &gt; 5.5)\n           If  Origin_brieman &lt;= 234.5)\n            If  Origin_brieman &lt;= 75.5)\n             If  CRS_Arr_Time_bin &lt;= 74.5)\n              If  Origin_brieman &lt;= 11.5)\n               If  Dest_brieman &lt;= 228.5)\n                Predict: 1.0\n               Else  Dest_brieman &gt; 228.5)\n                Predict: 0.0\n              Else  Origin_brieman &gt; 11.5)\n               Predict: 1.0\n             Else  CRS_Arr_Time_bin &gt; 74.5)\n              Predict: 1.0\n            Else  Origin_brieman &gt; 75.5)\n             If  Dest_brieman &lt;= 345.0)\n              If  Dest_brieman &lt;= 228.5)\n               Predict: 1.0\n              Else  Dest_brieman &gt; 228.5)\n               If  Dest_brieman &lt;= 267.5)\n                Predict: 0.0\n               Else  Dest_brieman &gt; 267.5)\n                If  Origin_brieman &lt;= 85.5)\n                 Predict: 0.0\n                Else  Origin_brieman &gt; 85.5)\n                 Predict: 1.0\n             Else  Dest_brieman &gt; 345.0)\n              Predict: 1.0\n           Else  Origin_brieman &gt; 234.5)\n            If  Op_Unique_Carrier_brieman &lt;= 18.5)\n             If  Origin_Dest_brieman &lt;= 16.0)\n              If  Op_Unique_Carrier_brieman &lt;= 17.5)\n               Predict: 1.0\n              Else  Op_Unique_Carrier_brieman &gt; 17.5)\n               If  Day_Of_Month &lt;= 24.5)\n                Predict: 1.0\n               Else  Day_Of_Month &gt; 24.5)\n                Predict: 0.0\n             Else  Origin_Dest_brieman &gt; 16.0)\n              Predict: 0.0\n            Else  Op_Unique_Carrier_brieman &gt; 18.5)\n             If  Origin_brieman &lt;= 282.5)\n              Predict: 1.0\n             Else  Origin_brieman &gt; 282.5)\n              If  CRS_Dep_Time_bin &lt;= 62.5)\n               Predict: 1.0\n              Else  CRS_Dep_Time_bin &gt; 62.5)\n               Predict: 0.0\n      Else  CRS_Elapsed_Time_bin &gt; 2.5)\n       If  Op_Unique_Carrier_brieman &lt;= 6.5)\n        If  Dest_brieman &lt;= 83.5)\n         If  Origin_brieman &lt;= 230.5)\n          If  Month &lt;= 2.5)\n           If  CRS_Dep_Time_bin &lt;= 55.5)\n            If  Distance_Group &lt;= 3.5)\n             If  CRS_Arr_Time_bin &lt;= 80.5)\n              Predict: 1.0\n             Else  CRS_Arr_Time_bin &gt; 80.5)\n              If  Day_Of_Month &lt;= 25.5)\n               If  Day_Of_Month &lt;= 7.5)\n                If  Day_Of_Month &lt;= 6.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 6.5)\n                 Predict: 1.0\n               Else  Day_Of_Month &gt; 7.5)\n                Predict: 0.0\n              Else  Day_Of_Month &gt; 25.5)\n               If  Day_Of_Month &lt;= 26.5)\n                Predict: 1.0\n               Else  Day_Of_Month &gt; 26.5)\n                Predict: 0.0\n            Else  Distance_Group &gt; 3.5)\n             Predict: 1.0\n           Else  CRS_Dep_Time_bin &gt; 55.5)\n            Predict: 1.0\n          Else  Month &gt; 2.5)\n           Predict: 1.0\n         Else  Origin_brieman &gt; 230.5)\n          If  Origin_brieman &lt;= 234.5)\n           If  Day_Of_Week &lt;= 6.5)\n            If  CRS_Arr_Time_bin &lt;= 102.5)\n             If  Day_Of_Month &lt;= 20.5)\n              If  Day_Of_Month &lt;= 16.5)\n               If  CRS_Dep_Time_bin &lt;= 55.5)\n                If  Year &lt;= 2016.5)\n                 Predict: 1.0\n                Else  Year &gt; 2016.5)\n                 Predict: 0.0\n               Else  CRS_Dep_Time_bin &gt; 55.5)\n                Predict: 0.0\n              Else  Day_Of_Month &gt; 16.5)\n               If  Day_Of_Week &lt;= 5.5)\n                Predict: 0.0\n               Else  Day_Of_Week &gt; 5.5)\n                If  Day_Of_Month &lt;= 19.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 19.5)\n                 Predict: 1.0\n             Else  Day_Of_Month &gt; 20.5)\n              If  Day_Of_Month &lt;= 29.5)\n               Predict: 0.0\n              Else  Day_Of_Month &gt; 29.5)\n               If  Month &lt;= 5.5)\n                Predict: 0.0\n               Else  Month &gt; 5.5)\n                If  Month &lt;= 7.5)\n                 Predict: 1.0\n                Else  Month &gt; 7.5)\n                 Predict: 0.0\n            Else  CRS_Arr_Time_bin &gt; 102.5)\n             Predict: 1.0\n           Else  Day_Of_Week &gt; 6.5)\n            If  Month &lt;= 9.5)\n             If  Day_Of_Month &lt;= 28.5)\n              If  Day_Of_Month &lt;= 13.5)\n               Predict: 0.0\n              Else  Day_Of_Month &gt; 13.5)\n               If  Day_Of_Month &lt;= 15.5)\n                Predict: 1.0\n               Else  Day_Of_Month &gt; 15.5)\n                Predict: 0.0\n             Else  Day_Of_Month &gt; 28.5)\n              If  Month &lt;= 4.5)\n               Predict: 0.0\n              Else  Month &gt; 4.5)\n               Predict: 1.0\n            Else  Month &gt; 9.5)\n             If  Day_Of_Month &lt;= 4.5)\n              Predict: 0.0\n             Else  Day_Of_Month &gt; 4.5)\n              If  Day_Of_Month &lt;= 8.5)\n               Predict: 1.0\n              Else  Day_Of_Month &gt; 8.5)\n               If  Day_Of_Month &lt;= 26.5)\n                Predict: 0.0\n               Else  Day_Of_Month &gt; 26.5)\n                Predict: 1.0\n          Else  Origin_brieman &gt; 234.5)\n           If  CRS_Dep_Time_bin &lt;= 70.5)\n            Predict: 1.0\n           Else  CRS_Dep_Time_bin &gt; 70.5)\n            If  Op_Unique_Carrier_brieman &lt;= 2.5)\n             If  Dest_brieman &lt;= 57.5)\n              If  Day_Of_Month &lt;= 7.5)\n               If  Year &lt;= 2017.5)\n                Predict: 0.0\n               Else  Year &gt; 2017.5)\n                If  Month &lt;= 2.5)\n                 Predict: 0.0\n                Else  Month &gt; 2.5)\n                 Predict: 1.0\n              Else  Day_Of_Month &gt; 7.5)\n               Predict: 0.0\n             Else  Dest_brieman &gt; 57.5)\n              Predict: 1.0\n            Else  Op_Unique_Carrier_brieman &gt; 2.5)\n             Predict: 1.0\n        Else  Dest_brieman &gt; 83.5)\n         If  Dest_brieman &lt;= 89.5)\n          If  Year &lt;= 2015.5)\n           If  CRS_Arr_Time_bin &lt;= 92.5)\n            Predict: 1.0\n           Else  CRS_Arr_Time_bin &gt; 92.5)\n            If  Day_Of_Month &lt;= 19.5)\n             Predict: 0.0\n            Else  Day_Of_Month &gt; 19.5)\n             If  Day_Of_Month &lt;= 21.5)\n              Predict: 1.0\n             Else  Day_Of_Month &gt; 21.5)\n              Predict: 0.0\n          Else  Year &gt; 2015.5)\n           If  Day_Of_Month &lt;= 2.5)\n            If  Month &lt;= 3.5)\n             Predict: 0.0\n            Else  Month &gt; 3.5)\n             Predict: 1.0\n           Else  Day_Of_Month &gt; 2.5)\n            Predict: 1.0\n         Else  Dest_brieman &gt; 89.5)\n          Predict: 1.0\n       Else  Op_Unique_Carrier_brieman &gt; 6.5)\n        If  Origin_brieman &lt;= 34.5)\n         If  Op_Unique_Carrier_brieman &lt;= 7.5)\n          If  Distance_Group &lt;= 3.5)\n           If  Origin_brieman &lt;= 18.5)\n            Predict: 1.0\n           Else  Origin_brieman &gt; 18.5)\n            If  Dest_brieman &lt;= 100.5)\n             If  Day_Of_Month &lt;= 9.5)\n              If  Day_Of_Month &lt;= 8.5)\n               Predict: 0.0\n              Else  Day_Of_Month &gt; 8.5)\n               If  Month &lt;= 10.5)\n                Predict: 1.0\n               Else  Month &gt; 10.5)\n                Predict: 0.0\n             Else  Day_Of_Month &gt; 9.5)\n              Predict: 0.0\n            Else  Dest_brieman &gt; 100.5)\n             If  Day_Of_Month &lt;= 10.5)\n              Predict: 0.0\n             Else  Day_Of_Month &gt; 10.5)\n              If  Month &lt;= 3.5)\n               If  Day_Of_Week &lt;= 4.5)\n                If  Day_Of_Month &lt;= 13.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 13.5)\n                 Predict: 1.0\n               Else  Day_Of_Week &gt; 4.5)\n                Predict: 0.0\n              Else  Month &gt; 3.5)\n               Predict: 1.0\n          Else  Distance_Group &gt; 3.5)\n           If  Day_Of_Week &lt;= 6.5)\n            Predict: 1.0\n           Else  Day_Of_Week &gt; 6.5)\n            If  Origin_brieman &lt;= 18.5)\n             If  Month &lt;= 7.5)\n              Predict: 0.0\n             Else  Month &gt; 7.5)\n              Predict: 1.0\n            Else  Origin_brieman &gt; 18.5)\n             Predict: 1.0\n         Else  Op_Unique_Carrier_brieman &gt; 7.5)\n          Predict: 1.0\n        Else  Origin_brieman &gt; 34.5)\n         If  Origin_brieman &lt;= 263.5)\n          If  Dest_brieman &lt;= 167.5)\n           If  Origin_brieman &lt;= 179.5)\n            If  Origin_brieman &lt;= 66.5)\n             If  CRS_Dep_Time_bin &lt;= 60.5)\n              If  Month &lt;= 10.5)\n               If  Year &lt;= 2015.5)\n                If  Month &lt;= 5.5)\n                 Predict: 0.0\n                Else  Month &gt; 5.5)\n                 Predict: 1.0\n               Else  Year &gt; 2015.5)\n                Predict: 1.0\n              Else  Month &gt; 10.5)\n               If  Year &lt;= 2016.5)\n                Predict: 1.0\n               Else  Year &gt; 2016.5)\n                Predict: 0.0\n             Else  CRS_Dep_Time_bin &gt; 60.5)\n              Predict: 1.0\n            Else  Origin_brieman &gt; 66.5)\n             If  Origin_brieman &lt;= 171.5)\n              Predict: 1.0\n             Else  Origin_brieman &gt; 171.5)\n              If  Dest_brieman &lt;= 123.5)\n               Predict: 1.0\n              Else  Dest_brieman &gt; 123.5)\n               If  Dest_brieman &lt;= 126.5)\n                Predict: 0.0\n               Else  Dest_brieman &gt; 126.5)\n                Predict: 1.0\n           Else  Origin_brieman &gt; 179.5)\n            If  Dest_brieman &lt;= 94.5)\n             If  Dest_brieman &lt;= 75.0)\n              If  Origin_brieman &lt;= 181.5)\n               If  Day_Of_Week &lt;= 5.5)\n                If  Dest_brieman &lt;= 42.5)\n                 Predict: 0.0\n                Else  Dest_brieman &gt; 42.5)\n                 Predict: 1.0\n               Else  Day_Of_Week &gt; 5.5)\n                Predict: 0.0\n              Else  Origin_brieman &gt; 181.5)\n               Predict: 1.0\n             Else  Dest_brieman &gt; 75.0)\n              If  Origin_brieman &lt;= 196.5)\n               If  Origin_brieman &lt;= 181.5)\n                If  Dest_brieman &lt;= 90.5)\n                 Predict: 1.0\n                Else  Dest_brieman &gt; 90.5)\n                 Predict: 0.0\n               Else  Origin_brieman &gt; 181.5)\n                Predict: 1.0\n              Else  Origin_brieman &gt; 196.5)\n               If  Origin_brieman &lt;= 253.5)\n                If  Op_Unique_Carrier_brieman &lt;= 18.5)\n                 Predict: 0.0\n                Else  Op_Unique_Carrier_brieman &gt; 18.5)\n                 Predict: 1.0\n               Else  Origin_brieman &gt; 253.5)\n                Predict: 1.0\n            Else  Dest_brieman &gt; 94.5)\n             If  Origin_brieman &lt;= 181.5)\n              If  CRS_Dep_Time_bin &lt;= 63.5)\n               If  CRS_Dep_Time_bin &lt;= 60.5)\n                Predict: 0.0\n               Else  CRS_Dep_Time_bin &gt; 60.5)\n                Predict: 1.0\n              Else  CRS_Dep_Time_bin &gt; 63.5)\n               If  Distance_Group &lt;= 5.5)\n                If  Year &lt;= 2017.5)\n                 Predict: 1.0\n                Else  Year &gt; 2017.5)\n                 Predict: 0.0\n               Else  Distance_Group &gt; 5.5)\n                Predict: 1.0\n             Else  Origin_brieman &gt; 181.5)\n              If  Origin_brieman &lt;= 230.5)\n               If  CRS_Arr_Time_bin &lt;= 71.5)\n                If  CRS_Dep_Time_bin &lt;= 53.5)\n                 Predict: 1.0\n                Else  CRS_Dep_Time_bin &gt; 53.5)\n                 Predict: 0.0\n               Else  CRS_Arr_Time_bin &gt; 71.5)\n                Predict: 1.0\n              Else  Origin_brieman &gt; 230.5)\n               If  Dest_brieman &lt;= 129.5)\n                If  Dest_brieman &lt;= 100.5)\n                 Predict: 1.0\n                Else  Dest_brieman &gt; 100.5)\n                 Predict: 0.0\n               Else  Dest_brieman &gt; 129.5)\n                Predict: 1.0\n          Else  Dest_brieman &gt; 167.5)\n           If  Dest_brieman &lt;= 339.5)\n            If  Origin_brieman &lt;= 53.5)\n             If  Distance_Group &lt;= 4.5)\n\n*** WARNING: skipped 1481050 bytes of output ***\n\n                Predict: 0.0\n               Else  Day_Of_Month &gt; 30.5)\n                Predict: 1.0\n              Else  Month &gt; 9.5)\n               If  Month &lt;= 11.5)\n                Predict: 1.0\n               Else  Month &gt; 11.5)\n                Predict: 0.0\n          Else  Origin_Dest_brieman &gt; 5621.5)\n           If  Year &lt;= 2017.5)\n            If  Year &lt;= 2015.5)\n             If  Dest_brieman &lt;= 345.0)\n              If  Distance_Group &lt;= 2.5)\n               If  Op_Unique_Carrier_brieman &lt;= 3.5)\n                If  Dest_brieman &lt;= 324.5)\n                 Predict: 0.0\n                Else  Dest_brieman &gt; 324.5)\n                 Predict: 1.0\n               Else  Op_Unique_Carrier_brieman &gt; 3.5)\n                Predict: 0.0\n              Else  Distance_Group &gt; 2.5)\n               If  Day_Of_Month &lt;= 5.5)\n                Predict: 1.0\n               Else  Day_Of_Month &gt; 5.5)\n                If  Day_Of_Month &lt;= 8.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 8.5)\n                 Predict: 1.0\n             Else  Dest_brieman &gt; 345.0)\n              If  Dest_brieman &lt;= 348.5)\n               If  Month &lt;= 11.5)\n                If  Day_Of_Month &lt;= 19.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 19.5)\n                 Predict: 0.0\n               Else  Month &gt; 11.5)\n                Predict: 1.0\n              Else  Dest_brieman &gt; 348.5)\n               If  Day_Of_Month &lt;= 22.5)\n                If  Day_Of_Month &lt;= 5.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 5.5)\n                 Predict: 0.0\n               Else  Day_Of_Month &gt; 22.5)\n                Predict: 1.0\n            Else  Year &gt; 2015.5)\n             If  Day_Of_Month &lt;= 25.5)\n              If  Day_Of_Month &lt;= 23.5)\n               Predict: 1.0\n              Else  Day_Of_Month &gt; 23.5)\n               If  Month &lt;= 9.5)\n                Predict: 0.0\n               Else  Month &gt; 9.5)\n                If  Month &lt;= 11.5)\n                 Predict: 1.0\n                Else  Month &gt; 11.5)\n                 Predict: 0.0\n             Else  Day_Of_Month &gt; 25.5)\n              If  Month &lt;= 9.5)\n               Predict: 1.0\n              Else  Month &gt; 9.5)\n               If  Day_Of_Month &lt;= 30.5)\n                Predict: 1.0\n               Else  Day_Of_Month &gt; 30.5)\n                If  Year &lt;= 2016.5)\n                 Predict: 1.0\n                Else  Year &gt; 2016.5)\n                 Predict: 0.0\n           Else  Year &gt; 2017.5)\n            If  Day_Of_Month &lt;= 29.5)\n             If  Day_Of_Month &lt;= 6.5)\n              Predict: 1.0\n             Else  Day_Of_Month &gt; 6.5)\n              If  Dest_brieman &lt;= 345.0)\n               If  Dest_brieman &lt;= 144.5)\n                If  CRS_Arr_Time_bin &lt;= 174.5)\n                 Predict: 0.0\n                Else  CRS_Arr_Time_bin &gt; 174.5)\n                 Predict: 1.0\n               Else  Dest_brieman &gt; 144.5)\n                If  Day_Of_Month &lt;= 28.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 28.5)\n                 Predict: 1.0\n              Else  Dest_brieman &gt; 345.0)\n               If  Day_Of_Month &lt;= 9.5)\n                If  Dest_brieman &lt;= 349.5)\n                 Predict: 0.0\n                Else  Dest_brieman &gt; 349.5)\n                 Predict: 1.0\n               Else  Day_Of_Month &gt; 9.5)\n                Predict: 1.0\n            Else  Day_Of_Month &gt; 29.5)\n             If  Day_Of_Month &lt;= 30.5)\n              If  Dest_brieman &lt;= 355.5)\n               Predict: 0.0\n              Else  Dest_brieman &gt; 355.5)\n               If  CRS_Arr_Time_bin &lt;= 217.0)\n                If  Dest_brieman &lt;= 358.5)\n                 Predict: 1.0\n                Else  Dest_brieman &gt; 358.5)\n                 Predict: 0.0\n               Else  CRS_Arr_Time_bin &gt; 217.0)\n                Predict: 0.0\n             Else  Day_Of_Month &gt; 30.5)\n              Predict: 1.0\n        Else  Op_Unique_Carrier_brieman &gt; 17.5)\n         If  Origin_Activity &lt;= 6.5)\n          If  Origin_Dest_brieman &lt;= 5117.5)\n           If  Origin_brieman &lt;= 253.5)\n            If  Origin_Activity &lt;= 4.5)\n             If  CRS_Arr_Time_bin &lt;= 193.5)\n              If  Origin_Dest_brieman &lt;= 4375.0)\n               If  CRS_Arr_Time_bin &lt;= 41.0)\n                If  Day_Of_Month &lt;= 16.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 16.5)\n                 Predict: 0.0\n               Else  CRS_Arr_Time_bin &gt; 41.0)\n                If  CRS_Elapsed_Time_bin &lt;= 5.5)\n                 Predict: 0.0\n                Else  CRS_Elapsed_Time_bin &gt; 5.5)\n                 Predict: 1.0\n              Else  Origin_Dest_brieman &gt; 4375.0)\n               If  Origin_brieman &lt;= 247.5)\n                If  Month &lt;= 9.5)\n                 Predict: 0.0\n                Else  Month &gt; 9.5)\n                 Predict: 1.0\n               Else  Origin_brieman &gt; 247.5)\n                Predict: 1.0\n             Else  CRS_Arr_Time_bin &gt; 193.5)\n              If  Year &lt;= 2017.5)\n               If  Op_Unique_Carrier_brieman &lt;= 18.5)\n                Predict: 0.0\n               Else  Op_Unique_Carrier_brieman &gt; 18.5)\n                If  Day_Of_Month &lt;= 24.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 24.5)\n                 Predict: 0.0\n              Else  Year &gt; 2017.5)\n               If  Dest_brieman &lt;= 181.5)\n                If  Day_Of_Month &lt;= 23.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 23.5)\n                 Predict: 0.0\n               Else  Dest_brieman &gt; 181.5)\n                If  Day_Of_Month &lt;= 25.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 25.5)\n                 Predict: 1.0\n            Else  Origin_Activity &gt; 4.5)\n             If  Distance_Group &lt;= 1.5)\n              Predict: 1.0\n             Else  Distance_Group &gt; 1.5)\n              If  Origin_brieman &lt;= 123.5)\n               If  Dest_brieman &lt;= 330.5)\n                Predict: 1.0\n               Else  Dest_brieman &gt; 330.5)\n                If  Year &lt;= 2017.5)\n                 Predict: 1.0\n                Else  Year &gt; 2017.5)\n                 Predict: 0.0\n              Else  Origin_brieman &gt; 123.5)\n               If  Day_Of_Month &lt;= 3.5)\n                If  CRS_Arr_Time_bin &lt;= 52.5)\n                 Predict: 0.0\n                Else  CRS_Arr_Time_bin &gt; 52.5)\n                 Predict: 1.0\n               Else  Day_Of_Month &gt; 3.5)\n                Predict: 1.0\n           Else  Origin_brieman &gt; 253.5)\n            If  Dest_brieman &lt;= 345.0)\n             If  CRS_Arr_Time_bin &lt;= 191.5)\n              If  CRS_Dep_Time_bin &lt;= 210.5)\n               If  Day_Of_Month &lt;= 17.5)\n                If  Origin_brieman &lt;= 326.5)\n                 Predict: 0.0\n                Else  Origin_brieman &gt; 326.5)\n                 Predict: 1.0\n               Else  Day_Of_Month &gt; 17.5)\n                If  Origin_brieman &lt;= 299.5)\n                 Predict: 1.0\n                Else  Origin_brieman &gt; 299.5)\n                 Predict: 0.0\n              Else  CRS_Dep_Time_bin &gt; 210.5)\n               If  Op_Unique_Carrier_brieman &lt;= 18.5)\n                If  CRS_Arr_Time_bin &lt;= 77.0)\n                 Predict: 0.0\n                Else  CRS_Arr_Time_bin &gt; 77.0)\n                 Predict: 1.0\n               Else  Op_Unique_Carrier_brieman &gt; 18.5)\n                If  Dest_brieman &lt;= 158.5)\n                 Predict: 1.0\n                Else  Dest_brieman &gt; 158.5)\n                 Predict: 0.0\n             Else  CRS_Arr_Time_bin &gt; 191.5)\n              If  CRS_Dep_Time_bin &lt;= 214.5)\n               If  Dest_brieman &lt;= 329.5)\n                Predict: 0.0\n               Else  Dest_brieman &gt; 329.5)\n                If  Distance_Group &lt;= 1.5)\n                 Predict: 0.0\n                Else  Distance_Group &gt; 1.5)\n                 Predict: 1.0\n              Else  CRS_Dep_Time_bin &gt; 214.5)\n               If  Distance_Group &lt;= 3.5)\n                Predict: 1.0\n               Else  Distance_Group &gt; 3.5)\n                Predict: 0.0\n            Else  Dest_brieman &gt; 345.0)\n             If  Year &lt;= 2017.5)\n              If  CRS_Arr_Time_bin &lt;= 213.5)\n               If  CRS_Dep_Time_bin &lt;= 163.5)\n                If  Distance_Group &lt;= 10.5)\n                 Predict: 1.0\n                Else  Distance_Group &gt; 10.5)\n                 Predict: 0.0\n               Else  CRS_Dep_Time_bin &gt; 163.5)\n                Predict: 1.0\n              Else  CRS_Arr_Time_bin &gt; 213.5)\n               If  Day_Of_Month &lt;= 8.5)\n                Predict: 0.0\n               Else  Day_Of_Month &gt; 8.5)\n                If  CRS_Arr_Time_bin &lt;= 220.5)\n                 Predict: 0.0\n                Else  CRS_Arr_Time_bin &gt; 220.5)\n                 Predict: 1.0\n             Else  Year &gt; 2017.5)\n              If  Month &lt;= 10.5)\n               If  Day_Of_Month &lt;= 12.5)\n                If  Day_Of_Month &lt;= 7.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 7.5)\n                 Predict: 1.0\n               Else  Day_Of_Month &gt; 12.5)\n                Predict: 0.0\n              Else  Month &gt; 10.5)\n               If  CRS_Dep_Time_bin &lt;= 212.5)\n                If  Day_Of_Month &lt;= 11.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 11.5)\n                 Predict: 1.0\n               Else  CRS_Dep_Time_bin &gt; 212.5)\n                If  Day_Of_Month &lt;= 4.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 4.5)\n                 Predict: 0.0\n          Else  Origin_Dest_brieman &gt; 5117.5)\n           If  Origin_brieman &lt;= 322.5)\n            If  Origin_brieman &lt;= 299.5)\n             If  CRS_Arr_Time_bin &lt;= 60.5)\n              If  Dest_brieman &lt;= 278.5)\n               If  Year &lt;= 2016.5)\n                If  Year &lt;= 2015.5)\n                 Predict: 0.0\n                Else  Year &gt; 2015.5)\n                 Predict: 1.0\n               Else  Year &gt; 2016.5)\n                If  Dest_brieman &lt;= 228.5)\n                 Predict: 1.0\n                Else  Dest_brieman &gt; 228.5)\n                 Predict: 0.0\n              Else  Dest_brieman &gt; 278.5)\n               If  Day_Of_Month &lt;= 20.5)\n                If  CRS_Dep_Time_bin &lt;= 222.5)\n                 Predict: 0.0\n                Else  CRS_Dep_Time_bin &gt; 222.5)\n                 Predict: 1.0\n               Else  Day_Of_Month &gt; 20.5)\n                If  CRS_Dep_Time_bin &lt;= 204.5)\n                 Predict: 0.0\n                Else  CRS_Dep_Time_bin &gt; 204.5)\n                 Predict: 1.0\n             Else  CRS_Arr_Time_bin &gt; 60.5)\n              If  Origin_Activity &lt;= 3.5)\n               Predict: 1.0\n              Else  Origin_Activity &gt; 3.5)\n               If  CRS_Dep_Time_bin &lt;= 187.5)\n                If  CRS_Arr_Time_bin &lt;= 230.5)\n                 Predict: 1.0\n                Else  CRS_Arr_Time_bin &gt; 230.5)\n                 Predict: 0.0\n               Else  CRS_Dep_Time_bin &gt; 187.5)\n                Predict: 1.0\n            Else  Origin_brieman &gt; 299.5)\n             If  CRS_Dep_Time_bin &lt;= 200.5)\n              If  Dest_brieman &lt;= 217.5)\n               If  Dest_brieman &lt;= 112.5)\n                Predict: 1.0\n               Else  Dest_brieman &gt; 112.5)\n                If  Origin_brieman &lt;= 316.5)\n                 Predict: 0.0\n                Else  Origin_brieman &gt; 316.5)\n                 Predict: 1.0\n              Else  Dest_brieman &gt; 217.5)\n               If  Day_Of_Month &lt;= 29.5)\n                Predict: 1.0\n               Else  Day_Of_Month &gt; 29.5)\n                Predict: 0.0\n             Else  CRS_Dep_Time_bin &gt; 200.5)\n              If  Op_Unique_Carrier_brieman &lt;= 18.5)\n               If  Dest_brieman &lt;= 240.5)\n                If  Day_Of_Month &lt;= 24.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 24.5)\n                 Predict: 0.0\n               Else  Dest_brieman &gt; 240.5)\n                Predict: 0.0\n              Else  Op_Unique_Carrier_brieman &gt; 18.5)\n               If  Origin_Activity &lt;= 3.5)\n                If  Distance_Group &lt;= 4.5)\n                 Predict: 1.0\n                Else  Distance_Group &gt; 4.5)\n                 Predict: 0.0\n               Else  Origin_Activity &gt; 3.5)\n                Predict: 1.0\n           Else  Origin_brieman &gt; 322.5)\n            If  Day_Of_Month &lt;= 14.5)\n             If  Year &lt;= 2016.5)\n              If  CRS_Dep_Time_bin &lt;= 174.5)\n               If  Origin_Dest_brieman &lt;= 5170.5)\n                Predict: 1.0\n               Else  Origin_Dest_brieman &gt; 5170.5)\n                Predict: 0.0\n              Else  CRS_Dep_Time_bin &gt; 174.5)\n               If  Origin_Dest_brieman &lt;= 5813.0)\n                If  CRS_Arr_Time_bin &lt;= 4.5)\n                 Predict: 1.0\n                Else  CRS_Arr_Time_bin &gt; 4.5)\n                 Predict: 0.0\n               Else  Origin_Dest_brieman &gt; 5813.0)\n                Predict: 1.0\n             Else  Year &gt; 2016.5)\n              If  Distance_Group &lt;= 1.5)\n               If  Month &lt;= 10.5)\n                Predict: 0.0\n               Else  Month &gt; 10.5)\n                If  Day_Of_Month &lt;= 2.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 2.5)\n                 Predict: 0.0\n              Else  Distance_Group &gt; 1.5)\n               If  Origin_Activity &lt;= 3.5)\n                If  CRS_Arr_Time_bin &lt;= 214.5)\n                 Predict: 1.0\n                Else  CRS_Arr_Time_bin &gt; 214.5)\n                 Predict: 0.0\n               Else  Origin_Activity &gt; 3.5)\n                If  CRS_Arr_Time_bin &lt;= 0.5)\n                 Predict: 0.0\n                Else  CRS_Arr_Time_bin &gt; 0.5)\n                 Predict: 1.0\n            Else  Day_Of_Month &gt; 14.5)\n             If  Origin_Dest_brieman &lt;= 5221.5)\n              If  Dest_brieman &lt;= 277.5)\n               If  CRS_Dep_Time_bin &lt;= 162.5)\n                Predict: 0.0\n               Else  CRS_Dep_Time_bin &gt; 162.5)\n                If  Month &lt;= 9.5)\n                 Predict: 0.0\n                Else  Month &gt; 9.5)\n                 Predict: 1.0\n              Else  Dest_brieman &gt; 277.5)\n               If  Day_Of_Month &lt;= 25.5)\n                Predict: 0.0\n               Else  Day_Of_Month &gt; 25.5)\n                If  Year &lt;= 2016.5)\n                 Predict: 0.0\n                Else  Year &gt; 2016.5)\n                 Predict: 1.0\n             Else  Origin_Dest_brieman &gt; 5221.5)\n              If  Origin_Activity &lt;= 3.5)\n               If  Day_Of_Month &lt;= 18.5)\n                If  Dest_brieman &lt;= 337.5)\n                 Predict: 1.0\n                Else  Dest_brieman &gt; 337.5)\n                 Predict: 0.0\n               Else  Day_Of_Month &gt; 18.5)\n                Predict: 1.0\n              Else  Origin_Activity &gt; 3.5)\n               If  Origin_brieman &lt;= 332.5)\n                Predict: 1.0\n               Else  Origin_brieman &gt; 332.5)\n                If  Year &lt;= 2015.5)\n                 Predict: 0.0\n                Else  Year &gt; 2015.5)\n                 Predict: 1.0\n         Else  Origin_Activity &gt; 6.5)\n          If  Origin_Dest_brieman &lt;= 5117.5)\n           If  Origin_Activity &lt;= 11.5)\n            If  Origin_brieman &lt;= 262.5)\n             If  Day_Of_Month &lt;= 22.5)\n              If  CRS_Dep_Time_bin &lt;= 162.5)\n               If  Day_Of_Month &lt;= 5.5)\n                Predict: 1.0\n               Else  Day_Of_Month &gt; 5.5)\n                Predict: 0.0\n              Else  CRS_Dep_Time_bin &gt; 162.5)\n               If  Dest_brieman &lt;= 330.5)\n                If  Origin_brieman &lt;= 67.5)\n                 Predict: 0.0\n                Else  Origin_brieman &gt; 67.5)\n                 Predict: 1.0\n               Else  Dest_brieman &gt; 330.5)\n                If  CRS_Dep_Time_bin &lt;= 224.5)\n                 Predict: 1.0\n                Else  CRS_Dep_Time_bin &gt; 224.5)\n                 Predict: 0.0\n             Else  Day_Of_Month &gt; 22.5)\n              If  Origin_Dest_brieman &lt;= 4446.5)\n               If  CRS_Arr_Time_bin &lt;= 74.5)\n                If  Day_Of_Month &lt;= 25.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 25.5)\n                 Predict: 1.0\n               Else  CRS_Arr_Time_bin &gt; 74.5)\n                Predict: 1.0\n              Else  Origin_Dest_brieman &gt; 4446.5)\n               If  Dest_brieman &lt;= 260.5)\n                Predict: 1.0\n               Else  Dest_brieman &gt; 260.5)\n                If  Year &lt;= 2015.5)\n                 Predict: 1.0\n                Else  Year &gt; 2015.5)\n                 Predict: 0.0\n            Else  Origin_brieman &gt; 262.5)\n             If  Origin_Activity &lt;= 8.5)\n              If  CRS_Dep_Time_bin &lt;= 201.5)\n               If  CRS_Arr_Time_bin &lt;= 224.5)\n                If  CRS_Arr_Time_bin &lt;= 184.5)\n                 Predict: 0.0\n                Else  CRS_Arr_Time_bin &gt; 184.5)\n                 Predict: 1.0\n               Else  CRS_Arr_Time_bin &gt; 224.5)\n                Predict: 0.0\n              Else  CRS_Dep_Time_bin &gt; 201.5)\n               If  Origin_brieman &lt;= 300.5)\n                If  Dest_brieman &lt;= 155.5)\n                 Predict: 1.0\n                Else  Dest_brieman &gt; 155.5)\n                 Predict: 0.0\n               Else  Origin_brieman &gt; 300.5)\n                Predict: 1.0\n             Else  Origin_Activity &gt; 8.5)\n              If  Year &lt;= 2017.5)\n               If  CRS_Dep_Time_bin &lt;= 177.5)\n                If  Day_Of_Month &lt;= 8.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 8.5)\n                 Predict: 1.0\n               Else  CRS_Dep_Time_bin &gt; 177.5)\n                If  Dest_brieman &lt;= 345.0)\n                 Predict: 1.0\n                Else  Dest_brieman &gt; 345.0)\n                 Predict: 0.0\n              Else  Year &gt; 2017.5)\n               If  CRS_Elapsed_Time_bin &lt;= 5.5)\n                If  CRS_Elapsed_Time_bin &lt;= 3.5)\n                 Predict: 0.0\n                Else  CRS_Elapsed_Time_bin &gt; 3.5)\n                 Predict: 1.0\n               Else  CRS_Elapsed_Time_bin &gt; 5.5)\n                Predict: 0.0\n           Else  Origin_Activity &gt; 11.5)\n            If  Month &lt;= 11.5)\n             If  CRS_Elapsed_Time_bin &lt;= 5.5)\n              If  CRS_Arr_Time_bin &lt;= 231.5)\n               If  Day_Of_Month &lt;= 4.5)\n                If  Month &lt;= 9.5)\n                 Predict: 0.0\n                Else  Month &gt; 9.5)\n                 Predict: 1.0\n               Else  Day_Of_Month &gt; 4.5)\n                Predict: 1.0\n              Else  CRS_Arr_Time_bin &gt; 231.5)\n               If  CRS_Elapsed_Time_bin &lt;= 3.5)\n                If  Day_Of_Month &lt;= 7.5)\n                 Predict: 1.0\n                Else  Day_Of_Month &gt; 7.5)\n                 Predict: 0.0\n               Else  CRS_Elapsed_Time_bin &gt; 3.5)\n                If  Origin_Activity &lt;= 36.5)\n                 Predict: 0.0\n                Else  Origin_Activity &gt; 36.5)\n                 Predict: 1.0\n             Else  CRS_Elapsed_Time_bin &gt; 5.5)\n              If  Year &lt;= 2016.5)\n               If  Day_Of_Month &lt;= 22.5)\n                If  CRS_Dep_Time_bin &lt;= 231.5)\n                 Predict: 1.0\n                Else  CRS_Dep_Time_bin &gt; 231.5)\n                 Predict: 0.0\n               Else  Day_Of_Month &gt; 22.5)\n                If  CRS_Dep_Time_bin &lt;= 183.5)\n                 Predict: 1.0\n                Else  CRS_Dep_Time_bin &gt; 183.5)\n                 Predict: 0.0\n              Else  Year &gt; 2016.5)\n               If  CRS_Dep_Time_bin &lt;= 183.5)\n                Predict: 0.0\n               Else  CRS_Dep_Time_bin &gt; 183.5)\n                If  Dest_brieman &lt;= 170.5)\n                 Predict: 1.0\n                Else  Dest_brieman &gt; 170.5)\n                 Predict: 0.0\n            Else  Month &gt; 11.5)\n             If  Day_Of_Month &lt;= 13.5)\n              If  Origin_Activity &lt;= 15.5)\n               If  CRS_Dep_Time_bin &lt;= 187.5)\n                If  CRS_Arr_Time_bin &lt;= 221.5)\n                 Predict: 1.0\n                Else  CRS_Arr_Time_bin &gt; 221.5)\n                 Predict: 0.0\n               Else  CRS_Dep_Time_bin &gt; 187.5)\n                Predict: 1.0\n              Else  Origin_Activity &gt; 15.5)\n               If  Dest_brieman &lt;= 249.5)\n                If  CRS_Arr_Time_bin &lt;= 211.5)\n                 Predict: 0.0\n                Else  CRS_Arr_Time_bin &gt; 211.5)\n                 Predict: 1.0\n               Else  Dest_brieman &gt; 249.5)\n                If  Origin_Dest_brieman &lt;= 4998.5)\n                 Predict: 0.0\n                Else  Origin_Dest_brieman &gt; 4998.5)\n                 Predict: 1.0\n             Else  Day_Of_Month &gt; 13.5)\n              If  Dest_brieman &lt;= 73.5)\n               Predict: 0.0\n              Else  Dest_brieman &gt; 73.5)\n               Predict: 1.0\n          Else  Origin_Dest_brieman &gt; 5117.5)\n           If  CRS_Elapsed_Time_bin &lt;= 6.5)\n            If  Day_Of_Month &lt;= 13.5)\n             If  Origin_Dest_brieman &lt;= 5541.0)\n              If  Dest_brieman &lt;= 312.5)\n               If  Dest_brieman &lt;= 208.5)\n                If  CRS_Dep_Time_bin &lt;= 172.5)\n                 Predict: 1.0\n                Else  CRS_Dep_Time_bin &gt; 172.5)\n                 Predict: 0.0\n               Else  Dest_brieman &gt; 208.5)\n                Predict: 1.0\n              Else  Dest_brieman &gt; 312.5)\n               If  CRS_Arr_Time_bin &lt;= 203.5)\n                If  CRS_Arr_Time_bin &lt;= 53.5)\n                 Predict: 1.0\n                Else  CRS_Arr_Time_bin &gt; 53.5)\n                 Predict: 0.0\n               Else  CRS_Arr_Time_bin &gt; 203.5)\n                If  Origin_Activity &lt;= 24.5)\n                 Predict: 1.0\n                Else  Origin_Activity &gt; 24.5)\n                 Predict: 0.0\n             Else  Origin_Dest_brieman &gt; 5541.0)\n              If  CRS_Arr_Time_bin &lt;= 174.5)\n               Predict: 1.0\n              Else  CRS_Arr_Time_bin &gt; 174.5)\n               If  Origin_brieman &lt;= 260.5)\n                Predict: 1.0\n               Else  Origin_brieman &gt; 260.5)\n                If  Origin_brieman &lt;= 268.5)\n                 Predict: 0.0\n                Else  Origin_brieman &gt; 268.5)\n                 Predict: 1.0\n            Else  Day_Of_Month &gt; 13.5)\n             If  Origin_brieman &lt;= 322.5)\n              If  Year &lt;= 2017.5)\n               Predict: 1.0\n              Else  Year &gt; 2017.5)\n               If  Month &lt;= 10.5)\n                If  Dest_brieman &lt;= 337.5)\n                 Predict: 0.0\n                Else  Dest_brieman &gt; 337.5)\n                 Predict: 1.0\n               Else  Month &gt; 10.5)\n                Predict: 1.0\n             Else  Origin_brieman &gt; 322.5)\n              If  Origin_Activity &lt;= 16.5)\n               Predict: 1.0\n              Else  Origin_Activity &gt; 16.5)\n               If  Day_Of_Month &lt;= 14.5)\n                If  Month &lt;= 10.5)\n                 Predict: 0.0\n                Else  Month &gt; 10.5)\n                 Predict: 1.0\n               Else  Day_Of_Month &gt; 14.5)\n                Predict: 1.0\n           Else  CRS_Elapsed_Time_bin &gt; 6.5)\n            If  CRS_Dep_Time_bin &lt;= 190.5)\n             If  Origin_Activity &lt;= 15.5)\n              If  Distance_Group &lt;= 10.5)\n               If  Origin_Activity &lt;= 9.5)\n                If  Year &lt;= 2017.5)\n                 Predict: 0.0\n                Else  Year &gt; 2017.5)\n                 Predict: 1.0\n               Else  Origin_Activity &gt; 9.5)\n                If  Day_Of_Month &lt;= 23.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 23.5)\n                 Predict: 1.0\n              Else  Distance_Group &gt; 10.5)\n               If  Month &lt;= 9.5)\n                If  Year &lt;= 2016.5)\n                 Predict: 1.0\n                Else  Year &gt; 2016.5)\n                 Predict: 0.0\n               Else  Month &gt; 9.5)\n                Predict: 0.0\n             Else  Origin_Activity &gt; 15.5)\n              If  CRS_Dep_Time_bin &lt;= 180.5)\n               If  CRS_Arr_Time_bin &lt;= 203.5)\n                If  Day_Of_Month &lt;= 20.5)\n                 Predict: 0.0\n                Else  Day_Of_Month &gt; 20.5)\n                 Predict: 1.0\n               Else  CRS_Arr_Time_bin &gt; 203.5)\n                Predict: 1.0\n              Else  CRS_Dep_Time_bin &gt; 180.5)\n               Predict: 0.0\n            Else  CRS_Dep_Time_bin &gt; 190.5)\n             If  Month &lt;= 11.5)\n              If  Day_Of_Month &lt;= 29.5)\n               If  Origin_Activity &lt;= 8.5)\n                Predict: 0.0\n               Else  Origin_Activity &gt; 8.5)\n                Predict: 1.0\n              Else  Day_Of_Month &gt; 29.5)\n               Predict: 0.0\n             Else  Month &gt; 11.5)\n              If  Origin_brieman &lt;= 300.5)\n               If  Year &lt;= 2016.5)\n                Predict: 0.0\n               Else  Year &gt; 2016.5)\n                Predict: 1.0\n              Else  Origin_brieman &gt; 300.5)\n               Predict: 1.0\n\n\n Provided Features:  [&#39;Year&#39;, &#39;Month&#39;, &#39;Day_Of_Month&#39;, &#39;Day_Of_Week&#39;, &#39;Distance_Group&#39;, &#39;CRS_Dep_Time_bin&#39;, &#39;CRS_Arr_Time_bin&#39;, &#39;CRS_Elapsed_Time_bin&#39;, &#39;Origin_Activity&#39;, &#39;Op_Unique_Carrier_brieman&#39;, &#39;Origin_brieman&#39;, &#39;Dest_brieman&#39;, &#39;Day_Of_Year_brieman&#39;, &#39;Origin_Dest_brieman&#39;, &#39;Dep_Time_Of_Week_brieman&#39;, &#39;Arr_Time_Of_Week_brieman&#39;, &#39;Holiday_brieman&#39;]\n\n     Used Features:  {&#39;Year&#39;, &#39;CRS_Arr_Time_bin&#39;, &#39;CRS_Elapsed_Time_bin&#39;, &#39;Day_Of_Month&#39;, &#39;Origin_Activity&#39;, &#39;Origin_Dest_brieman&#39;, &#39;Distance_Group&#39;, &#39;CRS_Dep_Time_bin&#39;, &#39;Dest_brieman&#39;, &#39;Origin_brieman&#39;, &#39;Month&#39;, &#39;Op_Unique_Carrier_brieman&#39;, &#39;Day_Of_Week&#39;}\n\n\n</div>"]}}],"execution_count":83},{"cell_type":"code","source":["# Hyper parameter tuning to find optimal parameters for the Decision Tree model\nfor max_depth in [5,10,15,20,30,50,100]:\n  dt_model = TrainDecisionTreeModel(train_smoted, [va_base], outcomeName, maxDepth=max_depth, maxBins=200)\n  print(\"\\nMax Depth:\", max_depth)\n  PredictAndEvaluate(dt_model, val, 'val', outcomeName)"],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"markdown","source":["### Training Random Forest on Smoted (Balanced) Training Dataset\n\nDecision trees have a tendency to overfit because they memorize the training data. One way to overcome this limitation is to prune the tree to help it generalize better. Another approach is to build a Random Forest (i.e), a forest of random decision trees, where the \"randomness\" comes from the random subset of features (without replacement) and observations (with replacement) given to each tree to consider. Multiple trees are generated through the random forest training, where each tree is trained on their own subset of data and features. \n\nAt inference time, the inference on a single data point involves taking the results or \"votes\" from each tree on the classification for that data point and aggregating them as an average of results to be the final prediction given by the random forest. Random forests tend to perform better than decision trees because they can generalize more easily. However, random forests have a bit of a loss in terms of interpretability compared to decision trees, as the decision making becomes a bit more distributed and requires aggregation. Having said that, we can still plot a ranking of feature importances for a random forest to understand which features are given most/least importance. \n\nBelow, we train and evaluate a simple random forest model, and rank the importance of each of our considered features, as shown in the barplot below. From this plot, we can see that `CRS_Dep_Time_bin` and `Origin_Activity` are given the highest importance by the full random forest model, meaning that these features gave some of the highest information gain among all the trees in the random forest model. Following this, we see `CRS_Arr_Time_bin`, `Origin_Dest_brieman`, and `Day_Of_Week` are next in importance, with features relating to the time of year, the elapsed time, and the distance traveled being less imortant. From this, we can generally infer that infromation about the origin airport along with the time of the day and the day of the week the flight is scheduled to take off and arrive can give us important information about predicting a departure delay.\n\nWith regard to performance on this single random forest model, we see a similar story to the decision tree. That is to say, the model performs quite well on the SMOTEd training data, but seems to fall short in performance on the original training and validation data, although not quite as severely as that seen with the decision tree, suggesting that the random forest algorithm may have helped reduce the amount of overfitting seen in the tree (though some overfitting is still present)."],"metadata":{}},{"cell_type":"code","source":["# Trains a simple Random Forest model\ndef TrainRandomForestModel(trainingData, stages, outcomeNames, maxDepth, maxBins, numTrees):\n  # Train Model\n  rf = RandomForestClassifier(labelCol = outcomeName, featuresCol = \"features\", seed = 6, maxDepth = maxDepth, maxBins=maxBins, numTrees=numTrees) \n  pipeline = Pipeline(stages = stages + [rf])\n  rf_model = pipeline.fit(trainingData)\n  return rf_model"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":86},{"cell_type":"code","source":["rf_model = TrainRandomForestModel(train_smoted, [va_base], outcomeName, maxDepth=10, maxBins=200, numTrees=20)\nPredictAndEvaluate(rf_model, train_smoted, 'train_smoted', outcomeName)\nPredictAndEvaluate(rf_model, train, 'train', outcomeName)\nPredictAndEvaluate(rf_model, val, 'val', outcomeName)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model Evaluation - train_smoted\n-----------------------------\nAccuracy = 0.6622529, Precision = 0.6554999, Recall = 0.7060148, f-score = 0.6798203, AreaUnderROC = 0.7217311, AreaUnderPRC = 0.7117491\n\nConfusion Matrix:\n        count\nTP  13499572\nFN   5621233\nTN  11433848\nFP   7094743 \n\nModel Evaluation - train\n-----------------------------\nAccuracy = 0.6550594, Precision = 0.1691789, Recall = 0.5122745, f-score = 0.2543564, AreaUnderROC = 0.6346952, AreaUnderPRC = 0.1772946\n\nConfusion Matrix:\n        count\nTP   1266654\nFN   1205954\nTN  12836393\nFP   6220415 \n\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6542051, Precision = 0.1700237, Recall = 0.5157057, f-score = 0.2557341, AreaUnderROC = 0.6354687, AreaUnderPRC = 0.1785722\n\nConfusion Matrix:\n       count\nTP   182615\nFN   171492\nTN  1828335\nFP   891441 \n\n</div>"]}}],"execution_count":87},{"cell_type":"code","source":["# Plot feature importance of the random forest model\nrf_importances =list(rf_model.stages[-1].featureImportances.toArray())\nfig = go.Figure([go.Bar(x=featureNames, y=rf_importances)]) \nfig.update_layout(title_text='Feature Importances in Random Forest Model', xaxis={'categoryorder':'total descending'}, xaxis_tickangle=-45)\nfig.update_yaxes(title_text=\"Feature Importance\")\nfig.update_xaxes(title_text=\"Features\")\nfig.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"b3eadbd3-0089-4690-bc5b-5fb0996d916f\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"b3eadbd3-0089-4690-bc5b-5fb0996d916f\")) {\n                    Plotly.newPlot(\n                        'b3eadbd3-0089-4690-bc5b-5fb0996d916f',\n                        [{\"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"y\": [0.0016088413490240373, 0.05000146178878333, 0.011668796970531557, 0.08945086824661716, 0.004088317181559224, 0.2747925675188488, 0.12226745986574201, 0.003609232636990875, 0.21466181174726193, 0.05845303204098189, 0.016653047409099543, 0.034852236971255314, 0.0, 0.11789232627330433, 0.0, 0.0, 0.0]}],\n                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Feature Importances in Random Forest Model\"}, \"xaxis\": {\"categoryorder\": \"total descending\", \"tickangle\": -45, \"title\": {\"text\": \"Features\"}}, \"yaxis\": {\"title\": {\"text\": \"Feature Importance\"}}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":88},{"cell_type":"markdown","source":["For hyper-parameter tuning our random forest model, we considered the following parameters: \n- numTrees: \n > - Represents the number of trees in the forest.\n > - More trees reduce overfitting but takes longer to train. \n > - Values used are 10, 20, 50, 100, 200.\n \n- maxDepth: \n > - Represents the maximum depth of each tree in the forest. \n > - The deeper the tree, the more splits it has and it captures more information about the data but leads to overfitting, as discussed above. \n > - Values used are 5, 10, 15.\n\nThe experiments we ran for our random forest model are shown below:"],"metadata":{}},{"cell_type":"code","source":["# Hyper parameter tuning to find optimal parameters for the random forest model\nimport time\n\nfor maxDepth in [5, 10, 15]:\n    for numTrees in [10, 20, 50, 100, 200]:\n        t0 = time.time()\n        # Train a RandomForest model\n        rforest_model = TrainRandomForestModel(train_smoted, [va_base], outcomeName, maxDepth=maxDepth, maxBins=200, numTrees=numTrees)\n        print(\"\\nmaxDepth:\", maxDepth,\", numTrees:\", numTrees)\n        PredictAndEvaluate(rforest_model, val, 'val', outcomeName)\n        t1 = time.time()\n        print(\"finish in %f seconds\" % (t1-t0))\n        print('*******************')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\nmaxDepth: 5 , numTrees: 10\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.5914259, Precision = 0.1661318, Recall = 0.6336136, f-score = 0.2632422, AreaUnderROC = 0.6474931, AreaUnderPRC = 0.1810566\n\nConfusion Matrix:\n       count\nTP   224367\nFN   129740\nTN  1593607\nFP  1126169 \n\nfinish in 118.956747 seconds\n*******************\n\nmaxDepth: 5 , numTrees: 20\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.5989522, Precision = 0.1639272, Recall = 0.6051702, f-score = 0.2579748, AreaUnderROC = 0.6406965, AreaUnderPRC = 0.1749929\n\nConfusion Matrix:\n       count\nTP   214295\nFN   139812\nTN  1626814\nFP  1092962 \n\nfinish in 291.069050 seconds\n*******************\n\nmaxDepth: 5 , numTrees: 50\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6057075, Precision = 0.1659364, Recall = 0.601708, f-score = 0.2601342, AreaUnderROC = 0.6434111, AreaUnderPRC = 0.1777422\n\nConfusion Matrix:\n       count\nTP   213069\nFN   141038\nTN  1648805\nFP  1070971 \n\nfinish in 391.879560 seconds\n*******************\n\nmaxDepth: 5 , numTrees: 100\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6049358, Precision = 0.1640636, Recall = 0.5932359, f-score = 0.2570408, AreaUnderROC = 0.6400135, AreaUnderPRC = 0.1766616\n\nConfusion Matrix:\n       count\nTP   210069\nFN   144038\nTN  1649433\nFP  1070343 \n\nfinish in 631.625718 seconds\n*******************\n\nmaxDepth: 5 , numTrees: 200\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6050012, Precision = 0.1649875, Recall = 0.5980819, f-score = 0.2586292, AreaUnderROC = 0.6415828, AreaUnderPRC = 0.1782341\n\nConfusion Matrix:\n       count\nTP   211785\nFN   142322\nTN  1647918\nFP  1071858 \n\nfinish in 912.671784 seconds\n*******************\n\nmaxDepth: 10 , numTrees: 10\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6430697, Precision = 0.1726967, Recall = 0.5535926, f-score = 0.263266, AreaUnderROC = 0.6477268, AreaUnderPRC = 0.1860668\n\nConfusion Matrix:\n       count\nTP   196031\nFN   158076\nTN  1780690\nFP   939086 \n\nfinish in 158.189163 seconds\n*******************\n\nmaxDepth: 10 , numTrees: 20\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6467852, Precision = 0.1720742, Recall = 0.5420876, f-score = 0.2612273, AreaUnderROC = 0.6440754, AreaUnderPRC = 0.1827624\n\nConfusion Matrix:\n       count\nTP   191957\nFN   162150\nTN  1796185\nFP   923591 \n\nfinish in 405.629747 seconds\n*******************\n\nmaxDepth: 10 , numTrees: 50\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6498585, Precision = 0.1728339, Recall = 0.5386988, f-score = 0.2617039, AreaUnderROC = 0.6454886, AreaUnderPRC = 0.1832027\n\nConfusion Matrix:\n       count\nTP   190757\nFN   163350\nTN  1806832\nFP   912944 \n\nfinish in 990.112626 seconds\n*******************\n\nmaxDepth: 10 , numTrees: 100\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6491483, Precision = 0.172296, Recall = 0.5377612, f-score = 0.2609765, AreaUnderROC = 0.6444026, AreaUnderPRC = 0.1843993\n\nConfusion Matrix:\n       count\nTP   190425\nFN   163682\nTN  1804981\nFP   914795 \n\nfinish in 2000.537420 seconds\n*******************\n\nmaxDepth: 10 , numTrees: 200\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.650151, Precision = 0.1726988, Recall = 0.5373856, f-score = 0.2613939, AreaUnderROC = 0.6452626, AreaUnderPRC = 0.1850408\n\nConfusion Matrix:\n       count\nTP   190292\nFN   163815\nTN  1808196\nFP   911580 \n\nfinish in 4729.728167 seconds\n*******************\n\nmaxDepth: 15 , numTrees: 10\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6676015, Precision = 0.1785717, Recall = 0.5237344, f-score = 0.2663345, AreaUnderROC = 0.6500522, AreaUnderPRC = 0.1894012\n\nConfusion Matrix:\n       count\nTP   185458\nFN   168649\nTN  1866671\nFP   853105 \n\nfinish in 609.658666 seconds\n*******************\n\nmaxDepth: 15 , numTrees: 20\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6673338, Precision = 0.1780915, Recall = 0.5221896, f-score = 0.2656006, AreaUnderROC = 0.6497931, AreaUnderPRC = 0.1902498\n\nConfusion Matrix:\n       count\nTP   184911\nFN   169196\nTN  1866395\nFP   853381 \n\nfinish in 1203.103352 seconds\n*******************\n\nmaxDepth: 15 , numTrees: 50\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6676412, Precision = 0.178449, Recall = 0.5230792, f-score = 0.2661133, AreaUnderROC = 0.6507497, AreaUnderPRC = 0.1914346\n\nConfusion Matrix:\n       count\nTP   185226\nFN   168881\nTN  1867025\nFP   852751 \n\nfinish in 2748.465021 seconds\n*******************\n\nmaxDepth: 15 , numTrees: 100\nModel Evaluation - val\n-----------------------------\nAccuracy = 0.6705821, Precision = 0.1788263, Recall = 0.5176938, f-score = 0.265828, AreaUnderROC = 0.6504246, AreaUnderPRC = 0.1916837\n\nConfusion Matrix:\n       count\nTP   183319\nFN   170788\nTN  1877972\nFP   841804 \n\nfinish in 5600.550341 seconds\n*******************\n</div>"]}}],"execution_count":90},{"cell_type":"markdown","source":["After performing parameter optimization on the random forest, we found that the random forest classifier with 100 trees and maxDepth of 15 performed best with metrics as follows:\n- Accuracy of 0.67, \n- Precision of 0.17, \n- Recall of 0.51,\n- AUROC of 0.65.\n\nAs expected, performance of the random forest model is better than the performance we generally saw on a single decision tree. But, to improve the performance further, we will try to generalize our models even moreso and try an ensemble of random forests (i.e. a forest of forests), as our next approach."],"metadata":{}},{"cell_type":"markdown","source":["### Training Ensemble with Majority Class Splitted (Balanced) Training Dataset\n\nWhen we considered constructing ensembles of random forests to try to better generalize our models, we took inspiration from a model design known as stacking, which attempts to train an ensemble of models on an unbalanced dataset. The stacking approach we referred to depended on balancing the dataset via the majority class splitting approach, which we described at a high-level in section III. For this reason, we will turn to using majority class splitting to balance our dataset in order to motivate the explanation behind constructing stacked models and then return to using our SMOTEd dataset in a similar stacking approach.\n\nAs we discussed previously, the majority class splitting approach involves simply the majority class into \\\\(N\\\\) parts and constructing \\\\(N\\\\) subsets of the majority class and combining them with the entire subset of the minority class, such that each data subset is balanced, contains the full minority class, and has a \\\\(\\frac{1}{N}\\\\)th random sample of the majority class. Each of these datasets will be used to train a single model in the first stage of the ensemble. By taking this approach, we can still ensure the training data used for each model is balanced and in the process, we will not lose any information that might have been lost from simply undersampling the majority class, nor will the stage 1 models overfit to the minority class (which would have happened had we oversampled the minority class). \n\nIn the diagram below, we depict how the distribution of the datasets are shared amongst the individual random forest models used in the first stage of the ensemble stacking approach. With this approach, each model learns from the dataset independently of each other. The training of these models can be parallized in spark using the python thread pool utility. Note that in the example, we have three stage 1 models, yet the majority class is split into four parts. This fourth majority split will be reserved for the second stage of the ensemble."],"metadata":{}},{"cell_type":"markdown","source":["<img src=\"https://github.com/shajikk/temp/blob/master/img1.png?raw=true\" width=60%>"],"metadata":{}},{"cell_type":"markdown","source":["In stacking, the algorithm takes the outputs of the sub-models and learns how to combine the input predictions to  make a better final prediction. The stacking procedure consists of two levels of models. The first level generates predictions and the second level combines these predictions to generate the final prediction. As a result, the models need to be trained in two stages. The first one is shown above, where we train each individual model in parallel. The second stage is shown below, where we train a voting model that aggregates the predictions of the individual models. The last subset of data is then used for training the Stage 2 voting model, as shown below:"],"metadata":{}},{"cell_type":"markdown","source":["<img src=\"https://github.com/shajikk/temp/blob/master/img2.png?raw=true\" width=60%>"],"metadata":{}},{"cell_type":"markdown","source":["In stage 2, we take the remaining balanced dataset and run inference on stage 1 models and collect their predictions. These predictions are the features for the  second level voting model and it is used to train that model.  The final model is an assembled pipeline of all these models and can be used for prediction and evaluation purposes. Hence, a stacked ensemble can use first level predictions and conditionally decide to weigh the input predictions of the voting model differently - giving a better performance. This approach works far better than a simple majority classifier or a weighted model."],"metadata":{}},{"cell_type":"markdown","source":["The steps for stacking can be outlined as below.  \n(a) Group the **training** data into majority and minority class.   \n(b) Split the  majority class into \\\\(N + 1\\\\) groups, each group containing same number of data points as that in minority class.    \n(c) Create \\\\(N + 1\\\\) datasets for training by combining the each group from (b) with minority class from (a). Each of these groups will be balanced.  \n(d) Use \\\\(N\\\\) datasets from (c) to train the first level classifier. Once the models are generated, use the remaing one dataset from (c) to generate predictions for each of these models. These \\\\(N\\\\) predictions are the features for the second level classifier. The target/label value for the second level classifier is the target/label value of this remaining dataset.  \n(e) Train the second level classifier. A final pipeline can be created by combining the models."],"metadata":{}},{"cell_type":"code","source":["# Prepare features for ensemble\ndef PreprocessForEnsemble(mini_train_data, train_data, val_data, test_data, train_smoted_data) :\n  target       = [\"Dep_Del30\"]\n  all_features = numFeatureNames + binFeatureNames + orgFeatureNames + briFeatureNames\n  \n  assembler = VectorAssembler(inputCols=all_features, outputCol=\"features\")\n  ensemble_pipeline = Pipeline(stages=[assembler])\n\n  tmp_mini_train, tmp_train, tmp_val, tmp_test, tmp_train_smoted = (ensemble_pipeline.fit(mini_train_data).transform(mini_train_data).select([\"features\"] + target).withColumnRenamed(\"Dep_Del30\", \"label\"),\n                                                  ensemble_pipeline.fit(train_data).transform(train_data).select([\"features\"] + target).withColumnRenamed(\"Dep_Del30\", \"label\"),\n                                                  ensemble_pipeline.fit(val_data).transform(val_data).select([\"features\"] + target).withColumnRenamed(\"Dep_Del30\", \"label\"),\n                                                  ensemble_pipeline.fit(test_data).transform(test_data).select([\"features\"] + target).withColumnRenamed(\"Dep_Del30\", \"label\"),\n                                                  ensemble_pipeline.fit(train_smoted_data).transform(train_smoted_data).select([\"features\"] + target).withColumnRenamed(\"Dep_Del30\", \"label\"))  \n  featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=400).fit(tmp_train.union(tmp_val).union(tmp_test))\n  featureIndexer_smoted = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=400).fit(tmp_train_smoted.union(tmp_val).union(tmp_test))\n  return all_features, featureIndexer, featureIndexer_smoted, tmp_mini_train, tmp_train, tmp_val, tmp_test, tmp_train_smoted\n\n\nall_ensemble_features, ensemble_featureIndexer, ensemble_featureIndexer_smoted, ensemble_mini_train, ensemble_train, ensemble_val, ensemble_test, ensemble_train_smoted = PreprocessForEnsemble(mini_train, train, val, test, train_smoted)\n\nprint(all_ensemble_features)\nensemble_mini_train.show(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[&#39;Year&#39;, &#39;Month&#39;, &#39;Day_Of_Month&#39;, &#39;Day_Of_Week&#39;, &#39;Distance_Group&#39;, &#39;CRS_Dep_Time_bin&#39;, &#39;CRS_Arr_Time_bin&#39;, &#39;CRS_Elapsed_Time_bin&#39;, &#39;Origin_Activity&#39;, &#39;Op_Unique_Carrier_brieman&#39;, &#39;Origin_brieman&#39;, &#39;Dest_brieman&#39;, &#39;Day_Of_Year_brieman&#39;, &#39;Origin_Dest_brieman&#39;, &#39;Dep_Time_Of_Week_brieman&#39;, &#39;Arr_Time_Of_Week_brieman&#39;, &#39;Holiday_brieman&#39;]\n+--------------------+-----+\n            features|label|\n+--------------------+-----+\n[2018.0,10.0,1.0,...|    0|\n[2018.0,10.0,1.0,...|    0|\n+--------------------+-----+\nonly showing top 2 rows\n\n</div>"]}}],"execution_count":98},{"cell_type":"code","source":["# Intermediate checkpoint creation\nif False :\n  ensemble_val.write.mode('overwrite').format(\"parquet\").save(\"dbfs:/user/team20/finalnotebook/ensemble_val.v1.parquet\")\n  ensemble_test.write.mode('overwrite').format(\"parquet\").save(\"dbfs:/user/team20/finalnotebook/ensemble_test.v1.parquet\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":99},{"cell_type":"markdown","source":["#### Balance the dataset, partition for further training\n\nFor the purpose of training the ensemble with the majority class splitted approach, we will generate a set of 10 datasets. 9 of them will be used for training the level one random forest classifiers. The last subset will be used to train the level two classfier. This is done below:"],"metadata":{}},{"cell_type":"code","source":["def PrepareDatasetForStacking(train, outcomeName, majClass = 0, minClass = 1):\n  # Determine distribution of dataset for each outcome value (zero & one)\n  ones, zeros = train.groupBy(outcomeName).count().sort(train[outcomeName].desc()).toPandas()[\"count\"].to_list()\n\n  # Set number of models & number of datasets (3 more than ratio majority to minority class)\n  # last split use to train level 2 classifier\n  num_splits = int(zeros/ones) + 3\n  print(\"Number of splits : \" + str(num_splits))\n  \n  # Split dataset for training individual modesl and for training the voting (ensemble) model\n  zero_df = train.filter(outcomeName + ' == ' + str(majClass))\n  one_df  = train.filter(outcomeName + ' == ' + str(minClass))\n\n  # get number of values in minority class\n  one_df_count = one_df.count()\n  \n  zeros_array = zero_df.randomSplit([1.0] * num_splits, 1)\n  zeros_array_count = [s.count() for s in zeros_array]\n  ones_array = [one_df.sample(False, min(0.999999999999, r/one_df_count), 1) for r in zeros_array_count]\n  ones_array_count = [s.count() for s in ones_array]\n\n  # Array of `num_models` datasets\n  # below resampling (shuffling) may not be necessary for random forest.\n  # Need to remove it in case of performance issues\n  train_group = [a.union(b).sample(False, 0.999999999999, 1) for a, b in zip(zeros_array[0:-1], ones_array[0:-1])]\n  \n  # Construct dataset for voting (ensemble) model\n  train_combiner = zeros_array[-1].union(ones_array[-1]).sample(False, 0.999999999999, 1) # Shuffle\n  \n  return (train_combiner, train_group)\n\n# Prepare datasets for stacking\n\n# Input the training set prep-ed for ensemble approach.\ntrain_combiner, train_group = PrepareDatasetForStacking(ensemble_train, 'label')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/types.py:1636: DeprecationWarning:\n\nUsing or importing the ABCs from &#39;collections&#39; instead of from &#39;collections.abc&#39; is deprecated, and in 3.8 it will stop working\n\nNumber of splits : 10\n</div>"]}}],"execution_count":101},{"cell_type":"code","source":["# For non- smoted cases - database is partitioned.\nprint([[d.groupBy('label').count().toPandas()[\"count\"].to_list()] for d in train_group], \n train_combiner.groupBy('label').count().toPandas()[\"count\"].to_list())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[[[1905441, 1906236]], [[1903204, 1904025]], [[1904958, 1905813]], [[1907560, 1908290]], [[1906608, 1907372]], [[1901660, 1902453]], [[1905272, 1906105]], [[1905913, 1906699]], [[1903074, 1903916]]] [1905050, 1905899]\n</div>"]}}],"execution_count":102},{"cell_type":"code","source":["# For non- smoted case\nprint(ensemble_train_smoted.groupBy('label').count().toPandas()[\"count\"].to_list())\nsmoted_splits = ensemble_train_smoted.randomSplit([1.0] * 10, 1) # Split the dataset.\ntrain_combiner_smoted, train_group_smoted = smoted_splits[-1], smoted_splits[0:-1]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[18528591, 19120805]\n</div>"]}}],"execution_count":103},{"cell_type":"markdown","source":["#### Stage 1 : Train first-level classifiers"],"metadata":{}},{"cell_type":"markdown","source":["Each of the first level classifier can be trained parallelly. Concurrency is obtained by using Python's ThreadPool utility, which triggers training of various models over many workers."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\nfrom multiprocessing.pool import ThreadPool\n\n# allow up to 10 concurrent threads\npool = ThreadPool(10)\n\n# You can increase the timeout for broadcasts. Default is 300 s\nspark.conf.set('spark.sql.broadcastTimeout', '900000ms')\nspark.conf.get('spark.sql.broadcastTimeout')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[31]: &#39;900000ms&#39;</div>"]}}],"execution_count":106},{"cell_type":"markdown","source":["This method does not work well when the clusters are loaded, so may need to revert back to serial training if the setup gives timeout errors."],"metadata":{}},{"cell_type":"code","source":["# Code for parallel training.\ndef TrainEnsembleModels_parallel(en_train, featureIndexer, classifier) :\n  job = []\n  for num, _ in enumerate(en_train):\n      print(\"Create ensemble model : \" + str(num))      \n      # Chain indexer and classifier in a Pipeline \n      job.append(Pipeline(stages=[featureIndexer, classifier]))\n      \n  return pool.map(lambda x: x[0].fit(x[1]), zip(job, en_train))\n\n# Below is the code for parallel training. (Commented out now)\n# Parallel training is not done in databricks environment.      \n# ensemble_model = TrainEnsembleModels_parallel(train_group, ensemble_featureIndexer, \n#                     # Type of model we can use.\n#                     RandomForestClassifier(featuresCol=\"indexedFeatures\", maxBins=369, maxDepth=5, numTrees=5, impurity='gini')\n#                    )\n# print(\"Training done\")\n\n# The training is still done serially now to avoid databricks error during heavy load.\ndef TrainEnsembleModels(en_train, featureIndexer, classifier) :\n  model = []\n  for num, train in enumerate(en_train):\n      print(\"Create ensemble model : \" + str(num))      \n      model.append(Pipeline(stages=[featureIndexer, classifier]).fit(train))\n  return model\n      \nensemble_model = TrainEnsembleModels(train_group, ensemble_featureIndexer, \n                    #RandomForestClassifier(featuresCol=\"indexedFeatures\", maxBins=369, maxDepth=5, numTrees=5, impurity='gini')\n                    #RandomForestClassifier(featuresCol=\"indexedFeatures\", maxBins=369, maxDepth=6, numTrees=25, impurity='gini')\n                    # Works best\n                    RandomForestClassifier(featuresCol=\"indexedFeatures\", maxBins=369, maxDepth=8, numTrees=50, impurity='gini')\n                   )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":108},{"cell_type":"code","source":["# Create check points\nif False : \n  for i, model in enumerate(ensemble_model):\n    model.save(\"dbfs:/user/team20/finalnotebook/ensemble_model\" + str(i) +  \".v1.model\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":109},{"cell_type":"markdown","source":["#### Visualize feature importance for individual ensembles\n\nEach feature's importance is the average of its importance across all trees in the ensemble. The importance vector is normalized to sum to 1, thus the bars represent the weight of each feature in the individual random forests. From the plots below, we see very similar distributions across all nine random forest models, which means that each of the models learned similar things from the data subsets they were provided. More specifically, we see that `Dep_Time_Of_Week`, `Day_Of_Year`, `Arr_Time_Of_Week`, and `Origin_Dest` were the most important features, which indicates that attributes relating to the departure/arrival time, time of week, time of year, and the origin airport are likely more important for prediction departure delays, especially compared to features like `CRS_Elapsed_Time`, distance, and holidays."],"metadata":{}},{"cell_type":"code","source":["from collections import defaultdict\n\ndef makedict(em, columns, features):\n    plot = defaultdict(dict)\n    rows = int(len(em)/columns)\n    for num, m in enumerate(em):\n        plot[num]['importance'] = list(m.stages[-1].featureImportances.toArray())\n        plot[num]['features']   = features\n        plot[num]['x_pos']      = int(num/columns)+1\n        plot[num]['y_pos']      = num%columns+1\n        plot[num]['title']      = \"ensemble model {}\".format(num)\n    return plot, rows, columns\n\nplt, rows, columns = makedict(ensemble_model, columns=3, features=all_ensemble_features)\n\n\nfig = make_subplots(rows=rows, cols=columns, subplot_titles=tuple([plt[key]['title'] for key, value in plt.items()]))\n\nfor key, value in plt.items() :\n    fig.add_trace(go.Bar(\n      x=plt[key]['features'],\n      y=plt[key]['importance'],\n      #marker_color=list(map(lambda x: px.colors.sequential.thermal[x%12], range(0,len(plt[key]['features'])))),\n      marker_color=list(map(lambda x: px.colors.sequential.thermal[x] if x < 12 else px.colors.sequential.RdBu[x%12] , \n                      range(0,len(plt[key]['features'])))),\n      name = '',\n      showlegend = False,\n    ), row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    \n    fig.update_xaxes(categoryorder='total descending', row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    fig.update_xaxes(categoryorder='total descending', row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    if plt[key]['y_pos'] == 1: fig.update_yaxes(title_text=\"Feature importance\", row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    fig.update_xaxes(tickangle=-45)\n    \nfig.update_layout(height=1200, width=1200, title_text=\"Feature importance for individual ensembles (Majority class splitted)\")\nfig.update_layout(xaxis_tickangle=-45)\nfig.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"c5190629-07d8-44bc-b051-93c71f06c451\" class=\"plotly-graph-div\" style=\"height:1200px; width:1200px;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"c5190629-07d8-44bc-b051-93c71f06c451\")) {\n                    Plotly.newPlot(\n                        'c5190629-07d8-44bc-b051-93c71f06c451',\n                        [{\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x\", \"y\": [0.0007084158684354556, 0.030811338148384593, 0.001128155707256624, 0.0013966010754017718, 0.0006446842363536058, 0.06058028183174801, 0.028454815637177826, 0.001514261847750307, 0.001257819321543213, 0.01989066844888622, 0.005672083249424484, 0.014808102745240019, 0.18279613828671817, 0.1746645494878073, 0.29449566653913234, 0.18093183277415636, 0.0002445847945835882], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x2\", \"y\": [0.0009870002219148828, 0.030580342019890138, 0.0010700975334166547, 0.0012176681262269064, 0.001063465050694572, 0.05953741235564702, 0.028811848002357143, 0.0015658341895102286, 0.0011533838858764117, 0.019244042599792628, 0.006144884759286987, 0.01553735902115077, 0.1799634610251309, 0.1749723143887986, 0.3006909872710837, 0.17716825384750115, 0.0002916457017209413], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x3\", \"y\": [0.000870480849468897, 0.03021608629025874, 0.0010659580514080196, 0.001329746218532543, 0.0007878459618567324, 0.060411148152549166, 0.02969522842607584, 0.0014106452278994414, 0.0012573304435110927, 0.020294878724523333, 0.006070740598650161, 0.015114803062214147, 0.18132369421020564, 0.1754040676749097, 0.29781454626534315, 0.17661619842817258, 0.00031660141442081837], \"yaxis\": \"y3\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x4\", \"y\": [0.0007851227249096486, 0.03099649072974658, 0.0011851404557329552, 0.0016394198558451376, 0.000831465501503897, 0.05820150264313868, 0.029275808424430397, 0.0015790379816170768, 0.0012481529904598532, 0.020081804026532563, 0.0063528841461027285, 0.015237725375869017, 0.17999855364245246, 0.17513611006326954, 0.3004203458090621, 0.1768375994200156, 0.00019283620931176946], \"yaxis\": \"y4\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x5\", \"y\": [0.0008575168369675308, 0.030283091330917306, 0.0011874139847083015, 0.0015112362552758218, 0.0012356027125703525, 0.05970031234223169, 0.02928020764448227, 0.0015288645606553381, 0.0013513614742462717, 0.020387013018151864, 0.006069131163471967, 0.015342941597760293, 0.18005816080528203, 0.1749830621086957, 0.29818392657606085, 0.17785352658711506, 0.00018663100140735482], \"yaxis\": \"y5\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x6\", \"y\": [0.0008575436968663336, 0.03187116227574681, 0.001002269421927527, 0.0012495598340849332, 0.0008892352195825349, 0.059268335514062145, 0.029518946503106394, 0.001225717497067278, 0.0009452329453648978, 0.019098680651818682, 0.006325836646531374, 0.0158778076526754, 0.1814200184653604, 0.17371919525591933, 0.29859450837288987, 0.1780035832994609, 0.00013236674753512798], \"yaxis\": \"y6\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x7\", \"y\": [0.0008535336546450435, 0.030197589233819863, 0.0010892686883149103, 0.001326399273413137, 0.0007430600410240596, 0.059810139666237584, 0.028663949106447522, 0.0014845010535582642, 0.001157748562672283, 0.020576279500220857, 0.006564970160293242, 0.0153046794584222, 0.18353159598817737, 0.1752045133965203, 0.29577041454923053, 0.17757365785555587, 0.00014769981144712612], \"yaxis\": \"y7\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x8\", \"y\": [0.0007595892764404672, 0.030724525147969604, 0.001310184290717265, 0.001480244720541442, 0.000738473134193492, 0.06036223817925715, 0.02912700601724211, 0.0018514394772886742, 0.0011678398965474534, 0.02049243947309593, 0.005789828476005338, 0.015977547475666532, 0.1814328771032627, 0.17321190395732347, 0.2962212860631776, 0.17909795778482102, 0.00025461952644964097], \"yaxis\": \"y8\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x9\", \"y\": [0.0006814199709631729, 0.030523109127945324, 0.0011645690329188168, 0.0013375649245804845, 0.0006854264584766485, 0.05897941163324009, 0.029341126841111356, 0.0015475784681176228, 0.001028445614042643, 0.019488135797842414, 0.006433874707150639, 0.016153875635797066, 0.18178412798003354, 0.17663562588472367, 0.2967623500230339, 0.17727652493189955, 0.00017683296812280488], \"yaxis\": \"y9\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 0\", \"x\": 0.14444444444444446, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 1\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 2\", \"x\": 0.8555555555555556, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 3\", \"x\": 0.14444444444444446, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.6111111111111112, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 4\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.6111111111111112, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 5\", \"x\": 0.8555555555555556, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.6111111111111112, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 6\", \"x\": 0.14444444444444446, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.22222222222222224, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 7\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.22222222222222224, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 8\", \"x\": 0.8555555555555556, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.22222222222222224, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 1200, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Feature importance for individual ensembles (Majority class splitted)\"}, \"width\": 1200, \"xaxis\": {\"anchor\": \"y\", \"categoryorder\": \"total descending\", \"domain\": [0.0, 0.2888888888888889], \"tickangle\": -45}, \"xaxis2\": {\"anchor\": \"y2\", \"categoryorder\": \"total descending\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"tickangle\": -45}, \"xaxis3\": {\"anchor\": \"y3\", \"categoryorder\": \"total descending\", \"domain\": [0.7111111111111111, 1.0], \"tickangle\": -45}, \"xaxis4\": {\"anchor\": \"y4\", \"categoryorder\": \"total descending\", \"domain\": [0.0, 0.2888888888888889], \"tickangle\": -45}, \"xaxis5\": {\"anchor\": \"y5\", \"categoryorder\": \"total descending\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"tickangle\": -45}, \"xaxis6\": {\"anchor\": \"y6\", \"categoryorder\": \"total descending\", \"domain\": [0.7111111111111111, 1.0], \"tickangle\": -45}, \"xaxis7\": {\"anchor\": \"y7\", \"categoryorder\": \"total descending\", \"domain\": [0.0, 0.2888888888888889], \"tickangle\": -45}, \"xaxis8\": {\"anchor\": \"y8\", \"categoryorder\": \"total descending\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"tickangle\": -45}, \"xaxis9\": {\"anchor\": \"y9\", \"categoryorder\": \"total descending\", \"domain\": [0.7111111111111111, 1.0], \"tickangle\": -45}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.7777777777777778, 1.0], \"title\": {\"text\": \"Feature importance\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.7777777777777778, 1.0]}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.7777777777777778, 1.0]}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.3888888888888889, 0.6111111111111112], \"title\": {\"text\": \"Feature importance\"}}, \"yaxis5\": {\"anchor\": \"x5\", \"domain\": [0.3888888888888889, 0.6111111111111112]}, \"yaxis6\": {\"anchor\": \"x6\", \"domain\": [0.3888888888888889, 0.6111111111111112]}, \"yaxis7\": {\"anchor\": \"x7\", \"domain\": [0.0, 0.22222222222222224], \"title\": {\"text\": \"Feature importance\"}}, \"yaxis8\": {\"anchor\": \"x8\", \"domain\": [0.0, 0.22222222222222224]}, \"yaxis9\": {\"anchor\": \"x9\", \"domain\": [0.0, 0.22222222222222224]}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":111},{"cell_type":"markdown","source":["#### Construct a new dataset based on the output of base classifiers\n\nUsing the random forest classifiers training in the first stage, we'll use the remaining balanced dataset subset to collection predictions from these random forest classifiers and use these predictions to train the voting models. The code below outlines how we'd aggregate these predictions for ingestion to the voting model for training the voting model."],"metadata":{}},{"cell_type":"code","source":["def do_ensemble_prediction(em, train_en) :\n    prediction_array = []\n    for num, m in enumerate(em) :\n        predictions = em[num].transform(train_en)\n        if num == 0 : prediction_array.append(\n            predictions.select(\"label\").withColumn('ROW_ID', F.monotonically_increasing_id())\n        )      \n        prediction_array.append(predictions\n                                .select(F.col(\"prediction\").alias(\"prediction_\" + str(num)))\n                                # Create a monotonically increasing row id with each data frame \n                                # so that we can do recursive join based on the row ID.\n                                .withColumn('ROW_ID', F.monotonically_increasing_id()) \n        )\n    return prediction_array\n\nensemble_prediction = do_ensemble_prediction(ensemble_model, train_combiner)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":113},{"cell_type":"markdown","source":["#### Assemble and transform data for second level training"],"metadata":{}},{"cell_type":"markdown","source":["Join together the individual dataframes to create the final training dataset for level two model."],"metadata":{}},{"cell_type":"code","source":["from functools import reduce\n\ndef assemble_dataframe(prediction_array) :\n    # Do a reduction operation using functional programming concepts, iterate over array and generate\n    # a dataframe towrds end.\n    def do_reduce(df1, df2): return df1.join(df2, \"ROW_ID\")\n    return reduce(do_reduce, prediction_array).drop(\"ROW_ID\")\n\ndef do_transform_final(df) :\n    ensemble_columns = df.schema.names\n    en_target, en_features = ensemble_columns[0], ensemble_columns[1:]\n\n    assembler = VectorAssembler(inputCols=en_features, outputCol=\"features\")\n    pipeline = Pipeline(stages=[assembler])\n    return (pipeline\n            .fit(df)\n            .transform(df)\n            .select([\"features\"] + [en_target])\n    )\n  \nreduced_df = assemble_dataframe(ensemble_prediction)\n#reduced_df.show(2)\nensemble_transformed = do_transform_final(reduced_df)\n#ensemble_transformed.show(2) "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":116},{"cell_type":"code","source":["reduced_df.show(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------+------------+------------+------------+------------+------------+------------+------------+------------+\nlabel|prediction_0|prediction_1|prediction_2|prediction_3|prediction_4|prediction_5|prediction_6|prediction_7|prediction_8|\n+-----+------------+------------+------------+------------+------------+------------+------------+------------+------------+\n    0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|\n    0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|         0.0|\n+-----+------------+------------+------------+------------+------------+------------+------------+------------+------------+\nonly showing top 2 rows\n\n</div>"]}}],"execution_count":117},{"cell_type":"markdown","source":["#### Stage 2 : Learn a second-level classifier based on training set from first-level.\n\nFor the second stage, we'll train the second level classifier, which will be our voting model. Among our candidate voting models, we will consider Logistic Regression, Support Vector Machines, and Random Forests, to have a diverse set of candidates for our voting models. This is done below:"],"metadata":{}},{"cell_type":"code","source":["def TrainCombiner(data, featureIndexer, classifier):\n  # Chain indexer and forest in a Pipeline\n  pipeline_ensemble = Pipeline(stages=[featureIndexer, classifier])\n\n  # Train model.  This also runs the indexer.\n  return pipeline_ensemble.fit(data)\n\n# Set up VectorIndexer for second level training\nensemble_featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=3).fit(ensemble_transformed)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":119},{"cell_type":"code","source":["# Logistic Regression\nmodel_trained_ensemble_lr = TrainCombiner(ensemble_transformed, ensemble_featureIndexer, \n              LogisticRegression(featuresCol=\"indexedFeatures\", maxIter=10, regParam=0.2))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":120},{"cell_type":"code","source":["# Linear SVM\nmodel_trained_ensemble_svm = TrainCombiner(ensemble_transformed, ensemble_featureIndexer, \n              LinearSVC(featuresCol=\"indexedFeatures\", maxIter=10, regParam=0.1))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":121},{"cell_type":"code","source":["# Random forest\nmodel_trained_ensemble_rf = TrainCombiner(ensemble_transformed, ensemble_featureIndexer, \n              RandomForestClassifier(featuresCol=\"indexedFeatures\", maxBins=20, maxDepth=5, numTrees=5, impurity='gini'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":122},{"cell_type":"code","source":["# Create checkpoint\nif False : \n  model_trained_ensemble_lr.save(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_lr.v1.model\")\n  model_trained_ensemble_svm.save(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_svm.v1.model\")\n  model_trained_ensemble_rf.save(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_rf.v1.model\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":123},{"cell_type":"markdown","source":["#### Create final ensemble pipeline\n\nFor the final pipeline, we'll stitch together the following pieces:\n* The level one models, which are combined into a single parameter\n* Level two voting model\n* Data for running inference (e.g. validation set)"],"metadata":{}},{"cell_type":"code","source":["# recursively call each of the functions described above to transform the model objects we give as agruments. \n# This is the final model pipeline.\ndef FinalEnsmblePipeline(model_comb, model_group, data) :\n  return model_comb.transform(\n    do_transform_final(\n      assemble_dataframe(\n        do_ensemble_prediction(model_group, data)\n      )\n    )\n  )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":125},{"cell_type":"markdown","source":["#### Plot Model weights of ensembles\n\nSimilar to plotting the feature importances, we can also attempt to plot \"model importances\" as considered by each of the three voting models we've explored. \n\nIn the case of Logistic Regression, these metrics are the coefficients estimated for each of the individual random forest predictions. We ideally don't want to see any of these coefficients set to 0, as this indicates that the model is ignored and thus the subset of data is ignored. In this case, we see that all 9 of the models are pretty evenly considered. Note that for our Logistic Regression voting model, we chose to use L2 regularization, which allows the weights to get close to zero but not be set to zero (which would be a consequence of using L1 regularization so in this case, we prefer L2 regularization). In this case, we thankfully see that the models are fairly evenly considered by the voting model.\n\nFor SVM, the weights show correspond to the coefficients for the separating boundary in \"model space\" for our delay and no-delay cases. Like for Logistic Regression, we don't want to see any of these weights zeroed out, as that would indicate that the model and the data subset is ignored for training. In this case, we see that the SVM gives a similar distribution for the model importance, as was seen with Logistic Regression.\n\nFor Random Forests, the weights we see correspond directly to the feature importances we've shown previously for the individual random forests. In this case though, our \"features\" are our individual models. Like in the previous plots, these model importances are based on how much the models contributed to the information gain in the voting model, so the higher the importance, the more information gain provided by the individual tree. Once again, we see that all models are being considered, though some more than others (in this case, model 2 is the least)."],"metadata":{}},{"cell_type":"code","source":["from collections import defaultdict\n\ndef makedict(em, columns, features, info):\n    plot = defaultdict(dict)\n    rows = int(len(em)/columns)\n    for num, m in enumerate(em):\n        plot[num]['importance'] = em[num]\n        plot[num]['features']   = features\n        plot[num]['x_pos']      = int(num/columns)+1\n        plot[num]['y_pos']      = num%columns+1\n        plot[num]['title']      = info[num]\n    return plot, rows, columns\n\nplt, rows, columns = makedict([\n  list(model_trained_ensemble_lr.stages[-1].coefficients.toArray()), \n  list(model_trained_ensemble_svm.stages[-1].coefficients.toArray()), \n  list(model_trained_ensemble_rf.stages[-1].featureImportances.toArray())], \n  columns=3, \n  features=[ \"model {}\".format(s) for s in range(0, 9)],\n  info=[\n    \"Logistic regression - weights of ensembles\",\n    \"SVM - weights of ensembles\",\n    \"Random forest - weights of ensembles\",\n  ]\n)\n\nfig = make_subplots(rows=rows, cols=columns, subplot_titles=tuple([plt[key]['title'] for key, value in plt.items()]))\n\nfor key, value in plt.items() :\n    fig.add_trace(go.Bar(\n      x=plt[key]['features'],\n      y=plt[key]['importance'],\n      marker_color=list(map(lambda x: px.colors.sequential.thermal[x], range(0,len(plt[key]['features'])))),\n      name = '',\n      showlegend = False,\n    ), row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    \n    fig.update_xaxes(categoryorder='total descending', row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    fig.update_xaxes(categoryorder='total descending', row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    if plt[key]['y_pos'] == 1: fig.update_yaxes(title_text=\"Feature importance\", row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    fig.update_xaxes(tickangle=-45)\n    \nfig.update_layout(height=400, width=1200, title_text=\"Feature importance for individual ensembles (Majority class splitted)\")\nfig.update_layout(xaxis_tickangle=-45)\nfig.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"4094e604-e9f4-4f90-a848-5b208a484db9\" class=\"plotly-graph-div\" style=\"height:400px; width:1200px;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"4094e604-e9f4-4f90-a848-5b208a484db9\")) {\n                    Plotly.newPlot(\n                        '4094e604-e9f4-4f90-a848-5b208a484db9',\n                        [{\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"model 0\", \"model 1\", \"model 2\", \"model 3\", \"model 4\", \"model 5\", \"model 6\", \"model 7\", \"model 8\"], \"xaxis\": \"x\", \"y\": [0.18413069867274973, 0.18310258728978018, 0.17663560204854759, 0.20696245649403022, 0.2067261677296353, 0.15097525305987403, 0.15439806801589356, 0.15526127212574684, 0.17772956761318184], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"model 0\", \"model 1\", \"model 2\", \"model 3\", \"model 4\", \"model 5\", \"model 6\", \"model 7\", \"model 8\"], \"xaxis\": \"x2\", \"y\": [0.2900040637569452, 0.2869913877298208, 0.26007791677950226, 0.1751323619362114, 0.2731359078905665, 0.23582185829140365, 0.3105281545441727, 0.23568040377819963, 0.2788227173308557], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"model 0\", \"model 1\", \"model 2\", \"model 3\", \"model 4\", \"model 5\", \"model 6\", \"model 7\", \"model 8\"], \"xaxis\": \"x3\", \"y\": [0.11096851859395351, 0.12308672673125982, 0.05156347822618662, 0.12704631135356786, 0.10015165904815476, 0.16187990289823803, 0.08514511967075518, 0.13474067760730343, 0.10541760587058062], \"yaxis\": \"y3\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Logistic regression - weights of ensembles\", \"x\": 0.14444444444444446, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"SVM - weights of ensembles\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Random forest - weights of ensembles\", \"x\": 0.8555555555555556, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Feature importance for individual ensembles (Majority class splitted)\"}, \"width\": 1200, \"xaxis\": {\"anchor\": \"y\", \"categoryorder\": \"total descending\", \"domain\": [0.0, 0.2888888888888889], \"tickangle\": -45}, \"xaxis2\": {\"anchor\": \"y2\", \"categoryorder\": \"total descending\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"tickangle\": -45}, \"xaxis3\": {\"anchor\": \"y3\", \"categoryorder\": \"total descending\", \"domain\": [0.7111111111111111, 1.0], \"tickangle\": -45}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Feature importance\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0]}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":127},{"cell_type":"markdown","source":["### Training Ensemble with SMOTEd (Balanced) Training Dataset\nNow that we've developed the stacking approach using the majority class splitting, we can easily extend this to our original SMOTEd dataset. This is showcased in the code below:"],"metadata":{}},{"cell_type":"code","source":["# Train first-level classifiers using random forest, store the resulting model array.\nensemble_model_smoted = TrainEnsembleModels(train_group_smoted, ensemble_featureIndexer_smoted, \n                    RandomForestClassifier(featuresCol=\"indexedFeatures\", maxBins=369, maxDepth=8, numTrees=50, impurity='gini')\n                   )"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Create ensemble model : 0\nCreate ensemble model : 1\nCreate ensemble model : 2\nCreate ensemble model : 3\nCreate ensemble model : 4\nCreate ensemble model : 5\nCreate ensemble model : 6\nCreate ensemble model : 7\nCreate ensemble model : 8\n</div>"]}}],"execution_count":129},{"cell_type":"markdown","source":["Similar to how we did previously, we can visualize the feature importance provided by each individual random forest model, as shown in the following plots. From the plots below, we again see very similar feature importance distributions for all nine random forest models, which means that each of the individual models are once again learning similar things from their subsets of data. Specifically, we see that `Origin_Activity`, `CRS_Dep_Time`, `CRS_Arr_Time`, `Day_Of_Week`, and `Origin_Dest` are some of the most important features which indicates that using the SMOTEd dataset, the model appears to learn that departure/arrival time, day of week and the origin airports are likely the most indicative features for predicting departure delays."],"metadata":{}},{"cell_type":"code","source":["from collections import defaultdict\n\ndef makedict(em, columns, features):\n    plot = defaultdict(dict)\n    rows = int(len(em)/columns)\n    for num, m in enumerate(em):\n        plot[num]['importance'] = list(m.stages[-1].featureImportances.toArray())\n        plot[num]['features']   = features\n        plot[num]['x_pos']      = int(num/columns)+1\n        plot[num]['y_pos']      = num%columns+1\n        plot[num]['title']      = \"ensemble model {}\".format(num)\n    return plot, rows, columns\n\nplt, rows, columns = makedict(ensemble_model_smoted, columns=3, features=all_ensemble_features)\n\n\nfig = make_subplots(rows=rows, cols=columns, subplot_titles=tuple([plt[key]['title'] for key, value in plt.items()]))\n\nfor key, value in plt.items() :\n    fig.add_trace(go.Bar(\n      x=plt[key]['features'],\n      y=plt[key]['importance'],\n      #marker_color=list(map(lambda x: px.colors.sequential.thermal[x%12], range(0,len(plt[key]['features'])))),\n      marker_color=list(map(lambda x: px.colors.sequential.thermal[x] if x < 12 else px.colors.sequential.RdBu[x%12] , \n                      range(0,len(plt[key]['features'])))),\n      name = '',\n      showlegend = False,\n    ), row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    \n    fig.update_xaxes(categoryorder='total descending', row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    fig.update_xaxes(categoryorder='total descending', row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    if plt[key]['y_pos'] == 1: fig.update_yaxes(title_text=\"Feature importance\", row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    fig.update_xaxes(tickangle=-45)\n    \nfig.update_layout(height=1200, width=1200, title_text=\"Feature importance for individual ensembles (Smoted)\")\nfig.update_layout(xaxis_tickangle=-45)\nfig.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"7a126d84-04cc-4d48-86ec-96b8475a2798\" class=\"plotly-graph-div\" style=\"height:1200px; width:1200px;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"7a126d84-04cc-4d48-86ec-96b8475a2798\")) {\n                    Plotly.newPlot(\n                        '7a126d84-04cc-4d48-86ec-96b8475a2798',\n                        [{\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x\", \"y\": [0.0013631511452467527, 0.10193101974463264, 0.030638852503113732, 0.13877252360644832, 0.0018396838056095601, 0.1773595093076874, 0.14978656596072776, 0.002692836175424043, 0.20112334351243186, 0.015768132177852848, 0.03654066850196377, 0.012149291564397306, 0.0, 0.13003442199446405, 0.0, 0.0, 0.0], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x2\", \"y\": [0.0018536320538108414, 0.09484247964587465, 0.03113175701884714, 0.14624163428447454, 0.0015303465699394497, 0.17662275685683662, 0.1532366630581263, 0.0024943078296869405, 0.2082618797287695, 0.01541782533222519, 0.03583924092906009, 0.01149872006955553, 0.0, 0.1210287566227933, 0.0, 0.0, 0.0], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x3\", \"y\": [0.0018896961163869525, 0.10315217331999615, 0.03155991220932393, 0.1396787347847454, 0.0015296160314881334, 0.18156100145795104, 0.14778556528705733, 0.0024415788152019322, 0.20132164798402707, 0.014139807547390068, 0.039276483580215786, 0.01310378401964312, 0.0, 0.12255999884657325, 0.0, 0.0, 0.0], \"yaxis\": \"y3\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x4\", \"y\": [0.0015824003127301598, 0.0972030059962112, 0.029066331283068, 0.144893807553746, 0.0018724622339822508, 0.17322854441949348, 0.148897309450487, 0.0023285781991425163, 0.20842508171254023, 0.016138556143673724, 0.036825634969471895, 0.012700766482556233, 0.0, 0.1268375212428974, 0.0, 0.0, 0.0], \"yaxis\": \"y4\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x5\", \"y\": [0.001705471155938523, 0.09870632066513542, 0.0303824476168238, 0.14248438164298793, 0.0018402383213007396, 0.18181334374543354, 0.14828605628063202, 0.002743706656426335, 0.20460544951753915, 0.014349677518679849, 0.035110791794616875, 0.01101966242898216, 0.0, 0.12695245265550367, 0.0, 0.0, 0.0], \"yaxis\": \"y5\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x6\", \"y\": [0.0016300659058350268, 0.09772407392164562, 0.030517510684744863, 0.1434174351110317, 0.0018279542411358087, 0.17612288046231608, 0.14857393460151783, 0.0022873804935723734, 0.2089872174597674, 0.015104420518421612, 0.03542791067790291, 0.012575105058106481, 0.0, 0.12580411086400226, 0.0, 0.0, 0.0], \"yaxis\": \"y6\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x7\", \"y\": [0.0017049116767260055, 0.09954505371347594, 0.03245730484086666, 0.14042969896573743, 0.0017944202448756216, 0.1790375394949483, 0.14789566715855362, 0.002580102253145441, 0.20036791491170858, 0.015391274433326224, 0.03572558326105256, 0.011196199979296578, 0.0, 0.13187432906628718, 0.0, 0.0, 0.0], \"yaxis\": \"y7\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x8\", \"y\": [0.0017667471617594836, 0.10180569264188252, 0.03210176649178149, 0.14193636758954778, 0.0016097252463997225, 0.17628662668767914, 0.14650939860592346, 0.0021853044018962965, 0.20339660507034216, 0.014184997179423254, 0.03851311215749346, 0.01175577671386918, 0.0, 0.12794788005200208, 0.0, 0.0, 0.0], \"yaxis\": \"y8\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x9\", \"y\": [0.0016180918134852146, 0.10049191027472658, 0.03153904669155507, 0.13978597031908413, 0.0018564593169568932, 0.18121200752797798, 0.14679775959435715, 0.003308187324225024, 0.20227253625838312, 0.01528782448792252, 0.03647866812017457, 0.01039680768758082, 0.0, 0.12895473058357093, 0.0, 0.0, 0.0], \"yaxis\": \"y9\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 0\", \"x\": 0.14444444444444446, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 1\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 2\", \"x\": 0.8555555555555556, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 3\", \"x\": 0.14444444444444446, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.6111111111111112, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 4\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.6111111111111112, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 5\", \"x\": 0.8555555555555556, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.6111111111111112, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 6\", \"x\": 0.14444444444444446, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.22222222222222224, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 7\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.22222222222222224, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"ensemble model 8\", \"x\": 0.8555555555555556, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.22222222222222224, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 1200, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Feature importance for individual ensembles (Smoted)\"}, \"width\": 1200, \"xaxis\": {\"anchor\": \"y\", \"categoryorder\": \"total descending\", \"domain\": [0.0, 0.2888888888888889], \"tickangle\": -45}, \"xaxis2\": {\"anchor\": \"y2\", \"categoryorder\": \"total descending\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"tickangle\": -45}, \"xaxis3\": {\"anchor\": \"y3\", \"categoryorder\": \"total descending\", \"domain\": [0.7111111111111111, 1.0], \"tickangle\": -45}, \"xaxis4\": {\"anchor\": \"y4\", \"categoryorder\": \"total descending\", \"domain\": [0.0, 0.2888888888888889], \"tickangle\": -45}, \"xaxis5\": {\"anchor\": \"y5\", \"categoryorder\": \"total descending\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"tickangle\": -45}, \"xaxis6\": {\"anchor\": \"y6\", \"categoryorder\": \"total descending\", \"domain\": [0.7111111111111111, 1.0], \"tickangle\": -45}, \"xaxis7\": {\"anchor\": \"y7\", \"categoryorder\": \"total descending\", \"domain\": [0.0, 0.2888888888888889], \"tickangle\": -45}, \"xaxis8\": {\"anchor\": \"y8\", \"categoryorder\": \"total descending\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"tickangle\": -45}, \"xaxis9\": {\"anchor\": \"y9\", \"categoryorder\": \"total descending\", \"domain\": [0.7111111111111111, 1.0], \"tickangle\": -45}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.7777777777777778, 1.0], \"title\": {\"text\": \"Feature importance\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.7777777777777778, 1.0]}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.7777777777777778, 1.0]}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.3888888888888889, 0.6111111111111112], \"title\": {\"text\": \"Feature importance\"}}, \"yaxis5\": {\"anchor\": \"x5\", \"domain\": [0.3888888888888889, 0.6111111111111112]}, \"yaxis6\": {\"anchor\": \"x6\", \"domain\": [0.3888888888888889, 0.6111111111111112]}, \"yaxis7\": {\"anchor\": \"x7\", \"domain\": [0.0, 0.22222222222222224], \"title\": {\"text\": \"Feature importance\"}}, \"yaxis8\": {\"anchor\": \"x8\", \"domain\": [0.0, 0.22222222222222224]}, \"yaxis9\": {\"anchor\": \"x9\", \"domain\": [0.0, 0.22222222222222224]}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":131},{"cell_type":"markdown","source":["Next, we will proceed to train three voting models for the second stage of stacking, which again includes Logistic Regression, SVM, and Random Forests. We will use the 9 models trained previously as our stage one models for the stacked ensemble."],"metadata":{}},{"cell_type":"code","source":["# Checkpoint the smoted ensemble model \nif False : \n  for i, model in enumerate(ensemble_model_smoted):\n    model.save(\"dbfs:/user/team20/finalnotebook/ensemble_model_smoted\" + str(i) +  \".v2.model\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":133},{"cell_type":"code","source":["# Construct a new data set based on the output of base classifiers\nensemble_prediction_smoted = do_ensemble_prediction(ensemble_model_smoted, train_combiner_smoted)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":134},{"cell_type":"code","source":["# Assemble and transform data for second level training\nreduced_df_smoted = assemble_dataframe(ensemble_prediction_smoted)\nensemble_transformed_smoted = do_transform_final(reduced_df_smoted)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":135},{"cell_type":"code","source":["ensemble_featureIndexer_smoted = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=3).fit(ensemble_transformed_smoted)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":136},{"cell_type":"code","source":["# Learn a second-level classifier based on training set from first-level.\n\n# Logistic Regression\nmodel_trained_ensemble_lr_smoted = TrainCombiner(ensemble_transformed_smoted, ensemble_featureIndexer_smoted, \n              LogisticRegression(featuresCol=\"indexedFeatures\", maxIter=10, regParam=0.2))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":137},{"cell_type":"code","source":["# Linear SVM\nmodel_trained_ensemble_svm_smoted = TrainCombiner(ensemble_transformed_smoted, ensemble_featureIndexer_smoted, \n              LinearSVC(featuresCol=\"indexedFeatures\", maxIter=10, regParam=0.1))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":138},{"cell_type":"code","source":["# Random forest\nmodel_trained_ensemble_rf_smoted = TrainCombiner(ensemble_transformed_smoted, ensemble_featureIndexer_smoted, \n              RandomForestClassifier(featuresCol=\"indexedFeatures\", maxBins=20, maxDepth=5, numTrees=5, impurity='gini'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":139},{"cell_type":"code","source":["# Save and checkpoint the models\nif False : \n  model_trained_ensemble_lr_smoted.save(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_lr_smoted.v2.model\")\n  model_trained_ensemble_svm_smoted.save(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_svm_smoted.v2.model\")\n  model_trained_ensemble_rf_smoted.save(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_rf_smoted.v2.model\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":140},{"cell_type":"markdown","source":["With the voting models trained, we can again evaluate how these voting models consider each of the individual random forest models. In the case of Logistic Regression and SVM, we see a fairly uniform distribution across all nine individual models, suggesting an event consideration of the entire smoted dataset, similar to what we saw before with majority class splitting. However, there's a stark difference when looking at the model importances for the Random Forest voting model. In this case, model 6 is highly prioritized over the other 8 models, leading to less of a priority given to models 7, 4, 3, 2, 5, and 8, which is slight concerning given that the data learned by these models may be ignored and may lead to a bias towards the data that belongs to model 6."],"metadata":{}},{"cell_type":"code","source":["from collections import defaultdict\n\ndef makedict(em, columns, features, info):\n    plot = defaultdict(dict)\n    rows = int(len(em)/columns)\n    for num, m in enumerate(em):\n        plot[num]['importance'] = em[num]\n        plot[num]['features']   = features\n        plot[num]['x_pos']      = int(num/columns)+1\n        plot[num]['y_pos']      = num%columns+1\n        plot[num]['title']      = info[num]\n    return plot, rows, columns\n\nplt, rows, columns = makedict([\n  list(model_trained_ensemble_lr_smoted.stages[-1].coefficients.toArray()), \n  list(model_trained_ensemble_svm_smoted.stages[-1].coefficients.toArray()), \n  list(model_trained_ensemble_rf_smoted.stages[-1].featureImportances.toArray())], \n  columns=3, \n  features=[ \"model {}\".format(s) for s in range(0, 9)],\n  info=[\n    \"Logistic regression - weights of ensembles\",\n    \"SVM - weights of ensembles\",\n    \"Random forest - weights of ensembles\",\n  ]\n)\n\nfig = make_subplots(rows=rows, cols=columns, subplot_titles=tuple([plt[key]['title'] for key, value in plt.items()]))\n\nfor key, value in plt.items() :\n    fig.add_trace(go.Bar(\n      x=plt[key]['features'],\n      y=plt[key]['importance'],\n      marker_color=list(map(lambda x: px.colors.sequential.thermal[x], range(0,len(plt[key]['features'])))),\n      name = '',\n      showlegend = False,\n    ), row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    \n    fig.update_xaxes(categoryorder='total descending', row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    fig.update_xaxes(categoryorder='total descending', row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    if plt[key]['y_pos'] == 1: fig.update_yaxes(title_text=\"Feature importance\", row=plt[key]['x_pos'], col=plt[key]['y_pos'])\n    fig.update_xaxes(tickangle=-45)\n    \nfig.update_layout(height=400, width=1200, title_text=\"Feature importance for individual ensembles (Smoted)\")\nfig.update_layout(xaxis_tickangle=-45)\nfig.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"aa783209-bde6-4389-9929-faf43f70c37b\" class=\"plotly-graph-div\" style=\"height:400px; width:1200px;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"aa783209-bde6-4389-9929-faf43f70c37b\")) {\n                    Plotly.newPlot(\n                        'aa783209-bde6-4389-9929-faf43f70c37b',\n                        [{\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"model 0\", \"model 1\", \"model 2\", \"model 3\", \"model 4\", \"model 5\", \"model 6\", \"model 7\", \"model 8\"], \"xaxis\": \"x\", \"y\": [0.12449226384322983, 0.11679578173329622, 0.11828377498343437, 0.11271266898475213, 0.11425372739770932, 0.11227485167123448, 0.12495655370068148, 0.1263055338902763, 0.12182748551184955], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"model 0\", \"model 1\", \"model 2\", \"model 3\", \"model 4\", \"model 5\", \"model 6\", \"model 7\", \"model 8\"], \"xaxis\": \"x2\", \"y\": [0.10625608405931646, 0.10709061723118457, 0.10707822444307229, 0.10690986423659375, 0.10776675694795547, 0.10772278680335598, 0.10742530446617551, 0.10470465219697174, 0.1073298135270513], \"yaxis\": \"y2\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"model 0\", \"model 1\", \"model 2\", \"model 3\", \"model 4\", \"model 5\", \"model 6\", \"model 7\", \"model 8\"], \"xaxis\": \"x3\", \"y\": [0.19228096116290588, 0.16766521751880117, 0.006304422231324082, 0.014568235622757927, 0.019703333927271232, 0.004180258540271862, 0.5629183621371583, 0.030623695152374304, 0.0017555137071351451], \"yaxis\": \"y3\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Logistic regression - weights of ensembles\", \"x\": 0.14444444444444446, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"SVM - weights of ensembles\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Random forest - weights of ensembles\", \"x\": 0.8555555555555556, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Feature importance for individual ensembles (Smoted)\"}, \"width\": 1200, \"xaxis\": {\"anchor\": \"y\", \"categoryorder\": \"total descending\", \"domain\": [0.0, 0.2888888888888889], \"tickangle\": -45}, \"xaxis2\": {\"anchor\": \"y2\", \"categoryorder\": \"total descending\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"tickangle\": -45}, \"xaxis3\": {\"anchor\": \"y3\", \"categoryorder\": \"total descending\", \"domain\": [0.7111111111111111, 1.0], \"tickangle\": -45}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Feature importance\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0]}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":142},{"cell_type":"markdown","source":["### Model Evaluation\n\nWith the ensemble models for both dataset balancing techniques trained and evaluated at a high-level, we'll now examine the actual performance results of the models against both the validation and the held out test sets. We will consider all of the six performance metrics discussed previously, as well as the full confusion matrix to again understand the nuances of model performance. We'll look at the performance metrics for each of our three voting models and compare them accordingly."],"metadata":{}},{"cell_type":"code","source":["# Reload voting model from checkpoints\nprint(\"Loading model_trained_ensemble_lr_smoted.v2.model\")\nmodel_trained_ensemble_lr_smoted_load = pl.PipelineModel.load(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_lr_smoted.v2.model\")\nprint(\"Loading model_trained_ensemble_svm_smoted.v2.model\")\nmodel_trained_ensemble_svm_smoted_load = pl.PipelineModel.load(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_svm_smoted.v2.model\")\nprint(\"Loading model_trained_ensemble_rf_smoted.v2.model\")\nmodel_trained_ensemble_rf_smoted_load = pl.PipelineModel.load(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_rf_smoted.v2.model\")\nprint(\"Loading model_trained_ensemble_lr.v2.model\")\nmodel_trained_ensemble_lr_load = pl.PipelineModel.load(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_lr.v1.model\")\nprint(\"Loading model_trained_ensemble_svm.v2.model\")\nmodel_trained_ensemble_svm_load = pl.PipelineModel.load(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_svm.v1.model\")\nprint(\"Loading model_trained_ensemble_rf.v2.model\")\nmodel_trained_ensemble_rf_load = pl.PipelineModel.load(\"dbfs:/user/team20/finalnotebook/model_trained_ensemble_rf.v1.model\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Loading model_trained_ensemble_lr_smoted.v2.model\nLoading model_trained_ensemble_svm_smoted.v2.model\nLoading model_trained_ensemble_rf_smoted.v2.model\nLoading model_trained_ensemble_lr.v2.model\nLoading model_trained_ensemble_svm.v2.model\nLoading model_trained_ensemble_rf.v2.model\n</div>"]}}],"execution_count":144},{"cell_type":"code","source":["# Reload ensemble model from checkpoints\nensemble_model_load = []\nfor i in range(0,9) :\n  print(\"Loading ensemble_model \" + str(i))\n  ensemble_model_load.append(pl.PipelineModel.load(\"dbfs:/user/team20/finalnotebook/ensemble_model\" + str(i) + \".v1.model\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Loading ensemble_model 0\nLoading ensemble_model 1\nLoading ensemble_model 2\nLoading ensemble_model 3\nLoading ensemble_model 4\nLoading ensemble_model 5\nLoading ensemble_model 6\nLoading ensemble_model 7\nLoading ensemble_model 8\n</div>"]}}],"execution_count":145},{"cell_type":"code","source":["# Reload smoted ensemble model from checkpoints\nensemble_model_smoted_load = []\nfor i in range(0,9) :\n  print(\"Loading ensemble_model \" + str(i))\n  ensemble_model_smoted_load.append(pl.PipelineModel.load(\"dbfs:/user/team20/finalnotebook/ensemble_model_smoted\" + str(i) + \".v2.model\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Loading ensemble_model 0\nLoading ensemble_model 1\nLoading ensemble_model 2\nLoading ensemble_model 3\nLoading ensemble_model 4\nLoading ensemble_model 5\nLoading ensemble_model 6\nLoading ensemble_model 7\nLoading ensemble_model 8\n</div>"]}}],"execution_count":146},{"cell_type":"code","source":["# Reload test and validation data from checkpoints\nprint(\"Loading ensemble_test.v1.parquet\")\nensemble_test_load = spark.read.option(\"header\", \"true\").parquet(\"dbfs:/user/team20/finalnotebook/ensemble_test.v1.parquet\")\nprint(\"Loading ensemble_val.v1.parquet\")\nensemble_val_load = spark.read.option(\"header\", \"true\").parquet(\"dbfs:/user/team20/finalnotebook/ensemble_val.v1.parquet\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Loading ensemble_test.v1.parquet\nLoading ensemble_val.v1.parquet\n</div>"]}}],"execution_count":147},{"cell_type":"code","source":["# Run the evaluation metrics after prediction. Use the model trained with non smote-d data for  prediction\n\nmodel_eval_regular = []\nfor (l2_name, l2_model, l1_model)  in [\n  (\"LR\", model_trained_ensemble_lr_load, ensemble_model_load), \n  (\"SVM\", model_trained_ensemble_svm_load, ensemble_model_load), \n  (\"RF\", model_trained_ensemble_rf_load, ensemble_model_load),\n] :\n  for data_name, data in [(\"test set\", ensemble_test_load), (\"validation\", ensemble_val_load)] :\n      print(\"Level 2 model type = {}, running on {}\".format(l2_name,data_name))\n      ensemble_test_prediction = FinalEnsmblePipeline(l2_model, l1_model, data) # Run prediction using the \"FinalEnsmblePipeline\"\n      eval = EvaluateModelPredictions(ensemble_test_prediction, dataName=data_name, ReturnVal=True)  # Run the evaluation function\n      \n      # Collect the evaluation metrics.\n      model_eval_regular.append({ 'l2_name' : l2_name, 'data_name' : data_name, 'result' : eval})\n      "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Level 2 model type = LR, running on test set\nLevel 2 model type = LR, running on validation\nLevel 2 model type = SVM, running on test set\nLevel 2 model type = SVM, running on validation\nLevel 2 model type = RF, running on test set\nLevel 2 model type = RF, running on validation\n</div>"]}}],"execution_count":148},{"cell_type":"code","source":["model_eval = model_eval_regular\nheaderColor  = 'lightgrey'\nrowEvenColor = 'lightgrey'\nrowOddColor  = 'white'\n\nfig = go.Figure(data=[go.Table(\n  header=dict(\n    values=['<b>Run type</b>','<b>Accuracy</b>','<b>Precision</b>','<b>Recall</b>','<b>f-score</b>', \n            '<b>AUROC</b>', '<b>AUPRC</b>', '<b>TP</b>', '<b>TN</b>', '<b>FP</b>', '<b>FN</b>'],\n    line_color='darkslategray',\n    fill_color=headerColor,\n    align=['left','center'],\n    font=dict(color='black', size=13)\n  ),\n  cells=dict(\n    values=[\n      [ev['l2_name'] + '<br>(' + ev['data_name'] + ')' for ev in model_eval],\n      [ev['result']['Accuracy'] for ev in model_eval],\n      [ev['result']['Precision'] for ev in model_eval],\n      [ev['result']['Recall'] for ev in model_eval],\n      [ev['result']['f-score'] for ev in model_eval],\n      [ev['result']['areaUnderROC'] for ev in model_eval],\n      [ev['result']['AreaUnderPRC'] for ev in model_eval],\n      [ev['result']['metric']['TP'] for ev in model_eval],\n      [ev['result']['metric']['TN'] for ev in model_eval],\n      [ev['result']['metric']['FP'] for ev in model_eval],\n      [ev['result']['metric']['FN'] for ev in model_eval],\n    ],\n    line_color='darkslategray',\n    align = ['left'],\n    font = dict(color = 'darkslategray', size = 13)\n    ))\n])\nfig.update_layout(width=1400, height=600, title=\"Model evaluation results (Not smoted)\")\nfig.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"27b1fcb9-ffdb-41f6-a4f8-3a4c3873a805\" class=\"plotly-graph-div\" style=\"height:600px; width:1400px;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"27b1fcb9-ffdb-41f6-a4f8-3a4c3873a805\")) {\n                    Plotly.newPlot(\n                        '27b1fcb9-ffdb-41f6-a4f8-3a4c3873a805',\n                        [{\"cells\": {\"align\": [\"left\"], \"font\": {\"color\": \"darkslategray\", \"size\": 13}, \"line\": {\"color\": \"darkslategray\"}, \"values\": [[\"LR<br>(test set)\", \"LR<br>(validation)\", \"SVM<br>(test set)\", \"SVM<br>(validation)\", \"RF<br>(test set)\", \"RF<br>(validation)\"], [0.6279107, 0.6257352, 0.619724, 0.6567659, 0.5833418, 0.4868177], [0.1271589, 0.1494983, 0.1520538, 0.1613635, 0.1553069, 0.0806484], [0.3481782, 0.6298822, 0.456148, 0.6145524, 0.5414978, 0.6757488], [0.1862845, 0.241644, 0.228079, 0.2556111, 0.2413828, 0.144099], [0.60079, 0.6674928, 0.5450617, 0.6738452, 0.5351326, 0.6372989], [0.1312294, 0.1692227, 0.1559297, 0.0982876, 0.1317182, 0.0874351], [298074, 176898, 396461, 175762, 472974, 123189], [4096337, 1679460, 3976922, 1783062, 3689264, 1265034], [2046032, 1006380, 2210913, 913468, 2572442, 1404294], [558022, 103945, 472689, 110238, 400481, 59111]]}, \"header\": {\"align\": [\"left\", \"center\"], \"fill\": {\"color\": \"lightgrey\"}, \"font\": {\"color\": \"black\", \"size\": 13}, \"line\": {\"color\": \"darkslategray\"}, \"values\": [\"<b>Run type</b>\", \"<b>Accuracy</b>\", \"<b>Precision</b>\", \"<b>Recall</b>\", \"<b>f-score</b>\", \"<b>AUROC</b>\", \"<b>AUPRC</b>\", \"<b>TP</b>\", \"<b>TN</b>\", \"<b>FP</b>\", \"<b>FN</b>\"]}, \"type\": \"table\"}],\n                        {\"height\": 600, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Model evaluation results (Not smoted)\"}, \"width\": 1400},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":149},{"cell_type":"code","source":["# Run the evaluation metrics after prediction. Use the model trained with regular (non smote-d) data for  prediction\nmodel_eval_smoted = []\nfor (l2_name, l2_model, l1_model)  in [\n  (\"LR-smoted\", model_trained_ensemble_lr_smoted_load, ensemble_model_smoted_load), \n  (\"SVM-smoted\", model_trained_ensemble_svm_smoted_load, ensemble_model_smoted_load), \n  (\"RF-smoted\", model_trained_ensemble_rf_smoted_load, ensemble_model_smoted_load),\n] :\n  for data_name, data in [(\"test set\", ensemble_test_load), (\"validation\", ensemble_val_load)] :\n      print(\"Level 2 model type = {}, running on {}\".format(l2_name,data_name))\n      ensemble_test_prediction = FinalEnsmblePipeline(l2_model, l1_model, data) # Run prediction using the \"FinalEnsmblePipeline\"\n      eval = EvaluateModelPredictions(ensemble_test_prediction, dataName=data_name, ReturnVal=True) # Run the evaluation function \n      \n      # Collect the evaluation metrics.\n      model_eval_smoted.append({ 'l2_name' : l2_name, 'data_name' : data_name, 'result' : eval})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Level 2 model type = LR-smoted, running on test set\nLevel 2 model type = LR-smoted, running on validation\nLevel 2 model type = SVM-smoted, running on test set\nLevel 2 model type = SVM-smoted, running on validation\nLevel 2 model type = RF-smoted, running on test set\nLevel 2 model type = RF-smoted, running on validation\n</div>"]}}],"execution_count":150},{"cell_type":"code","source":["model_eval = model_eval_smoted\nheaderColor  = 'lightgrey'\nrowEvenColor = 'lightgrey'\nrowOddColor  = 'white'\n\nfig = go.Figure(data=[go.Table(\n  header=dict(\n    values=['<b>Run type</b>','<b>Accuracy</b>','<b>Precision</b>','<b>Recall</b>','<b>f-score</b>', \n            '<b>AUROC</b>', '<b>AUPRC</b>', '<b>TP</b>', '<b>TN</b>', '<b>FP</b>', '<b>FN</b>'],\n    line_color='darkslategray',\n    fill_color=headerColor,\n    align=['left','center'],\n    font=dict(color='black', size=13)\n  ),\n  cells=dict(\n    values=[\n      [ev['l2_name'] + '<br>(' + ev['data_name'] + ')' for ev in model_eval],\n      [ev['result']['Accuracy'] for ev in model_eval],\n      [ev['result']['Precision'] for ev in model_eval],\n      [ev['result']['Recall'] for ev in model_eval],\n      [ev['result']['f-score'] for ev in model_eval],\n      [ev['result']['areaUnderROC'] for ev in model_eval],\n      [ev['result']['AreaUnderPRC'] for ev in model_eval],\n      [ev['result']['metric']['TP'] for ev in model_eval],\n      [ev['result']['metric']['TN'] for ev in model_eval],\n      [ev['result']['metric']['FP'] for ev in model_eval],\n      [ev['result']['metric']['FN'] for ev in model_eval],\n    ],\n    line_color='darkslategray',\n    align = ['left'],\n    font = dict(color = 'darkslategray', size = 13)\n    ))\n])\nfig.update_layout(width=1400, height=600, title=\"Model evaluation results (smoted)\")\nfig.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"3f245656-7c39-4d58-9067-90c1d3b1b92c\" class=\"plotly-graph-div\" style=\"height:600px; width:1400px;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"3f245656-7c39-4d58-9067-90c1d3b1b92c\")) {\n                    Plotly.newPlot(\n                        '3f245656-7c39-4d58-9067-90c1d3b1b92c',\n                        [{\"cells\": {\"align\": [\"left\"], \"font\": {\"color\": \"darkslategray\", \"size\": 13}, \"line\": {\"color\": \"darkslategray\"}, \"values\": [[\"LR-smoted<br>(test set)\", \"LR-smoted<br>(validation)\", \"SVM-smoted<br>(test set)\", \"SVM-smoted<br>(validation)\", \"RF-smoted<br>(test set)\", \"RF-smoted<br>(validation)\"], [0.5565957, 0.5644327, 0.1229729, 0.1151986, 0.1908567, 0.1228697], [0.1495696, 0.1431371, 0.1229729, 0.1151986, 0.1236052, 0.1151922], [0.5576658, 0.5577297, 1.0, 1.0, 0.9213854, 0.9899607], [0.2358758, 0.2278088, 0.2190132, 0.2065975, 0.2179695, 0.2063709], [0.5377001, 0.5703643, 0.5068496, 0.5702799, 0.5374141, 0.56574], [0.1291274, 0.1400508, 0.1349326, 0.1400256, 0.131762, 0.1333717], [513168, 197496, 861972, 354107, 783829, 350552], [3660426, 1537504, 0, 0, 542836, 27135], [2917797, 1182272, 6147473, 2719776, 5557562, 2692641], [407039, 156611, 0, 0, 66878, 3555]]}, \"header\": {\"align\": [\"left\", \"center\"], \"fill\": {\"color\": \"lightgrey\"}, \"font\": {\"color\": \"black\", \"size\": 13}, \"line\": {\"color\": \"darkslategray\"}, \"values\": [\"<b>Run type</b>\", \"<b>Accuracy</b>\", \"<b>Precision</b>\", \"<b>Recall</b>\", \"<b>f-score</b>\", \"<b>AUROC</b>\", \"<b>AUPRC</b>\", \"<b>TP</b>\", \"<b>TN</b>\", \"<b>FP</b>\", \"<b>FN</b>\"]}, \"type\": \"table\"}],\n                        {\"height\": 600, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Model evaluation results (smoted)\"}, \"width\": 1400},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":151},{"cell_type":"markdown","source":["In the tables shown above, we see the performance results for both dataset balancing approaches across the different voting models. One thing that we want to look for is consistency across both the validation and test sets, which is something that we see for most metrics, but there does appear to be a stark difference in most of the runs between the two data balancing methods. Accuracy seems to be consistently higher for majority class splitting and greater than 0.5 but both approaches have fairly decent AUROC. In some cases, recall seems to fair better for sMOTE, which is great if the airlines and airports are using this model to prepare for delays from a resource perspective, but the lower precision means people might be more likely to miss their flights if they rely on this model to predict departure delays. The f-score, which attempts to balance both precision and recall into one metric, seems to hover around the same 0.22 regardless of data balancing approaches or voting models, as does the AUPRC at around 0.12. \n\nOne thing that stands out is the low accuracy on SVM and Random Forest voting models with SMOTEing, which appears to be due to the very high number of false positives, which indicates that the models are predicting a lot of the flights as delayed when they are not--this could be because we generated a lot of synthetic data for the minority class, some of which might have actually been similar to non-delayed flights. This is especially exemplified by the high recall of 1 and 0.92/0.98 for SVM and Random Forests respectively, which also have fairly small numbers of true negatives and false negatives. In fact, in the case of the SVM voting model, the model always predicted delay, which is the inverse of the problem we were worried about when it came to data balancing--if anything, SVM appears to have gotten fairly confused between delay and no delay flights. But it's important to note that the Logistic Regression voting model actually does fairly well and doesn't seem to fall into the trap of always predicting delays. It does seem to outperform the other voting models on many of the statistics we've considered, likey due to the fact that in the model's simplest form, it will just predict the average, which is essentially a majority vote among all the individual random forests. \n\nBy comparison, the voting models that leveraged majority class splitted trees seem to more consistently perform well across all of the voting models considered. We do see that all three models generally have higher performance compared to the SMOTEd voting models, but Logistic Regression and SVM seems to be approximately tied across all metrics for the majority class splitted models in terms of performance on both validation and test sets. In general though, across both data balancing techniques, Logistic Regression seems to fare as better voting model; although, to know for sure, we would need to do proper cross validation and hyperparameter experimentation.\n\nAt the end of the day, it depends on what your priorities are and who is going to use this model. But, while the metrics might not be perfect, our core question really had two sides to it--we want to have decent performance but also explain what is going on to help us try to find a solution to the problem. With that, we will once again explore the feature importances in a side by side comparison for the two data balancing approaches, which are shown below:"],"metadata":{}},{"cell_type":"code","source":["import numpy as np\n\nfig = make_subplots(rows=rows, cols=columns, subplot_titles=(\"Majority class splitted\",\"Smoted\"))\n\ndef normalize_vec(x) :\n    vec = np.stack(x).sum(axis=0)  # Normalization step.\n    return(vec/np.linalg.norm(vec))\n\nfor (row, col), value in [((1, 1), [m.stages[-1].featureImportances.toArray() for m in ensemble_model_load]), \n                          ((1, 2), [m.stages[-1].featureImportances.toArray() for m in ensemble_model_smoted_load])] :\n    fig.add_trace(go.Bar(\n      x = all_ensemble_features,\n      y = normalize_vec(value),\n      marker_color=list(map(lambda x: px.colors.sequential.thermal[x] if x < 12 else px.colors.sequential.RdBu[x%12] , \n                            range(0,len(all_ensemble_features)))),\n      name = '',\n      showlegend = False,\n    ), row=row, col=col)\n    \n    fig.update_xaxes(categoryorder='total descending', row=row, col=col)\n    fig.update_xaxes(categoryorder='total descending', row=row, col=col)\n    fig.update_xaxes(tickangle=-60)\n    \nfig.update_layout(height=600, width=1500, title_text=\"<b>Feature importance for individual ensembles</b>\")\nfig.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>\n            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n            <div id=\"b411fc2a-d710-4e7d-bf39-912b22ab6d76\" class=\"plotly-graph-div\" style=\"height:600px; width:1500px;\"></div>\n            <script type=\"text/javascript\">\n                \n                    window.PLOTLYENV=window.PLOTLYENV || {};\n                    \n                if (document.getElementById(\"b411fc2a-d710-4e7d-bf39-912b22ab6d76\")) {\n                    Plotly.newPlot(\n                        'b411fc2a-d710-4e7d-bf39-912b22ab6d76',\n                        [{\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x\", \"y\": [0.0018774000523291382, 0.07044850662086383, 0.002602391101444575, 0.0031853007716914168, 0.0019433675337159704, 0.136929125841702, 0.06686879202598928, 0.0034963310642692116, 0.0026952987151859413, 0.04579701690348746, 0.014136501518262049, 0.035543837000421484, 0.4163365330366769, 0.40144682642384255, 0.6832938421272372, 0.408442557459999, 0.0004957901380874445], \"yaxis\": \"y\"}, {\"marker\": {\"color\": [\"rgb(3, 35, 51)\", \"rgb(13, 48, 100)\", \"rgb(53, 50, 155)\", \"rgb(93, 62, 153)\", \"rgb(126, 77, 143)\", \"rgb(158, 89, 135)\", \"rgb(193, 100, 121)\", \"rgb(225, 113, 97)\", \"rgb(246, 139, 69)\", \"rgb(251, 173, 60)\", \"rgb(246, 211, 70)\", \"rgb(231, 250, 90)\", \"rgb(103,0,31)\", \"rgb(178,24,43)\", \"rgb(214,96,77)\", \"rgb(244,165,130)\", \"rgb(253,219,199)\"]}, \"name\": \"\", \"showlegend\": false, \"type\": \"bar\", \"x\": [\"Year\", \"Month\", \"Day_Of_Month\", \"Day_Of_Week\", \"Distance_Group\", \"CRS_Dep_Time_bin\", \"CRS_Arr_Time_bin\", \"CRS_Elapsed_Time_bin\", \"Origin_Activity\", \"Op_Unique_Carrier_brieman\", \"Origin_brieman\", \"Dest_brieman\", \"Day_Of_Year_brieman\", \"Origin_Dest_brieman\", \"Dep_Time_Of_Week_brieman\", \"Arr_Time_Of_Week_brieman\", \"Holiday_brieman\"], \"xaxis\": \"x2\", \"y\": [0.004419257412856806, 0.2618080535257057, 0.08169276445527196, 0.373571521399187, 0.00459081494276425, 0.4687753350352513, 0.3911525579044747, 0.0067431326688597035, 0.5376386924928365, 0.039701683451895564, 0.09641268904927949, 0.03110934296772062, 0.0, 0.33390965100095704, 0.0, 0.0, 0.0], \"yaxis\": \"y2\"}],\n                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Majority class splitted\", \"x\": 0.14444444444444446, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Smoted\", \"x\": 0.5, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"<b>Feature importance for individual ensembles</b>\"}, \"width\": 1500, \"xaxis\": {\"anchor\": \"y\", \"categoryorder\": \"total descending\", \"domain\": [0.0, 0.2888888888888889], \"tickangle\": -60}, \"xaxis2\": {\"anchor\": \"y2\", \"categoryorder\": \"total descending\", \"domain\": [0.35555555555555557, 0.6444444444444445], \"tickangle\": -60}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.7111111111111111, 1.0], \"tickangle\": -60}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0]}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 1.0]}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.0, 1.0]}},\n                        {\"responsive\": true}\n                    )\n                };\n                \n            </script>\n        </div>\n</body>\n</html>"]}}],"execution_count":153},{"cell_type":"markdown","source":["At first glance, these plots appear to tell us that the random forests trained on SMOTEd data and Majority Class Splitted data seemed to have learned something different. In the Majority Class Splitted case, we see that `Dep_Time_Of_Week` has the highest importance and for SMOTEd data, `Origin_Activity` ranks the highest, and the features that follow for both are different. But we need to remember something about decision trees in general--they have the ability to build their own interaction terms. In this case, `Dep_Time_Of_Week` in the majority class splitted models is the cross of `Dep_Time` & `Day_Of_Week`, which are highly ranked in the SMOTEd Models; same goes for `Day_Of_Year` as the interaction of `Month` and `Day_Of_Month`. Though the plots may look different, this is an artifact of the feature engineering we did. In reality, both kinds of ensembles tells us a similar story. Features relating to the origin airport and the traffic at it, the scheduled departure time (both time and day of week), as well as the time of year seem to be important indicators, whereas the length of the flight (both in terms of elapsed time and distance) and the airline carriers are less so. For airlines and airports, this can give useful information about where they can fundamentally make changes to the infrastructure to try to reduce delays and help address the underlying problems that lead to departure delays."],"metadata":{}},{"cell_type":"markdown","source":["## VI. Conclusions\n\nAs we draw to a close in this investigation, we want to revisit the question we posed at the start of this analysis: **Given known information prior to a flight's departure, can we predict departure delays and identify the likely causes of such delays?** Throughout this analysis, we've explored a variety of models and settled on decision trees as the fundamental algorithm to help answer this question. After experiment with decision trees and extending to random forests and stacked ensembles of random forests, we came to develop models that could predict departure delays, given information known 6 hours prior to the scheduled departure time. Depending on the data balancing techniques we used, as well as the voting models we chose, the models were able to perform well across metrics such as accuracy, recall, area under ROC, especially considering the high-degree of imbalance present in the original dataset. But we were also able to identify the likely causes of delays, which gave us consistent information regardless of the data balancing techniques used. Namely, features relating to the departure time, day of the week, time of the year, as well as the origin airport and traffic at it were very good indicators of departure delays, suggesting that these features may be able to explain the causes of such delays. This gives airlines and airports the ability to act on this information and potentially make fundamental changes to infrastructure to reduce the departure delays.\n\nFrom an exploration perspective, scalability challenges were present every step of the way, whether it was with SMOTEing our dataset, training our ensembles, or anticipating challenges with our feature engineering approaches. Due to limitations on our computational capacity, we did have to approximate SMOTE with K-means and we were limited in the amount of experimentation we could do with our ensembles. For the future, we'd look to trying out more data balancing approaches and comparing them to what we've already tried, as well as bringing in some more datasets to help introduce more features, such as weather data."],"metadata":{}},{"cell_type":"markdown","source":["## VII. Applications of Course Concepts\n### Bias-variance tradeoff     \nBias variance tradeoff came up throughout the project at different places. During Algorithm Exploration we broadly classified algorithms as those that underfit with high bias and low variance and those that tend to over-fit with low bias and high variance. The Logistic Regression and Naive Bayes belonged to the former category while Decision Tree and Support Vector Machines belonged to the latter. Lastly, during algorithm performance evaluation of decision trees it became clear that this algorithm due to the higher complexity and low bias tended to overfit to the given training set.  Because of that there was high variance between training and validation sets. To reduce the over-fitting and high variance, we used random forests and ensembles of random forests to help generalize the models to the scenario. Some limited hyperparameter tuning using random forests helped us to get closer to a solution that balanced both bias and variance.\n       \n### Breiman's Theorem       \nWe applied Breiman's theorem to all of the unordered categorical features to generate a ranking within each categorical feature. We accomplished this by ordering each category based on the ranking obtained from the calculation of the average outcome. This method helped us convert categorical features to ranked numerical features. In our dataset, we applied Breimanâs Theorem to the following features. `Op_Unique_Carrier`, `Origin`, `Dest` and for the following interacted features `Day_Of_Year`, `Origin_Dest`, `Dep_Time_Of_Week`, `Arr_Time_Of_Week`, `Holiday`. For example, if you consider the feature `Op_Unique_Carrier` it had 19 unique categories. Using Breiman's method the potential 262,143 splits were reduced to 18 splits by ranking them based on the average outcome value. The scalability benefits were even more pronounced for features like `Origin_Dest` and `Day_Of_Year` where the number of categories were much larger.\n\n### Data storage on cluster - parquet\nThe original airlines dataset has roughly 31 million records and 54 features. While analyzing this data, it is crucial to be efficient with use of disk and I/O memory. Parquet files is a column oriented efficient way of storing this data and is very helpful in transporting the data before unpacking it. In our project we used this format when originally ingesting the data. In addition we made use of the convenience of parquet format, in storing the mini_train, train, validation, test data. We also benefitted from parquet-formatted storage when running EDA, where many of the EDA tasks were isolated to just a few columns at a time (thus benefit from the column-wise storage of data). We also used this format extensively during the feature engineering phase where we augmented the dataset by adding new features/columns through interactions, binning, applying Breiman, etc. Another place this format came in handy was while oversampling the imbalanced data using SMOTE. The transformed dataset was then saved in parquet to be accessed during algorithm evaluation by decision tree, random forests and ensembles.\n\n### Scalability for Data Sampling & Ensemble Training\nGiven the high-degree of imbalance in the dataset, we decided to use SMOTE to create a more balanced set. We had scalability challenges in implementing the KNN algorithm required of the original SMOTE algorithm. Namely, trying to create K nearest neighbors for approximately 2 million samples from the minority class didnât scale well. This was due to the fact that we would need to store all of these samples in memory in order to find the K nearest neighbors for each sample. To address this challenge we used only a small random sample of the minority class which fit in memory well. The second approach was to create 1000 clusters of minority samples using the K-Means algorithm and run the KNN algorithm in parallel on these smaller clusters to generate synthetic data.  The second approach was much more scalable compared to the first (2.5 hrs Vs 24+hrs) and took much less time. It also yielded a set of synthetic samples closer to the distribution of the original minority dataset.\n\nWe also saw scalability concerns with training our ensembles, given that each of the random forests could be trained in parallel. In order to solve this \"embarrassingly parallel\" problem, we looked to using threadpools to run the training in parallel, which worked at first, but started to give broadcast timeout errors as the clusters became busier.\n\n### Broadcasting (for SMOTE, Breiman's Theorem, Holiday feature)\nBroadcasted variables allow the programmer to specify to the Spark execution engine that the data stored in a given broadcasted variable is small enough for a pure copy to be shipped to each worker that needs to reference it. This is especially useful in situations where we need to join a larger dataset (like the *Airline Delays* dataset) with a small one (like the Holidays dataset). In this case, if we specify the smaller dataset in a broadcast variable prior to joining, we can trigger a broadcast join, which will allow copies of the dataset to be shipped to each worker that proccesses a subset of the larger dataset and do the join on the workers, rather than having to shuffle partitions of the large and small datasets to be joined down-stream. This was particularly useful when generating the `Holiday` feature, `Origin_Activity` feature, and when joining our Breiman ranks back to the original dataset when applying Breiman's Theorem."],"metadata":{}},{"cell_type":"markdown","source":["## VIII. References\n* *Airline Delays* Dataset\n  - https://www.transtats.bts.gov/HomeDrillChart.asp\n  - Prepared by Luis Villarreal\n* References on the Bureau of Transportation Statistics\n  - https://www.bts.gov/topics/airlines-and-airports/understanding-reporting-causes-flight-delays-and-cancellations\n  - https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236\n* Holidays Dataset\n  - https://gist.github.com/shivaas/4758439\n* SMOTE Algorithm\n  - Chawla, Nitesh V., et al. âSMOTE: synthetic minority over-sampling technique.â Journal of artificial intelligence research16 (2002): 321â357: https://arxiv.org/pdf/1106.1813.pdf\n  - https://www.youtube.com/watch?v=FheTDyCwRdE\n* Majority Class Splitting & Stacking Algorithm\n  - https://en.wikipedia.org/wiki/Ensemble_learning\n  - https://www.mdpi.com/2076-3417/8/5/815/pdf\n  - http://marmota.dlsi.uji.es/WebBIB/papers/2003/paa-2.pdf \n* Feature Importance for Random Forests\n  - https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/ml/classification/RandomForestClassifier.scala\n* General Airline Study\n - \"Flight delays are costing airlines serious money\", by The Associated Press, DEC 10, 2014.: https://mashable.com/2014/12/10/cost-of-delayed-flights/"],"metadata":{}}],"metadata":{"name":"Final_Notebook_Draft - w261Project","notebookId":14766879045700},"nbformat":4,"nbformat_minor":0}