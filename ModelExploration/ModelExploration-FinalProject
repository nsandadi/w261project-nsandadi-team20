# Databricks notebook source
display(dbutils.fs.ls("dbfs:/mnt/mids-w261/data/datasets_final_project/parquet_airlines_data"))

# COMMAND ----------

airlines = spark.read.option("header", "true").parquet(f"dbfs:/mnt/mids-w261/data/datasets_final_project/parquet_airlines_data/201*.parquet")

# COMMAND ----------

# Split airlines data into train, dev, test
test = airlines.where('Year = 2019') # held out
train, val = airlines.where('Year != 2019').randomSplit([7.0, 1.0], 6)

# Select a mini subset for the training dataset (~2000 records)
mini_train = train.sample(fraction=0.0001, seed=6)

# COMMAND ----------

